{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=100,176\n",
    "nb_frames = 64    # img_depth or number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def data_gen(train_list, batch_size=64):\n",
    "    while True:\n",
    "        current_vid=0\n",
    "        X_tr_array = np.zeros([batch_size,nb_frames,img_cols,img_rows,channels])\n",
    "        Y_train = np.zeros([batch_size, nb_classes])\n",
    "        for vid_ID in random.sample(train_list,batch_size):\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"D:/Project/eventbins/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"D:/Project/eventbins/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                pos = os.path.join(pos_dir,img_ID)\n",
    "                neg = os.path.join(neg_dir,img_ID)\n",
    "                p_img = cv2.imread(pos,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,0]=p_img\n",
    "                n_img = cv2.imread(neg,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,1]=n_img\n",
    "                #frame = cv2.merge((p_img,n_img))\n",
    "                #X_tr_array[current_vid,frame_count]=frame\n",
    "                frame_count+=1\n",
    "            Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "            current_vid+=1\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "import tensorflow as tf\n",
    "keras=tf.contrib.keras\n",
    "l2=keras.regularizers.l2\n",
    "weight_decay = 0.00005\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(nb_frames,  img_cols, img_rows, channels)))\n",
    "\n",
    "model.add(Conv3D(16,(1,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_1'))\n",
    "model.add(Conv3D(16,(1,3,3),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_12'))\n",
    "model.add(Conv3D(16,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_13'))\n",
    "model.add(Conv3D(16,(5,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_1'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), name='MaxPool_1'))\n",
    "\n",
    "model.add(Conv3D(64,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_2'))\n",
    "model.add(Conv3D(64,(1,3,3), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_22'))\n",
    "model.add(Conv3D(64,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_23'))\n",
    "model.add(Conv3D(64,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_2'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 3), name='MaxPool_2'))\n",
    "\n",
    "model.add(Conv3D(128,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_3'))\n",
    "model.add(Conv3D(128,(1,3,3), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_32'))\n",
    "model.add(Conv3D(128,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_33'))\n",
    "model.add(Conv3D(128,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_3'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 2), name='MaxPool_3'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_1'))\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_2'))\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_3'))\n",
    "\n",
    "model.add(Flatten(name='Flatten'))\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='FC_1'))\n",
    "model.add(Dropout(0.5, name='Dropout_1'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='FC_2'))\n",
    "model.add(Dropout(0.5, name='Dropout_2'))\n",
    "\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay), name='FC_3'))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling3d_1 (MaxPooling3 (None, 64, 50, 88, 2)     0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_1 (Conv3D)      (None, 64, 46, 84, 16)    816       \n",
      "_________________________________________________________________\n",
      "Conv_spatial_12 (Conv3D)     (None, 64, 44, 82, 16)    2320      \n",
      "_________________________________________________________________\n",
      "Conv_spatial_13 (Conv3D)     (None, 64, 44, 82, 16)    272       \n",
      "_________________________________________________________________\n",
      "Conv_temporal_1 (Conv3D)     (None, 60, 44, 82, 16)    1296      \n",
      "_________________________________________________________________\n",
      "MaxPool_1 (MaxPooling3D)     (None, 60, 22, 41, 16)    0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_2 (Conv3D)      (None, 60, 18, 37, 64)    25664     \n",
      "_________________________________________________________________\n",
      "Conv_spatial_22 (Conv3D)     (None, 60, 16, 35, 64)    36928     \n",
      "_________________________________________________________________\n",
      "Conv_spatial_23 (Conv3D)     (None, 60, 16, 35, 64)    4160      \n",
      "_________________________________________________________________\n",
      "Conv_temporal_2 (Conv3D)     (None, 58, 16, 35, 64)    12352     \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling3D)     (None, 58, 8, 11, 64)     0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_3 (Conv3D)      (None, 58, 4, 7, 128)     204928    \n",
      "_________________________________________________________________\n",
      "Conv_spatial_32 (Conv3D)     (None, 58, 2, 5, 128)     147584    \n",
      "_________________________________________________________________\n",
      "Conv_spatial_33 (Conv3D)     (None, 58, 2, 5, 128)     16512     \n",
      "_________________________________________________________________\n",
      "Conv_temporal_3 (Conv3D)     (None, 56, 2, 5, 128)     49280     \n",
      "_________________________________________________________________\n",
      "MaxPool_3 (MaxPooling3D)     (None, 56, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "LSTM_1 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "LSTM_2 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "LSTM_3 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 28672)             0         \n",
      "_________________________________________________________________\n",
      "FC_1 (Dense)                 (None, 512)               14680576  \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FC_2 (Dense)                 (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "FC_3 (Dense)                 (None, 27)                6939      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 18,861,435\n",
      "Trainable params: 18,861,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"deeper_full\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.002,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "463/463 [==============================] - 4171s 9s/step - loss: 3.6793 - acc: 0.0849 - val_loss: 3.6160 - val_acc: 0.1118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.11184, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 2/60\n",
      "463/463 [==============================] - 4318s 9s/step - loss: 3.5596 - acc: 0.1122 - val_loss: 3.3485 - val_acc: 0.1590\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.11184 to 0.15899, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 3/60\n",
      "463/463 [==============================] - 4320s 9s/step - loss: 3.2752 - acc: 0.1714 - val_loss: 3.0507 - val_acc: 0.2445\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.15899 to 0.24452, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 4/60\n",
      "463/463 [==============================] - 4248s 9s/step - loss: 3.1052 - acc: 0.1976 - val_loss: 2.9400 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.24452 to 0.27303, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 5/60\n",
      "463/463 [==============================] - 4256s 9s/step - loss: 3.0580 - acc: 0.2065 - val_loss: 2.8930 - val_acc: 0.2686\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.27303\n",
      "Epoch 6/60\n",
      "463/463 [==============================] - 4262s 9s/step - loss: 2.9795 - acc: 0.2302 - val_loss: 2.7698 - val_acc: 0.2818\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.27303 to 0.28180, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 7/60\n",
      "463/463 [==============================] - 4420s 10s/step - loss: 2.8940 - acc: 0.2445 - val_loss: 2.7893 - val_acc: 0.2807\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.28180\n",
      "Epoch 8/60\n",
      "463/463 [==============================] - 4635s 10s/step - loss: 2.8391 - acc: 0.2620 - val_loss: 2.6766 - val_acc: 0.3070\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.28180 to 0.30702, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 9/60\n",
      "463/463 [==============================] - 4663s 10s/step - loss: 2.7667 - acc: 0.2805 - val_loss: 2.5640 - val_acc: 0.3465\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.30702 to 0.34649, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 10/60\n",
      "463/463 [==============================] - 4772s 10s/step - loss: 2.7220 - acc: 0.2935 - val_loss: 2.5892 - val_acc: 0.3268\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.34649\n",
      "Epoch 11/60\n",
      "463/463 [==============================] - 5217s 11s/step - loss: 2.6947 - acc: 0.3041 - val_loss: 2.5603 - val_acc: 0.3487\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.34649 to 0.34868, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 12/60\n",
      "463/463 [==============================] - 8076s 17s/step - loss: 2.6384 - acc: 0.3178 - val_loss: 2.5457 - val_acc: 0.3575\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.34868 to 0.35746, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 13/60\n",
      "463/463 [==============================] - 9226s 20s/step - loss: 2.6025 - acc: 0.3288 - val_loss: 2.4735 - val_acc: 0.3695\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.35746 to 0.36952, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 14/60\n",
      "463/463 [==============================] - 3552s 8s/step - loss: 2.5626 - acc: 0.3282 - val_loss: 2.4209 - val_acc: 0.3860\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.36952 to 0.38596, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 15/60\n",
      "463/463 [==============================] - 3408s 7s/step - loss: 2.4923 - acc: 0.3504 - val_loss: 2.4438 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.38596\n",
      "Epoch 16/60\n",
      "463/463 [==============================] - 3500s 8s/step - loss: 2.4301 - acc: 0.3705 - val_loss: 2.3340 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.38596 to 0.41009, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 17/60\n",
      "463/463 [==============================] - 3427s 7s/step - loss: 2.4255 - acc: 0.3676 - val_loss: 2.1735 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.41009 to 0.46601, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 18/60\n",
      "463/463 [==============================] - 3774s 8s/step - loss: 2.4297 - acc: 0.3727 - val_loss: 2.2258 - val_acc: 0.4430\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.46601\n",
      "Epoch 19/60\n",
      "463/463 [==============================] - 3598s 8s/step - loss: 2.3594 - acc: 0.3865 - val_loss: 2.3318 - val_acc: 0.3794\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.46601\n",
      "Epoch 20/60\n",
      "463/463 [==============================] - 3436s 7s/step - loss: 2.3323 - acc: 0.4000 - val_loss: 2.2259 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.46601\n",
      "Epoch 21/60\n",
      "463/463 [==============================] - 4858s 10s/step - loss: 2.3163 - acc: 0.4027 - val_loss: 2.1483 - val_acc: 0.4649\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.46601\n",
      "Epoch 22/60\n",
      "463/463 [==============================] - 3201s 7s/step - loss: 2.2728 - acc: 0.4154 - val_loss: 2.1107 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.46601 to 0.47368, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 23/60\n",
      "463/463 [==============================] - 3171s 7s/step - loss: 2.2330 - acc: 0.4243 - val_loss: 2.0919 - val_acc: 0.4572\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.47368\n",
      "Epoch 24/60\n",
      "463/463 [==============================] - 3167s 7s/step - loss: 2.2410 - acc: 0.4218 - val_loss: 2.1183 - val_acc: 0.4857\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.47368 to 0.48575, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 25/60\n",
      "463/463 [==============================] - 3192s 7s/step - loss: 2.1790 - acc: 0.4336 - val_loss: 2.0482 - val_acc: 0.4682\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.48575\n",
      "Epoch 26/60\n",
      "463/463 [==============================] - 3276s 7s/step - loss: 2.1703 - acc: 0.4436 - val_loss: 2.0340 - val_acc: 0.4616\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.48575\n",
      "Epoch 27/60\n",
      "463/463 [==============================] - 3271s 7s/step - loss: 2.1751 - acc: 0.4517 - val_loss: 2.0886 - val_acc: 0.4682\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.48575\n",
      "Epoch 28/60\n",
      "463/463 [==============================] - 3257s 7s/step - loss: 2.1555 - acc: 0.4488 - val_loss: 2.0299 - val_acc: 0.5011\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.48575 to 0.50110, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 29/60\n",
      "463/463 [==============================] - 3264s 7s/step - loss: 2.1203 - acc: 0.4586 - val_loss: 1.9831 - val_acc: 0.4956\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.50110\n",
      "Epoch 30/60\n",
      "463/463 [==============================] - 3185s 7s/step - loss: 2.1086 - acc: 0.4538 - val_loss: 1.9491 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.50110\n",
      "Epoch 31/60\n",
      "463/463 [==============================] - 3118s 7s/step - loss: 2.0993 - acc: 0.4599 - val_loss: 2.1302 - val_acc: 0.4726\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.50110\n",
      "Epoch 32/60\n",
      "463/463 [==============================] - 3130s 7s/step - loss: 2.0713 - acc: 0.4796 - val_loss: 1.9173 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.50110 to 0.54167, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 33/60\n",
      "463/463 [==============================] - 3156s 7s/step - loss: 2.0430 - acc: 0.4852 - val_loss: 1.9193 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.54167\n",
      "Epoch 34/60\n",
      "463/463 [==============================] - 3160s 7s/step - loss: 2.0292 - acc: 0.4883 - val_loss: 1.9764 - val_acc: 0.4814\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.54167\n",
      "Epoch 35/60\n",
      "463/463 [==============================] - 3116s 7s/step - loss: 2.0106 - acc: 0.4900 - val_loss: 1.8975 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.54167\n",
      "Epoch 36/60\n",
      "463/463 [==============================] - 3168s 7s/step - loss: 1.9930 - acc: 0.5053 - val_loss: 1.8783 - val_acc: 0.5318\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.54167\n",
      "Epoch 37/60\n",
      "463/463 [==============================] - 3149s 7s/step - loss: 1.9980 - acc: 0.4856 - val_loss: 1.9159 - val_acc: 0.5230\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.54167\n",
      "Epoch 38/60\n",
      "463/463 [==============================] - 3159s 7s/step - loss: 2.0000 - acc: 0.5028 - val_loss: 1.8643 - val_acc: 0.5208\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.54167\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 3218s 7s/step - loss: 1.9583 - acc: 0.5065 - val_loss: 1.8505 - val_acc: 0.5515\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.54167 to 0.55154, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 40/60\n",
      "463/463 [==============================] - 3159s 7s/step - loss: 1.9285 - acc: 0.5189 - val_loss: 1.8866 - val_acc: 0.5077\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.55154\n",
      "Epoch 41/60\n",
      "463/463 [==============================] - 3141s 7s/step - loss: 1.9247 - acc: 0.5154 - val_loss: 1.8870 - val_acc: 0.5461\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.55154\n",
      "Epoch 42/60\n",
      "463/463 [==============================] - 3143s 7s/step - loss: 1.8911 - acc: 0.5298 - val_loss: 1.8122 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.55154 to 0.55702, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 43/60\n",
      "463/463 [==============================] - 3186s 7s/step - loss: 1.9196 - acc: 0.5243 - val_loss: 1.7922 - val_acc: 0.5351\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.55702\n",
      "Epoch 44/60\n",
      "463/463 [==============================] - 3215s 7s/step - loss: 1.8573 - acc: 0.5400 - val_loss: 1.7637 - val_acc: 0.5976\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.55702 to 0.59759, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 45/60\n",
      "463/463 [==============================] - 3183s 7s/step - loss: 1.8803 - acc: 0.5447 - val_loss: 1.7533 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.59759\n",
      "Epoch 46/60\n",
      "463/463 [==============================] - 3122s 7s/step - loss: 1.8799 - acc: 0.5315 - val_loss: 1.8942 - val_acc: 0.5471\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.59759\n",
      "Epoch 47/60\n",
      "463/463 [==============================] - 3150s 7s/step - loss: 1.8459 - acc: 0.5406 - val_loss: 1.8624 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.59759\n",
      "Epoch 48/60\n",
      "463/463 [==============================] - 3200s 7s/step - loss: 1.8200 - acc: 0.5578 - val_loss: 1.7087 - val_acc: 0.5855\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.59759\n",
      "Epoch 49/60\n",
      "463/463 [==============================] - 3148s 7s/step - loss: 1.8257 - acc: 0.5531 - val_loss: 1.5676 - val_acc: 0.6425\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.59759 to 0.64254, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 50/60\n",
      "463/463 [==============================] - 3144s 7s/step - loss: 1.8218 - acc: 0.5556 - val_loss: 1.8623 - val_acc: 0.5351\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.64254\n",
      "Epoch 51/60\n",
      "463/463 [==============================] - 3273s 7s/step - loss: 1.8061 - acc: 0.5574 - val_loss: 1.8134 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.64254\n",
      "Epoch 52/60\n",
      "463/463 [==============================] - 3440s 7s/step - loss: 1.7575 - acc: 0.5692 - val_loss: 1.6386 - val_acc: 0.6086\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.64254\n",
      "Epoch 53/60\n",
      "463/463 [==============================] - 3366s 7s/step - loss: 1.7827 - acc: 0.5629 - val_loss: 1.6418 - val_acc: 0.6228\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.64254\n",
      "Epoch 54/60\n",
      " 36/463 [=>............................] - ETA: 2:12:26 - loss: 1.9180 - acc: 0.5226"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bffe28026cbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Video\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                            \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                            \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                           )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=7, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"for entry in hist1.history['loss']:\n",
    "    training_loss.append(entry)\n",
    "for entry in hist1.history['val_loss']:\n",
    "    val_loss.append(entry)\n",
    "for entry in hist1.history['acc']:\n",
    "    training_acc.append(entry)\n",
    "for entry in hist1.history['val_acc']:\n",
    "    val_acc.append(entry)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "with open('E:/Jupyter/Project/save_model/deeperloss_tr.pkl','wb') as fid:\n",
    "    pickle.dump(training_loss, fid)\n",
    "with open('E:/Jupyter/Project/save_model/deeperloss_val.pkl','wb') as fid:\n",
    "    pickle.dump(val_loss, fid)\n",
    "\"\"\"with open('deeploss_tr.pkl','rb') as fid:\n",
    "    training_loss = pickle.load(fid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "with open('E:/Jupyter/Project/save_model/deeperacc_tr.pkl','wb') as fid:\n",
    "    pickle.dump(training_acc, fid)\n",
    "with open('E:/Jupyter/Project/save_model/deeperacc_val.pkl','wb') as fid:\n",
    "    pickle.dump(val_acc, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(16*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=7, min_lr=0.005/(2^4),verbose=1)\n",
    "hist1 = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(16*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.07, \n",
    "                               cooldown=0, patience=5, min_lr=0.00002/(2^4),verbose=1)\n",
    "hist2 = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, save_model\n",
    "model1_name = \"deeper_full\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "save_model(model,model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"deeper_full\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_predict_gen(train_list, niter, batch_size=64):\n",
    "    while True:\n",
    "        current_vid=0\n",
    "        X_tr_array = np.zeros([batch_size,nb_frames,img_cols,img_rows,channels])\n",
    "        Y_train = np.zeros([batch_size, nb_classes])\n",
    "        for vid_ID in train_list[niter*batch_size:(niter+1)*batch_size]:\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                pos = os.path.join(pos_dir,img_ID)\n",
    "                neg = os.path.join(neg_dir,img_ID)\n",
    "                p_img = cv2.imread(pos,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,0]=p_img\n",
    "                n_img = cv2.imread(neg,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,1]=n_img\n",
    "                #frame = cv2.merge((p_img,n_img))\n",
    "                #X_tr_array[current_vid,frame_count]=frame\n",
    "                frame_count+=1\n",
    "            Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "            current_vid+=1\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 16\n",
    "batch_size = 16\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ls_path = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled\")\n",
    "met = confusion_matrix([26],[26],labels.sort_values(by=['Label'])['Label'].tolist())\n",
    "met[26][26]-=1\n",
    "for n in tqdm(range(len(validation[\"Video\"].tolist()[0:])//(num_samples))):\n",
    "    current_vid=0\n",
    "    Y_train = np.zeros([batch_size, nb_classes])\n",
    "    for vid_ID in validation[\"Video\"].tolist()[n*batch_size:(n+1)*batch_size]:\n",
    "        Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "        current_vid+=1\n",
    "    met1 = confusion_matrix(np.argmax(Y_train,axis =1), np.argmax(model1.predict_generator(data_predict_gen(validation[\"Video\"].tolist()[0:],n,num_samples),1),axis =1),labels.sort_values(by=['Label'])['Label'].tolist())\n",
    "    for x in range(met1.shape[0]):\n",
    "        for y in range(met1.shape[0]):\n",
    "            met[x][y]=met[x][y]+met1[x][y]\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('E:/Jupyter/Project/save_model/deeperconf.pkl','wb') as fid:\n",
    "    pickle.dump(met, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Full Label Set Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm *= 100\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(15, 15))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=270)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix_plot(met, classes=labels.sort_values(by=['Label'])['Class'].tolist())\n",
    "plt.savefig(\"fullconfusion.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "X_tr_array = np.zeros([1,nb_frames,img_cols,img_rows,channels])\n",
    "Y_train = np.zeros([1, nb_classes])\n",
    "vid_ID = 95\n",
    "frame_count=0\n",
    "current_vid=0\n",
    "pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "for img_ID in sorted(os.listdir(pos_dir)):\n",
    "    pos = os.path.join(pos_dir,img_ID)\n",
    "    neg = os.path.join(neg_dir,img_ID)\n",
    "    p_img = cv2.imread(pos,0)\n",
    "    X_tr_array[current_vid,frame_count,:,:,0]=p_img\n",
    "    n_img = cv2.imread(neg,0)\n",
    "    X_tr_array[current_vid,frame_count,:,:,1]=n_img\n",
    "    #frame = cv2.merge((p_img,n_img))\n",
    "    #X_tr_array[current_vid,frame_count]=frame\n",
    "    frame_count+=1\n",
    "print(labels_dict[vid_ID])\n",
    "\n",
    "layer_outputs = [layer.output for layer in model1.layers[:12]]\n",
    "activation_model = Model(inputs=model1.input, outputs=layer_outputs)\n",
    "activations=activation_model.predict(X_tr_array[0:1])\n",
    "fig = plt.figure()\n",
    "\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "for i in range(X_tr_array[0:1].shape[1]):\n",
    "    im = plt.imshow(X_tr_array[0:1][0, i, :,:, 0], cmap='viridis')\n",
    "    ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "if not os.path.exists(\"E:/Jupyter/Project/deep_activations\"):\n",
    "    os.makedirs(\"E:/Jupyter/Project/deep_activations\")\n",
    "ani.save(\"E:/Jupyter/Project/deep_activations/\"+'input' + '.mp4')\n",
    "\n",
    "layer_num = 0\n",
    "layer_names=[]\n",
    "for layer in model1.layers[:16]:\n",
    "    layer_names.append(layer.name)\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # ims is a list of lists, each row is a list of artists to draw in the\n",
    "    # current frame; here we are just animating one artist, the image, in\n",
    "    # each frame\n",
    "    ims = []\n",
    "    if layer_num<10:\n",
    "        x=layer_activation.shape[-1]\n",
    "        if x>32:\n",
    "            x=32\n",
    "        for layer_iteration in range(x):\n",
    "            ims = []\n",
    "            for i in range(layer_activation.shape[1]):\n",
    "                im = plt.imshow(layer_activation[0, i, :,:,layer_iteration], cmap='viridis')\n",
    "                ims.append([im])\n",
    "            ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                            repeat_delay=1000)\n",
    "            if not os.path.exists(\"E:/Jupyter/Project/deep_activations/\"+str(layer_num)):\n",
    "                os.makedirs(\"E:/Jupyter/Project/deep_activations/\"+str(layer_num))\n",
    "            ani.save(\"E:/Jupyter/Project/deep_activations/\"+str(layer_num) +\"/\"+layer_name+ 'activation' + str(layer_iteration) + '.mp4')\n",
    "        layer_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
