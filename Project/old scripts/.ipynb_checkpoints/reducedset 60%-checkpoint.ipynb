{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=100,176\n",
    "nb_frames = 16    # img_depth or number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_gen(train_list, batch_size=64):\n",
    "    while True:\n",
    "        X_tr=[]\n",
    "        label=[]\n",
    "        for vid_ID in random.sample(train_list,batch_size):\n",
    "            frames = []\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                if frame_count < nb_frames:\n",
    "                    pos = os.path.join(pos_dir,img_ID)\n",
    "                    neg = os.path.join(neg_dir,img_ID)\n",
    "                    p_img = cv2.imread(pos,0)\n",
    "                    p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    n_img = cv2.imread(neg,0)\n",
    "                    n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    frame = cv2.merge((p_img,n_img))\n",
    "                    frames.append(frame)\n",
    "                    frame_count+=1\n",
    "                else:\n",
    "                    break\n",
    "            while frame_count < nb_frames:\n",
    "                frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "                frame_count+=1\n",
    "            input_img = np.array(frames)\n",
    "            ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "            ipt=np.rollaxis(ipt,2,0)\n",
    "            X_tr.append(ipt)\n",
    "            label.append(labels_dict[vid_ID])\n",
    "\n",
    "        X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "        Y_train = np_utils.to_categorical(label, nb_classes)\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16, 100, 176, 2)\n"
     ]
    }
   ],
   "source": [
    "print(next(data_gen(train[\"Video\"].tolist()))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low resolution network\n",
    "weight_decay = 0.005\n",
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(nb_frames,  img_cols, img_rows, channels)))\n",
    "\n",
    "model.add(Conv3D(8,(1,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(8,(5,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(32,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64,(1,3,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(64,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 4 )))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling3d_1 (MaxPooling3 (None, 16, 50, 88, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 16, 46, 84, 8)     408       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 46, 84, 8)     328       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 23, 42, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 12, 19, 38, 32)    6432      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 19, 38, 32)    3104      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 5, 9, 19, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 5, 7, 15, 64)      30784     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 3, 7, 15, 64)      12352     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 7, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2064896   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 27)                6939      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 2,256,571\n",
      "Trainable params: 2,256,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"30%\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.005,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "64/64 [==============================] - 118s 2s/step - loss: 10.3068 - acc: 0.0688 - val_loss: 10.0565 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08984, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 2/400\n",
      "64/64 [==============================] - 115s 2s/step - loss: 9.8474 - acc: 0.0793 - val_loss: 9.6040 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.08984\n",
      "Epoch 3/400\n",
      "24/64 [==========>...................] - ETA: 1:07 - loss: 9.5606 - acc: 0.0768"
     ]
    }
   ],
   "source": [
    "nb_epoch = 400\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:]),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:1500]),\n",
    "                           steps_per_epoch=64,\n",
    "                           validation_steps=4,\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"30%\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "X_tr=[]           # variable to store entire dataset\n",
    "label=[]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "ls_path = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled\")\n",
    "\n",
    "for vid_ID in tqdm(validation[\"Video\"].tolist()[0:2000]):\n",
    "    frames = []\n",
    "    frame_count=0\n",
    "    pos_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    neg_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    for img_ID in sorted(os.listdir(pos_dir)):\n",
    "        if frame_count < nb_frames:\n",
    "            pos = os.path.join(pos_dir,img_ID)\n",
    "            neg = os.path.join(neg_dir,img_ID)\n",
    "            p_img = cv2.imread(pos,0)\n",
    "            p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            n_img = cv2.imread(neg,0)\n",
    "            n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.merge((p_img,n_img))\n",
    "            frames.append(frame)\n",
    "            frame_count+=1\n",
    "        else:\n",
    "            break\n",
    "    while frame_count < nb_frames:\n",
    "        frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "        frame_count+=1\n",
    "    input_img = np.array(frames)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    X_tr.append(ipt)\n",
    "    label.append(labels_dict[vid_ID])\n",
    "\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr) \n",
    "print (num_samples)\n",
    "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "train_data = [X_tr_array,label]\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "train_set = np.zeros((num_samples, nb_frames, img_cols,img_rows,2))\n",
    "for h in range(num_samples):\n",
    "    train_set[h][:][:][:][:]=X_train[h,:,:,:]\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =model1.predict(train_set[50:70])\n",
    "result = np.argmax(test_pred, axis =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = train_set[50]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "met = confusion_matrix(np.argmax(Y_train,axis =1), np.argmax(model1.predict(train_set),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, range(27), rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(met, classes=labels.sort_values(by=['Label'])['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.sort_values(by=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(train_set,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
