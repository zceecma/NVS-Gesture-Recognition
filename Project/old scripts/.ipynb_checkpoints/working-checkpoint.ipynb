{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=100,176\n",
    "nb_frames = 64    # number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118562\n",
      "14787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "print(len(train))\n",
    "print(len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_gen(train_list, batch_size=32):\n",
    "    while True:\n",
    "        X_tr=[]\n",
    "        label=[]\n",
    "        for vid_ID in random.sample(train_list,batch_size):\n",
    "            frames = []\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                if frame_count < nb_frames:\n",
    "                    pos = os.path.join(pos_dir,img_ID)\n",
    "                    neg = os.path.join(neg_dir,img_ID)\n",
    "                    p_img = cv2.imread(pos,0)\n",
    "                    n_img = cv2.imread(neg,0)\n",
    "                    frame = cv2.merge((p_img,n_img))\n",
    "                    frames.append(frame)\n",
    "                    frame_count+=1\n",
    "                else:\n",
    "                    break\n",
    "            while frame_count < nb_frames:\n",
    "                frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "                frame_count+=1\n",
    "            input_img = np.array(frames)\n",
    "            ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "            ipt=np.rollaxis(ipt,2,0)\n",
    "            X_tr.append(ipt)\n",
    "            label.append(labels_dict[vid_ID])\n",
    "\n",
    "        X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "        Y_train = np_utils.to_categorical(label, nb_classes)\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 100, 176, 2)\n"
     ]
    }
   ],
   "source": [
    "print(next(data_gen(train[\"Video\"].tolist()))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.005\n",
    "from keras import regularizers\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low resolution network\n",
    "weight_decay = 0.005\n",
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(nb_frames,  img_cols, img_rows, channels)))\n",
    "\n",
    "model.add(Conv3D(8,(1,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(8,(5,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(32,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64,(1,3,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(64,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 4 )))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling3d_1 (MaxPooling3 (None, 64, 50, 88, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 64, 46, 84, 8)     408       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 60, 46, 84, 8)     328       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 60, 23, 42, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 60, 19, 38, 32)    6432      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 58, 19, 38, 32)    3104      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 29, 9, 19, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 29, 7, 15, 64)     30784     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 27, 7, 15, 64)     12352     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 27, 7, 3, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18579968  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 27)                6939      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 18,771,643\n",
      "Trainable params: 18,771,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"30%\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.002,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "231/231 [==============================] - 4584s 20s/step - loss: 10.7043 - acc: 0.0749 - val_loss: 10.2965 - val_acc: 0.0871\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08705, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 2/100\n",
      "231/231 [==============================] - 4490s 19s/step - loss: 9.9799 - acc: 0.0841 - val_loss: 9.6354 - val_acc: 0.0893\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08705 to 0.08929, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 3/100\n",
      "231/231 [==============================] - 4432s 19s/step - loss: 9.3549 - acc: 0.0820 - val_loss: 8.9745 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.08929 to 0.14286, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 4/100\n",
      "231/231 [==============================] - 4430s 19s/step - loss: 8.7454 - acc: 0.1070 - val_loss: 8.2919 - val_acc: 0.1362\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.14286\n",
      "Epoch 5/100\n",
      "231/231 [==============================] - 4437s 19s/step - loss: 8.1375 - acc: 0.1511 - val_loss: 7.7205 - val_acc: 0.2054\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.14286 to 0.20536, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 6/100\n",
      "231/231 [==============================] - 4435s 19s/step - loss: 7.5852 - acc: 0.1688 - val_loss: 7.1942 - val_acc: 0.2321\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.20536 to 0.23214, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 7/100\n",
      "231/231 [==============================] - 4436s 19s/step - loss: 7.1032 - acc: 0.1847 - val_loss: 6.7860 - val_acc: 0.2254\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.23214\n",
      "Epoch 8/100\n",
      "231/231 [==============================] - 4433s 19s/step - loss: 6.6904 - acc: 0.1913 - val_loss: 6.4479 - val_acc: 0.2254\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.23214\n",
      "Epoch 9/100\n",
      "231/231 [==============================] - 4435s 19s/step - loss: 6.2659 - acc: 0.2090 - val_loss: 6.0329 - val_acc: 0.2165\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.23214\n",
      "Epoch 10/100\n",
      "231/231 [==============================] - 4438s 19s/step - loss: 5.9040 - acc: 0.2248 - val_loss: 5.6619 - val_acc: 0.2835\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.23214 to 0.28348, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 11/100\n",
      "231/231 [==============================] - 4442s 19s/step - loss: 5.6168 - acc: 0.2223 - val_loss: 5.2232 - val_acc: 0.3281\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.28348 to 0.32812, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 12/100\n",
      "231/231 [==============================] - 4445s 19s/step - loss: 5.2896 - acc: 0.2396 - val_loss: 5.0713 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.32812\n",
      "Epoch 13/100\n",
      "231/231 [==============================] - 4435s 19s/step - loss: 5.0006 - acc: 0.2550 - val_loss: 4.7616 - val_acc: 0.2545\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.32812\n",
      "Epoch 14/100\n",
      "231/231 [==============================] - 4431s 19s/step - loss: 4.7558 - acc: 0.2765 - val_loss: 4.4873 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.32812\n",
      "Epoch 15/100\n",
      "231/231 [==============================] - 4420s 19s/step - loss: 4.5387 - acc: 0.2729 - val_loss: 4.3654 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.32812\n",
      "Epoch 16/100\n",
      "231/231 [==============================] - 4418s 19s/step - loss: 4.3593 - acc: 0.2861 - val_loss: 4.0573 - val_acc: 0.3326\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.32812 to 0.33259, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 17/100\n",
      "231/231 [==============================] - 4424s 19s/step - loss: 4.1638 - acc: 0.2995 - val_loss: 4.0872 - val_acc: 0.3192\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.33259\n",
      "Epoch 18/100\n",
      "231/231 [==============================] - 4420s 19s/step - loss: 3.9894 - acc: 0.3044 - val_loss: 3.7108 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.33259 to 0.36384, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 19/100\n",
      "231/231 [==============================] - 4418s 19s/step - loss: 3.8578 - acc: 0.3029 - val_loss: 3.5313 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.36384 to 0.38839, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 20/100\n",
      "231/231 [==============================] - 4421s 19s/step - loss: 3.6813 - acc: 0.3293 - val_loss: 3.4511 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.38839\n",
      "Epoch 21/100\n",
      "231/231 [==============================] - 4422s 19s/step - loss: 3.5548 - acc: 0.3386 - val_loss: 3.3941 - val_acc: 0.3906\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.38839 to 0.39062, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 22/100\n",
      "231/231 [==============================] - 4431s 19s/step - loss: 3.4161 - acc: 0.3439 - val_loss: 3.2893 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.39062 to 0.41071, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 23/100\n",
      "231/231 [==============================] - 4437s 19s/step - loss: 3.3535 - acc: 0.3511 - val_loss: 3.2151 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.41071\n",
      "Epoch 24/100\n",
      "231/231 [==============================] - 4439s 19s/step - loss: 3.2505 - acc: 0.3589 - val_loss: 3.0740 - val_acc: 0.3817\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.41071\n",
      "Epoch 25/100\n",
      "231/231 [==============================] - 4435s 19s/step - loss: 3.1721 - acc: 0.3632 - val_loss: 3.1091 - val_acc: 0.3817\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.41071\n",
      "Epoch 26/100\n",
      "231/231 [==============================] - 4444s 19s/step - loss: 3.0994 - acc: 0.3592 - val_loss: 2.9509 - val_acc: 0.4219\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.41071 to 0.42188, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 27/100\n",
      "231/231 [==============================] - 4448s 19s/step - loss: 3.0018 - acc: 0.3720 - val_loss: 2.9094 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.42188\n",
      "Epoch 28/100\n",
      "231/231 [==============================] - 4403s 19s/step - loss: 2.9794 - acc: 0.3746 - val_loss: 2.8795 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.42188 to 0.43750, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 29/100\n",
      "231/231 [==============================] - 4394s 19s/step - loss: 2.8844 - acc: 0.3960 - val_loss: 2.6945 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.43750\n",
      "Epoch 30/100\n",
      "231/231 [==============================] - 4394s 19s/step - loss: 2.8737 - acc: 0.3923 - val_loss: 2.6803 - val_acc: 0.4330\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.43750\n",
      "Epoch 31/100\n",
      "231/231 [==============================] - 4394s 19s/step - loss: 2.7978 - acc: 0.3957 - val_loss: 2.5814 - val_acc: 0.4665\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.43750 to 0.46652, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 32/100\n",
      "231/231 [==============================] - 4408s 19s/step - loss: 2.7544 - acc: 0.4042 - val_loss: 2.5888 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.46652 to 0.49330, saving model to E:\\Jupyter\\Project\\save_model\\30%\n",
      "Epoch 33/100\n",
      "231/231 [==============================] - 4396s 19s/step - loss: 2.7290 - acc: 0.4037 - val_loss: 2.4829 - val_acc: 0.4911\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.49330\n",
      "Epoch 34/100\n",
      "  1/231 [..............................] - ETA: 1:17:14 - loss: 2.3628 - acc: 0.4688"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(32*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"30%\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "X_tr=[]           # variable to store entire dataset\n",
    "label=[]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "ls_path = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled\")\n",
    "\n",
    "for vid_ID in tqdm(validation[\"Video\"].tolist()[0:2000]):\n",
    "    frames = []\n",
    "    frame_count=0\n",
    "    pos_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    neg_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    for img_ID in sorted(os.listdir(pos_dir)):\n",
    "        if frame_count < nb_frames:\n",
    "            pos = os.path.join(pos_dir,img_ID)\n",
    "            neg = os.path.join(neg_dir,img_ID)\n",
    "            p_img = cv2.imread(pos,0)\n",
    "            p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            n_img = cv2.imread(neg,0)\n",
    "            n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.merge((p_img,n_img))\n",
    "            frames.append(frame)\n",
    "            frame_count+=1\n",
    "        else:\n",
    "            break\n",
    "    while frame_count < nb_frames:\n",
    "        frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "        frame_count+=1\n",
    "    input_img = np.array(frames)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    X_tr.append(ipt)\n",
    "    label.append(labels_dict[vid_ID])\n",
    "\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr) \n",
    "print (num_samples)\n",
    "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "train_data = [X_tr_array,label]\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "train_set = np.zeros((num_samples, nb_frames, img_cols,img_rows,2))\n",
    "for h in range(num_samples):\n",
    "    train_set[h][:][:][:][:]=X_train[h,:,:,:]\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =model1.predict(train_set[50:70])\n",
    "result = np.argmax(test_pred, axis =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = train_set[50]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "met = confusion_matrix(np.argmax(Y_train,axis =1), np.argmax(model1.predict(train_set),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, range(27), rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(met, classes=labels.sort_values(by=['Label'])['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.sort_values(by=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(train_set,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
