{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=100,176\n",
    "nb_frames = 64    # img_depth or number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def data_gen(train_list, batch_size=64):\n",
    "    while True:\n",
    "        current_vid=0\n",
    "        X_tr_array = np.zeros([batch_size,nb_frames,img_cols,img_rows,channels])\n",
    "        Y_train = np.zeros([batch_size, nb_classes])\n",
    "        for vid_ID in random.sample(train_list,batch_size):\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                pos = os.path.join(pos_dir,img_ID)\n",
    "                neg = os.path.join(neg_dir,img_ID)\n",
    "                p_img = cv2.imread(pos,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,0]=p_img\n",
    "                n_img = cv2.imread(neg,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,1]=n_img\n",
    "                #frame = cv2.merge((p_img,n_img))\n",
    "                #X_tr_array[current_vid,frame_count]=frame\n",
    "                frame_count+=1\n",
    "            Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "            current_vid+=1\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "import tensorflow as tf\n",
    "keras=tf.contrib.keras\n",
    "l2=keras.regularizers.l2\n",
    "weight_decay = 0.00005\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(nb_frames,  img_cols, img_rows, channels)))\n",
    "\n",
    "model.add(Conv3D(16,(1,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_1'))\n",
    "model.add(Conv3D(16,(1,3,3),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_12'))\n",
    "model.add(Conv3D(16,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_13'))\n",
    "model.add(Conv3D(16,(5,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_1'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), name='MaxPool_1'))\n",
    "\n",
    "model.add(Conv3D(64,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_2'))\n",
    "model.add(Conv3D(64,(1,3,3), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_22'))\n",
    "model.add(Conv3D(64,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_23'))\n",
    "model.add(Conv3D(64,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_2'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 3), name='MaxPool_2'))\n",
    "\n",
    "model.add(Conv3D(128,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_3'))\n",
    "model.add(Conv3D(128,(1,3,3), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_32'))\n",
    "model.add(Conv3D(128,(1,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_spatial_33'))\n",
    "model.add(Conv3D(128,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='Conv_temporal_3'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 2), name='MaxPool_3'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_1'))\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_2'))\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(3,3),\n",
    "                     strides=(1,1),padding='same',\n",
    "                     kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                     return_sequences=True, name='LSTM_3'))\n",
    "\n",
    "model.add(Flatten(name='Flatten'))\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='FC_1'))\n",
    "model.add(Dropout(0.5, name='Dropout_1'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay), name='FC_2'))\n",
    "model.add(Dropout(0.5, name='Dropout_2'))\n",
    "\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay), name='FC_3'))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling3d_1 (MaxPooling3 (None, 64, 50, 88, 2)     0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_1 (Conv3D)      (None, 64, 46, 84, 16)    816       \n",
      "_________________________________________________________________\n",
      "Conv_spatial_12 (Conv3D)     (None, 64, 44, 82, 16)    2320      \n",
      "_________________________________________________________________\n",
      "Conv_spatial_13 (Conv3D)     (None, 64, 44, 82, 16)    272       \n",
      "_________________________________________________________________\n",
      "Conv_temporal_1 (Conv3D)     (None, 60, 44, 82, 16)    1296      \n",
      "_________________________________________________________________\n",
      "MaxPool_1 (MaxPooling3D)     (None, 60, 22, 41, 16)    0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_2 (Conv3D)      (None, 60, 18, 37, 64)    25664     \n",
      "_________________________________________________________________\n",
      "Conv_spatial_22 (Conv3D)     (None, 60, 16, 35, 64)    36928     \n",
      "_________________________________________________________________\n",
      "Conv_spatial_23 (Conv3D)     (None, 60, 16, 35, 64)    4160      \n",
      "_________________________________________________________________\n",
      "Conv_temporal_2 (Conv3D)     (None, 58, 16, 35, 64)    12352     \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling3D)     (None, 58, 8, 11, 64)     0         \n",
      "_________________________________________________________________\n",
      "Conv_spatial_3 (Conv3D)      (None, 58, 4, 7, 128)     204928    \n",
      "_________________________________________________________________\n",
      "Conv_spatial_32 (Conv3D)     (None, 58, 2, 5, 128)     147584    \n",
      "_________________________________________________________________\n",
      "Conv_spatial_33 (Conv3D)     (None, 58, 2, 5, 128)     16512     \n",
      "_________________________________________________________________\n",
      "Conv_temporal_3 (Conv3D)     (None, 56, 2, 5, 128)     49280     \n",
      "_________________________________________________________________\n",
      "MaxPool_3 (MaxPooling3D)     (None, 56, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "LSTM_1 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "LSTM_2 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "LSTM_3 (ConvLSTM2D)          (None, 56, 2, 2, 128)     1180160   \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 28672)             0         \n",
      "_________________________________________________________________\n",
      "FC_1 (Dense)                 (None, 512)               14680576  \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FC_2 (Dense)                 (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "FC_3 (Dense)                 (None, 27)                6939      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 18,861,435\n",
      "Trainable params: 18,861,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"deeper_full\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.002,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "463/463 [==============================] - 1015s 2s/step - loss: 3.6631 - acc: 0.0796 - val_loss: 3.5093 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15461, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 2/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 3.4312 - acc: 0.1355 - val_loss: 3.1973 - val_acc: 0.2094\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.15461 to 0.20943, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 3/60\n",
      "463/463 [==============================] - 1016s 2s/step - loss: 3.2347 - acc: 0.1718 - val_loss: 3.0687 - val_acc: 0.2149\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.20943 to 0.21491, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 4/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 3.1098 - acc: 0.2007 - val_loss: 3.0878 - val_acc: 0.2116\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.21491\n",
      "Epoch 5/60\n",
      "463/463 [==============================] - 1011s 2s/step - loss: 3.0552 - acc: 0.2086 - val_loss: 2.9210 - val_acc: 0.2851\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.21491 to 0.28509, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 6/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 2.9754 - acc: 0.2241 - val_loss: 2.7600 - val_acc: 0.2796\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.28509\n",
      "Epoch 7/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 2.9392 - acc: 0.2252 - val_loss: 2.8622 - val_acc: 0.2566\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.28509\n",
      "Epoch 8/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 2.8339 - acc: 0.2570 - val_loss: 2.7563 - val_acc: 0.2719\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.28509\n",
      "Epoch 9/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 2.8147 - acc: 0.2647 - val_loss: 2.7035 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.28509 to 0.29276, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 10/60\n",
      "463/463 [==============================] - 1018s 2s/step - loss: 2.7919 - acc: 0.2644 - val_loss: 2.6792 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.29276 to 0.30044, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 11/60\n",
      "463/463 [==============================] - 1019s 2s/step - loss: 2.7067 - acc: 0.2964 - val_loss: 2.5502 - val_acc: 0.3202\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.30044 to 0.32018, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 12/60\n",
      "463/463 [==============================] - 1010s 2s/step - loss: 2.6927 - acc: 0.3004 - val_loss: 2.4275 - val_acc: 0.3596\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.32018 to 0.35965, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 13/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 2.6021 - acc: 0.3049 - val_loss: 2.4306 - val_acc: 0.3607\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.35965 to 0.36075, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 14/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 2.5678 - acc: 0.3176 - val_loss: 2.5183 - val_acc: 0.3520\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.36075\n",
      "Epoch 15/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 2.5457 - acc: 0.3302 - val_loss: 2.3336 - val_acc: 0.3761\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.36075 to 0.37610, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 16/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.5504 - acc: 0.3390 - val_loss: 2.4204 - val_acc: 0.3739\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.37610\n",
      "Epoch 17/60\n",
      "463/463 [==============================] - 996s 2s/step - loss: 2.4930 - acc: 0.3408 - val_loss: 2.4724 - val_acc: 0.3476\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.37610\n",
      "Epoch 18/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 2.4948 - acc: 0.3527 - val_loss: 2.3212 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.37610 to 0.41667, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 19/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 2.4501 - acc: 0.3688 - val_loss: 2.2829 - val_acc: 0.4134\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.41667\n",
      "Epoch 20/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.4125 - acc: 0.3662 - val_loss: 2.3293 - val_acc: 0.3827\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.41667\n",
      "Epoch 21/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 2.3999 - acc: 0.3773 - val_loss: 2.2757 - val_acc: 0.3925\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.41667\n",
      "Epoch 22/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 2.3411 - acc: 0.3870 - val_loss: 2.2833 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.41667\n",
      "Epoch 23/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 2.3672 - acc: 0.3834 - val_loss: 2.1800 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.41667 to 0.43531, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 24/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 2.3428 - acc: 0.3939 - val_loss: 2.1378 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.43531 to 0.46930, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 25/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 2.3122 - acc: 0.3959 - val_loss: 2.1429 - val_acc: 0.4550\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.46930\n",
      "Epoch 26/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.2538 - acc: 0.4143 - val_loss: 2.2575 - val_acc: 0.4211\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.46930\n",
      "Epoch 27/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 2.2430 - acc: 0.4201 - val_loss: 2.1336 - val_acc: 0.4298\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.46930\n",
      "Epoch 28/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 2.2035 - acc: 0.4281 - val_loss: 2.1290 - val_acc: 0.4364\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.46930\n",
      "Epoch 29/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 2.1921 - acc: 0.4393 - val_loss: 2.2003 - val_acc: 0.4485\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.46930\n",
      "Epoch 30/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 2.1633 - acc: 0.4502 - val_loss: 2.2158 - val_acc: 0.4309\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.46930\n",
      "Epoch 31/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 2.1667 - acc: 0.4406 - val_loss: 2.1043 - val_acc: 0.4594\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.46930\n",
      "Epoch 32/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 2.1204 - acc: 0.4545 - val_loss: 2.0848 - val_acc: 0.4726\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.46930 to 0.47259, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 33/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 2.1173 - acc: 0.4559 - val_loss: 2.0719 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.47259\n",
      "Epoch 34/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 2.0905 - acc: 0.4681 - val_loss: 2.0157 - val_acc: 0.4803\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.47259 to 0.48026, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 35/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 2.0854 - acc: 0.4681 - val_loss: 2.0478 - val_acc: 0.4781\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.48026\n",
      "Epoch 36/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.0813 - acc: 0.4680 - val_loss: 1.9609 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.48026 to 0.50329, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 37/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 2.0640 - acc: 0.4862 - val_loss: 1.9183 - val_acc: 0.5351\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.50329 to 0.53509, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 38/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 2.0498 - acc: 0.4823 - val_loss: 2.0008 - val_acc: 0.5022\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.53509\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1004s 2s/step - loss: 2.0244 - acc: 0.4825 - val_loss: 1.9782 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.53509\n",
      "Epoch 40/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.0200 - acc: 0.4949 - val_loss: 2.0592 - val_acc: 0.4923\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.53509\n",
      "Epoch 41/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.0212 - acc: 0.4889 - val_loss: 1.9436 - val_acc: 0.5011\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.53509\n",
      "Epoch 42/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 2.0008 - acc: 0.5023 - val_loss: 1.8334 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.53509 to 0.55702, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 43/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 1.9659 - acc: 0.5101 - val_loss: 1.8112 - val_acc: 0.5373\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.55702\n",
      "Epoch 44/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.9425 - acc: 0.5171 - val_loss: 1.8528 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.55702\n",
      "Epoch 45/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.9319 - acc: 0.5200 - val_loss: 1.8998 - val_acc: 0.5208\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.55702\n",
      "Epoch 46/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.9161 - acc: 0.5239 - val_loss: 1.8330 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.55702\n",
      "Epoch 47/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.9277 - acc: 0.5244 - val_loss: 2.0145 - val_acc: 0.5230\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.55702\n",
      "Epoch 48/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.8895 - acc: 0.5396 - val_loss: 1.7981 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.55702\n",
      "Epoch 49/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.9064 - acc: 0.5235 - val_loss: 1.8273 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.55702 to 0.57895, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 50/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.9030 - acc: 0.5304 - val_loss: 1.8664 - val_acc: 0.5614\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.57895\n",
      "Epoch 51/60\n",
      "463/463 [==============================] - 1011s 2s/step - loss: 1.8473 - acc: 0.5391 - val_loss: 1.7555 - val_acc: 0.5779\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.57895\n",
      "Epoch 52/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.8534 - acc: 0.5463 - val_loss: 1.7473 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.57895 to 0.59101, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 53/60\n",
      "463/463 [==============================] - 1012s 2s/step - loss: 1.8380 - acc: 0.5470 - val_loss: 1.7477 - val_acc: 0.5702\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.59101\n",
      "Epoch 54/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.8361 - acc: 0.5467 - val_loss: 1.8278 - val_acc: 0.5746\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.59101\n",
      "Epoch 55/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.8253 - acc: 0.5594 - val_loss: 1.8225 - val_acc: 0.5482\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.59101\n",
      "Epoch 56/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.7780 - acc: 0.5624 - val_loss: 1.7541 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.59101\n",
      "Epoch 57/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.8206 - acc: 0.5475 - val_loss: 1.7130 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.59101\n",
      "Epoch 58/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.7815 - acc: 0.5715 - val_loss: 1.7098 - val_acc: 0.5987\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.59101 to 0.59868, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 59/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.7642 - acc: 0.5719 - val_loss: 1.7749 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.59868 to 0.60417, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 60/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.7656 - acc: 0.5791 - val_loss: 1.6990 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.60417\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=7, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"for entry in hist1.history['loss']:\n",
    "    training_loss.append(entry)\n",
    "for entry in hist1.history['val_loss']:\n",
    "    val_loss.append(entry)\n",
    "for entry in hist1.history['acc']:\n",
    "    training_acc.append(entry)\n",
    "for entry in hist1.history['val_acc']:\n",
    "    val_acc.append(entry)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"with open('deeploss_tr.pkl','rb') as fid:\\n    training_loss = pickle.load(fid)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "with open('E:/Jupyter/Project/save_model/deeperloss_tr.pkl','wb') as fid:\n",
    "    pickle.dump(training_loss, fid)\n",
    "with open('E:/Jupyter/Project/save_model/deeperloss_val.pkl','wb') as fid:\n",
    "    pickle.dump(val_loss, fid)\n",
    "\"\"\"with open('deeploss_tr.pkl','rb') as fid:\n",
    "    training_loss = pickle.load(fid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "with open('E:/Jupyter/Project/save_model/deeperacc_tr.pkl','wb') as fid:\n",
    "    pickle.dump(training_acc, fid)\n",
    "with open('E:/Jupyter/Project/save_model/deeperacc_val.pkl','wb') as fid:\n",
    "    pickle.dump(val_acc, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(16*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6988016678528353, 0.6007169913419913]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.7488 - acc: 0.5726 - val_loss: 1.6464 - val_acc: 0.6096\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.60417 to 0.60965, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 2/60\n",
      "463/463 [==============================] - 997s 2s/step - loss: 1.7204 - acc: 0.5844 - val_loss: 1.6761 - val_acc: 0.6064\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.60965\n",
      "Epoch 3/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.7564 - acc: 0.5764 - val_loss: 1.6500 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.60965\n",
      "Epoch 4/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.7589 - acc: 0.5749 - val_loss: 1.6562 - val_acc: 0.6140\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.60965 to 0.61404, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 5/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.7121 - acc: 0.5933 - val_loss: 1.6988 - val_acc: 0.5932\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61404\n",
      "Epoch 6/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.7401 - acc: 0.5907 - val_loss: 1.6748 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.61404 to 0.61732, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 7/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.7128 - acc: 0.5929 - val_loss: 1.6250 - val_acc: 0.6118\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61732\n",
      "Epoch 8/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.7403 - acc: 0.5857 - val_loss: 1.5553 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61732\n",
      "Epoch 9/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.7165 - acc: 0.5929 - val_loss: 1.7460 - val_acc: 0.5877\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61732\n",
      "Epoch 10/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.6778 - acc: 0.5934 - val_loss: 1.6927 - val_acc: 0.5866\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61732\n",
      "Epoch 11/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.6653 - acc: 0.6114 - val_loss: 1.5445 - val_acc: 0.6360\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.61732 to 0.63596, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 12/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.6620 - acc: 0.6089 - val_loss: 1.6074 - val_acc: 0.6382\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.63596 to 0.63816, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 13/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.6868 - acc: 0.5999 - val_loss: 1.7645 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.63816\n",
      "Epoch 14/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.6491 - acc: 0.6154 - val_loss: 1.6304 - val_acc: 0.6360\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.63816\n",
      "Epoch 15/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.6728 - acc: 0.6180 - val_loss: 1.7208 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.63816\n",
      "Epoch 16/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 1.5900 - acc: 0.6254 - val_loss: 1.7457 - val_acc: 0.5954\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63816\n",
      "Epoch 17/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.6402 - acc: 0.6161 - val_loss: 1.5553 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.63816 to 0.64364, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 18/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.6188 - acc: 0.6263 - val_loss: 1.6291 - val_acc: 0.6195\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.64364\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 19/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.5143 - acc: 0.6493 - val_loss: 1.5803 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.64364 to 0.65241, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 20/60\n",
      "463/463 [==============================] - 997s 2s/step - loss: 1.4730 - acc: 0.6687 - val_loss: 1.5225 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.65241\n",
      "Epoch 21/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.4365 - acc: 0.6778 - val_loss: 1.5384 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.65241 to 0.65351, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 22/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.4320 - acc: 0.6786 - val_loss: 1.4422 - val_acc: 0.6612\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.65351 to 0.66118, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 23/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.4324 - acc: 0.6751 - val_loss: 1.4982 - val_acc: 0.6546\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.66118\n",
      "Epoch 24/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.4085 - acc: 0.6872 - val_loss: 1.4770 - val_acc: 0.6908\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.66118 to 0.69079, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 25/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.3932 - acc: 0.6920 - val_loss: 1.4411 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.69079\n",
      "Epoch 26/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.3970 - acc: 0.6942 - val_loss: 1.3639 - val_acc: 0.7039\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.69079 to 0.70395, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 27/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.4171 - acc: 0.6864 - val_loss: 1.3692 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.70395 to 0.72039, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 28/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.3829 - acc: 0.6951 - val_loss: 1.3838 - val_acc: 0.6864\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.72039\n",
      "Epoch 29/60\n",
      "463/463 [==============================] - 996s 2s/step - loss: 1.4009 - acc: 0.6910 - val_loss: 1.4262 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72039\n",
      "Epoch 30/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.3542 - acc: 0.7003 - val_loss: 1.4125 - val_acc: 0.7039\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72039\n",
      "Epoch 31/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.3716 - acc: 0.6971 - val_loss: 1.4483 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.72039\n",
      "Epoch 32/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.3677 - acc: 0.7055 - val_loss: 1.4373 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.72039\n",
      "Epoch 33/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.3491 - acc: 0.7022 - val_loss: 1.4336 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.72039\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 34/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.3685 - acc: 0.6972 - val_loss: 1.4729 - val_acc: 0.6743\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.72039\n",
      "Epoch 35/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.3249 - acc: 0.7110 - val_loss: 1.4004 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.72039\n",
      "Epoch 36/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.3545 - acc: 0.7082 - val_loss: 1.4089 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.72039\n",
      "Epoch 37/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.3458 - acc: 0.7079 - val_loss: 1.3803 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.72039\n",
      "Epoch 38/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.3015 - acc: 0.7244 - val_loss: 1.3079 - val_acc: 0.7138\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.72039\n",
      "Epoch 39/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.3103 - acc: 0.7196 - val_loss: 1.4424 - val_acc: 0.6776\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.72039\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1001s 2s/step - loss: 1.3199 - acc: 0.7229 - val_loss: 1.4829 - val_acc: 0.6689\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.72039\n",
      "Epoch 41/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.3044 - acc: 0.7191 - val_loss: 1.4133 - val_acc: 0.6886\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.72039\n",
      "Epoch 42/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 1.2908 - acc: 0.7218 - val_loss: 1.3795 - val_acc: 0.7138\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.72039\n",
      "Epoch 43/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.2980 - acc: 0.7208 - val_loss: 1.3367 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.72039\n",
      "Epoch 44/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.2890 - acc: 0.7229 - val_loss: 1.4523 - val_acc: 0.6930\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.72039\n",
      "Epoch 45/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 1.2720 - acc: 0.7280 - val_loss: 1.4814 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.72039\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 46/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.2874 - acc: 0.7242 - val_loss: 1.2822 - val_acc: 0.7094\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.72039\n",
      "Epoch 47/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.3031 - acc: 0.7202 - val_loss: 1.3936 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.72039\n",
      "Epoch 48/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.2496 - acc: 0.7347 - val_loss: 1.3082 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.72039 to 0.72368, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 49/60\n",
      "463/463 [==============================] - 997s 2s/step - loss: 1.2931 - acc: 0.7256 - val_loss: 1.4374 - val_acc: 0.6798\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.72368\n",
      "Epoch 50/60\n",
      "463/463 [==============================] - 995s 2s/step - loss: 1.2600 - acc: 0.7365 - val_loss: 1.4291 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.72368\n",
      "Epoch 51/60\n",
      "463/463 [==============================] - 992s 2s/step - loss: 1.2758 - acc: 0.7249 - val_loss: 1.3752 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.72368\n",
      "Epoch 52/60\n",
      "463/463 [==============================] - 993s 2s/step - loss: 1.2554 - acc: 0.7314 - val_loss: 1.4284 - val_acc: 0.6919\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.72368\n",
      "Epoch 53/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.2555 - acc: 0.7349 - val_loss: 1.4515 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.72368\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 54/60\n",
      "463/463 [==============================] - 993s 2s/step - loss: 1.2588 - acc: 0.7299 - val_loss: 1.4493 - val_acc: 0.6820\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.72368\n",
      "Epoch 55/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.2409 - acc: 0.7439 - val_loss: 1.3480 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.72368\n",
      "Epoch 56/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.2412 - acc: 0.7396 - val_loss: 1.2693 - val_acc: 0.7314\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.72368 to 0.73136, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 57/60\n",
      "463/463 [==============================] - 993s 2s/step - loss: 1.2208 - acc: 0.7516 - val_loss: 1.3961 - val_acc: 0.6743\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.73136\n",
      "Epoch 58/60\n",
      "463/463 [==============================] - 997s 2s/step - loss: 1.2284 - acc: 0.7387 - val_loss: 1.3487 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.73136\n",
      "Epoch 59/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.2568 - acc: 0.7303 - val_loss: 1.3438 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.73136\n",
      "Epoch 60/60\n",
      "463/463 [==============================] - 996s 2s/step - loss: 1.2379 - acc: 0.7418 - val_loss: 1.3005 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.73136\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=7, min_lr=0.005/(2^4),verbose=1)\n",
    "hist1 = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3309132341752972, 0.7269736842105263]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(16*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3423013119470506, 0.7129329004329005]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.2270 - acc: 0.7453 - val_loss: 1.3761 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.73136\n",
      "Epoch 2/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.2265 - acc: 0.7420 - val_loss: 1.3731 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73136\n",
      "Epoch 3/60\n",
      "463/463 [==============================] - 995s 2s/step - loss: 1.2242 - acc: 0.7447 - val_loss: 1.3717 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73136\n",
      "Epoch 4/60\n",
      "463/463 [==============================] - 993s 2s/step - loss: 1.2107 - acc: 0.7507 - val_loss: 1.3532 - val_acc: 0.7007\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73136\n",
      "Epoch 5/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.2304 - acc: 0.7416 - val_loss: 1.4110 - val_acc: 0.6820\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73136\n",
      "Epoch 6/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.2469 - acc: 0.7410 - val_loss: 1.4260 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73136\n",
      "Epoch 7/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.1954 - acc: 0.7553 - val_loss: 1.3325 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73136\n",
      "Epoch 8/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.2132 - acc: 0.7480 - val_loss: 1.2633 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73136\n",
      "Epoch 9/60\n",
      "463/463 [==============================] - 996s 2s/step - loss: 1.2014 - acc: 0.7501 - val_loss: 1.3566 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73136\n",
      "Epoch 10/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.2215 - acc: 0.7415 - val_loss: 1.3542 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.73136\n",
      "Epoch 11/60\n",
      "463/463 [==============================] - 1002s 2s/step - loss: 1.2010 - acc: 0.7513 - val_loss: 1.2880 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.73136\n",
      "Epoch 12/60\n",
      "463/463 [==============================] - 1014s 2s/step - loss: 1.2308 - acc: 0.7420 - val_loss: 1.3289 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.73136\n",
      "Epoch 13/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.2106 - acc: 0.7450 - val_loss: 1.4019 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.73136\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 5.833333474583924e-05.\n",
      "Epoch 14/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.1628 - acc: 0.7559 - val_loss: 1.3357 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.73136 to 0.73794, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 15/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.1500 - acc: 0.7736 - val_loss: 1.2574 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.73794\n",
      "Epoch 16/60\n",
      "463/463 [==============================] - 1013s 2s/step - loss: 1.1108 - acc: 0.7756 - val_loss: 1.2612 - val_acc: 0.7248\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.73794\n",
      "Epoch 17/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.1101 - acc: 0.7770 - val_loss: 1.3348 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.73794\n",
      "Epoch 18/60\n",
      "463/463 [==============================] - 1005s 2s/step - loss: 1.0733 - acc: 0.7886 - val_loss: 1.1887 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.73794 to 0.77632, saving model to E:\\Jupyter\\Project\\save_model\\deeper_full\n",
      "Epoch 19/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0618 - acc: 0.7921 - val_loss: 1.2726 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.77632\n",
      "Epoch 20/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0778 - acc: 0.7896 - val_loss: 1.2769 - val_acc: 0.7314\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.77632\n",
      "Epoch 21/60\n",
      "463/463 [==============================] - 1011s 2s/step - loss: 1.0690 - acc: 0.7875 - val_loss: 1.2462 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.77632\n",
      "Epoch 22/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0841 - acc: 0.7863 - val_loss: 1.2534 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.77632\n",
      "Epoch 23/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.0499 - acc: 0.7918 - val_loss: 1.2484 - val_acc: 0.7401\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.77632\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.083333442395088e-06.\n",
      "Epoch 24/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.0685 - acc: 0.7925 - val_loss: 1.2774 - val_acc: 0.7336\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.77632\n",
      "Epoch 25/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0632 - acc: 0.7948 - val_loss: 1.2925 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.77632\n",
      "Epoch 26/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0663 - acc: 0.7954 - val_loss: 1.3153 - val_acc: 0.7182\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.77632\n",
      "Epoch 27/60\n",
      "463/463 [==============================] - 1010s 2s/step - loss: 1.0610 - acc: 0.7950 - val_loss: 1.2760 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.77632\n",
      "Epoch 28/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.0443 - acc: 0.8020 - val_loss: 1.3141 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.77632\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.3333333333333337e-06.\n",
      "Epoch 29/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0873 - acc: 0.7900 - val_loss: 1.2803 - val_acc: 0.7314\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.77632\n",
      "Epoch 30/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0717 - acc: 0.7906 - val_loss: 1.3308 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.77632\n",
      "Epoch 31/60\n",
      "463/463 [==============================] - 1011s 2s/step - loss: 1.0575 - acc: 0.7981 - val_loss: 1.2765 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.77632\n",
      "Epoch 32/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0666 - acc: 0.7947 - val_loss: 1.2104 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77632\n",
      "Epoch 33/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0416 - acc: 0.7991 - val_loss: 1.1885 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77632\n",
      "Epoch 34/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0556 - acc: 0.7979 - val_loss: 1.2992 - val_acc: 0.7182\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77632\n",
      "Epoch 35/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.0484 - acc: 0.8008 - val_loss: 1.1716 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77632\n",
      "Epoch 36/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0537 - acc: 0.7948 - val_loss: 1.3630 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.77632\n",
      "Epoch 37/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0782 - acc: 0.7901 - val_loss: 1.1877 - val_acc: 0.7577\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.77632\n",
      "Epoch 38/60\n",
      "463/463 [==============================] - 1007s 2s/step - loss: 1.0669 - acc: 0.7869 - val_loss: 1.2172 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.77632\n",
      "Epoch 39/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0426 - acc: 0.7975 - val_loss: 1.2466 - val_acc: 0.7248\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.77632\n",
      "Epoch 40/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0658 - acc: 0.7977 - val_loss: 1.2997 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.77632\n",
      "Epoch 41/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.0520 - acc: 0.7943 - val_loss: 1.2367 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.77632\n",
      "Epoch 42/60\n",
      "463/463 [==============================] - 1012s 2s/step - loss: 1.0466 - acc: 0.7981 - val_loss: 1.1944 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.77632\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1008s 2s/step - loss: 1.0666 - acc: 0.7913 - val_loss: 1.2295 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.77632\n",
      "Epoch 44/60\n",
      "463/463 [==============================] - 1006s 2s/step - loss: 1.0651 - acc: 0.7939 - val_loss: 1.2900 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.77632\n",
      "Epoch 45/60\n",
      "463/463 [==============================] - 1016s 2s/step - loss: 1.0741 - acc: 0.7921 - val_loss: 1.2970 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.77632\n",
      "Epoch 46/60\n",
      "463/463 [==============================] - 997s 2s/step - loss: 1.0589 - acc: 0.7924 - val_loss: 1.2449 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.77632\n",
      "Epoch 47/60\n",
      "463/463 [==============================] - 1008s 2s/step - loss: 1.0579 - acc: 0.7952 - val_loss: 1.3423 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.77632\n",
      "Epoch 48/60\n",
      "463/463 [==============================] - 1004s 2s/step - loss: 1.0891 - acc: 0.7904 - val_loss: 1.2040 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.77632\n",
      "Epoch 49/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.0675 - acc: 0.7874 - val_loss: 1.2770 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.77632\n",
      "Epoch 50/60\n",
      "463/463 [==============================] - 999s 2s/step - loss: 1.0837 - acc: 0.7878 - val_loss: 1.3185 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.77632\n",
      "Epoch 51/60\n",
      "463/463 [==============================] - 996s 2s/step - loss: 1.0491 - acc: 0.7979 - val_loss: 1.2971 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.77632\n",
      "Epoch 52/60\n",
      "463/463 [==============================] - 998s 2s/step - loss: 1.0456 - acc: 0.7944 - val_loss: 1.2382 - val_acc: 0.7336\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.77632\n",
      "Epoch 53/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.0280 - acc: 0.8044 - val_loss: 1.1952 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.77632\n",
      "Epoch 54/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.0429 - acc: 0.7987 - val_loss: 1.1574 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.77632\n",
      "Epoch 55/60\n",
      "463/463 [==============================] - 1001s 2s/step - loss: 1.0631 - acc: 0.7966 - val_loss: 1.2396 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.77632\n",
      "Epoch 56/60\n",
      "463/463 [==============================] - 1003s 2s/step - loss: 1.0620 - acc: 0.7913 - val_loss: 1.1718 - val_acc: 0.7511\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.77632\n",
      "Epoch 57/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0594 - acc: 0.7950 - val_loss: 1.3094 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.77632\n",
      "Epoch 58/60\n",
      "463/463 [==============================] - 1009s 2s/step - loss: 1.0572 - acc: 0.7982 - val_loss: 1.3608 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.77632\n",
      "Epoch 59/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.0497 - acc: 0.7914 - val_loss: 1.2278 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.77632\n",
      "Epoch 60/60\n",
      "463/463 [==============================] - 1000s 2s/step - loss: 1.0412 - acc: 0.8028 - val_loss: 1.2408 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.77632\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 60\n",
    "batch_size = 16\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.07, \n",
    "                               cooldown=0, patience=5, min_lr=0.00002/(2^4),verbose=1)\n",
    "hist2 = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                           steps_per_epoch=len(train[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           validation_steps=len(validation[\"Video\"].tolist()[0:])//(16*batch_size),\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2417231451123307, 0.7410037878787878]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(data_gen(validation[\"Video\"].tolist()[0:],batch_size),\n",
    "                         len(validation[\"Video\"].tolist()[0:])//(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, save_model\n",
    "model1_name = \"deeper_full\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "save_model(model,model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"deeper_full\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_predict_gen(train_list, niter, batch_size=64):\n",
    "    while True:\n",
    "        current_vid=0\n",
    "        X_tr_array = np.zeros([batch_size,nb_frames,img_cols,img_rows,channels])\n",
    "        Y_train = np.zeros([batch_size, nb_classes])\n",
    "        for vid_ID in train_list[niter*batch_size:(niter+1)*batch_size]:\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                pos = os.path.join(pos_dir,img_ID)\n",
    "                neg = os.path.join(neg_dir,img_ID)\n",
    "                p_img = cv2.imread(pos,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,0]=p_img\n",
    "                n_img = cv2.imread(neg,0)\n",
    "                X_tr_array[current_vid,frame_count,:,:,1]=n_img\n",
    "                #frame = cv2.merge((p_img,n_img))\n",
    "                #X_tr_array[current_vid,frame_count]=frame\n",
    "                frame_count+=1\n",
    "            Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "            current_vid+=1\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 924/924 [38:33<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1096   20   67    5   15   10   18   10    7   14    3    7    1   13\n",
      "     8    6    8   11    7   45   38    8    6    9   15    2   19]\n",
      " [  13  486    3    0    2    0    1    0    1    7    1    0    0    1\n",
      "     2    2    0    1    2    1    0    0    1    3    5    1    2]\n",
      " [  17    2  502    0    0    0    0    0    0    1    2    0    0    0\n",
      "     1    1    0    0    0    1    1    0    0    0    0    1    4]\n",
      " [  18    1    2  370   31    7    7    1    0    2    3    1    0    1\n",
      "     8    9    8    2   32    5    1    4    6    1    1    4    1]\n",
      " [  32    1    2   40  362    1   15    1    1    0    4    2    2    6\n",
      "     5   11    1    1    6    2   13    1    1    3    2    2    2]\n",
      " [  16    0    1    7    4  430    9    0    1    7    1    0    0    2\n",
      "    24   17    0    0    3    2    4    0    1    7    0    2    0]\n",
      " [  34    3    1   14   36   21  306    1    2    1   28    0    0    6\n",
      "     2    8    1    1    4    2   47    2    0    1    3    4    3]\n",
      " [   5    1    0    2    0    0    0  437   37    0    0    0    0    0\n",
      "     1    5    0    1    1    1    0    0    0    0    0    1    0]\n",
      " [   7    3    2    1    1    0    0   28  468    0    1    0    0    3\n",
      "     0    4    0    1    1    0    0    0    0    1    0    0    0]\n",
      " [  11   13    3    2    0    6    3    1    0  448    0    0    0    2\n",
      "     1    1    0    1    1    0    1   14   12    4    0    3    1]\n",
      " [  12    3    2    5    4    0   10    1    2    0  395    1    0   23\n",
      "     4   40    2    0    4    3   12    0    0    1    3    1    3]\n",
      " [   7    0    0    0    7    0    2    0    0    0    0  399    2    0\n",
      "     0    0   93    3    0    1    0    2    2    0    0    0    1]\n",
      " [   8    1    1    0    0    1    0    0    1    0    2    3  384    0\n",
      "     0    0    3  107    1    0    1    3    0    0    0    0    0]\n",
      " [  15    1    0    0   10    1   10    1    7    3   69    0    1  340\n",
      "     4   10    0    0   25    5    6    0    0    4    8    0    2]\n",
      " [  16    0   15    9    7   66    2    0    0    6    2    1    0    0\n",
      "   359   23    1    0    3    2    7    2    0    7    3    3    2]\n",
      " [   8    2    3   12    3    7    3    6    1    4   30    1    0   11\n",
      "    26  356    1    2   20    8    3    0    1    6    3    2    1]\n",
      " [   8    0    1    1    5    2    0    0    0    1    1   60    3    1\n",
      "     2    2  396    4    0    3    1    0    2    0    0    1    0]\n",
      " [   7    0    1    0    0    2    0    0    0    0    2    4   86    0\n",
      "     1    0    6  375    0    0    0    2    0    0    0    0    0]\n",
      " [   8    0    3   33   11    0    5    0    2    0    6    0    0   18\n",
      "    10   20    3    0  369   10    3    2    1    1    0    2    0]\n",
      " [  36    2   12    5    0    2    2    0    2    2    3    0    0    1\n",
      "     2    5    4    2    5  439    1    1    4    0    0    0    5]\n",
      " [  38    1    5    2   14    8   38    0    0    0    3    0    2    4\n",
      "     6    2    2    1    2    2  395    2    1    3    6    0    2]\n",
      " [  22    3    2    5    5    4    1    0    0   20    0    0    1    0\n",
      "     1    0    4    0    4    3    2  224   73    7    1    1    2]\n",
      " [  12    3    1    6    3    1    3    0    0   32    0    2    0    0\n",
      "     3    1    8    1    7    3    1   62  239    4    1    5    1]\n",
      " [  14    5    2    2    4   13    4    0    2    4    0    0    1    5\n",
      "    14    9    1    1    4    5    1   13    6  343   40   27    6]\n",
      " [  30    8    5    0    4    0    3    0    0    1    6    0    0    9\n",
      "     2    2    0    0    2    2   20    2    1   64  322   12   27]\n",
      " [  15    4    6    2    6    1    1    2    0    6    4    0    1    3\n",
      "    11   12    1    2    1    2    4    2    9   16   15  355   45]\n",
      " [  20    4   14    0    3    1    8    0    1    1   11    2    1    2\n",
      "     0    3    2    0    1    1    7    0    4    8   29   57  350]]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 16\n",
    "batch_size = 16\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ls_path = os.path.join(\"E:/Jupyter/Project/generated_images_timeSampled\")\n",
    "met = confusion_matrix([26],[26],labels.sort_values(by=['Label'])['Label'].tolist())\n",
    "met[26][26]-=1\n",
    "for n in tqdm(range(len(validation[\"Video\"].tolist()[0:])//(num_samples))):\n",
    "    current_vid=0\n",
    "    Y_train = np.zeros([batch_size, nb_classes])\n",
    "    for vid_ID in validation[\"Video\"].tolist()[n*batch_size:(n+1)*batch_size]:\n",
    "        Y_train[current_vid]=np_utils.to_categorical(labels_dict[vid_ID], nb_classes)\n",
    "        current_vid+=1\n",
    "    met1 = confusion_matrix(np.argmax(Y_train,axis =1), np.argmax(model1.predict_generator(data_predict_gen(validation[\"Video\"].tolist()[0:],n,num_samples),1),axis =1),labels.sort_values(by=['Label'])['Label'].tolist())\n",
    "    for x in range(met1.shape[0]):\n",
    "        for y in range(met1.shape[0]):\n",
    "            met[x][y]=met[x][y]+met1[x][y]\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('E:/Jupyter/Project/save_model/deeperconf.pkl','wb') as fid:\n",
    "    pickle.dump(met, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Full Label Set Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm *= 100\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(10, 30))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=270)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix_plot(met, classes=labels.sort_values(by=['Label'])['Class'].tolist())\n",
    "plt.savefig(\"fullconfusion.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bc7bf367a94b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlayer_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mactivations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "layer_outputs = [layer.output for layer in model1.layers[:12]]\n",
    "activation_model = Model(inputs=model1.input, outputs=layer_outputs)\n",
    "activations=activation_model.predict(train_set[50:51])\n",
    "fig = plt.figure()\n",
    "\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "for i in range(train_set[50:51].shape[1]):\n",
    "    im = plt.imshow(train_set[50:51][0, i, :,:, 0], cmap='viridis')\n",
    "    ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "ani.save(\"E:/Jupyter/Project/deep_activations/\"+'input' + '.mp4')\n",
    "\n",
    "layer_num = 0\n",
    "layer_names=[]\n",
    "for layer in model1.layers[:16]:\n",
    "    layer_names.append(layer.name)\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # ims is a list of lists, each row is a list of artists to draw in the\n",
    "    # current frame; here we are just animating one artist, the image, in\n",
    "    # each frame\n",
    "    ims = []\n",
    "    if layer_num<10:\n",
    "        x=layer_activation.shape[-1]\n",
    "        if x>32:\n",
    "            x=32\n",
    "        for layer_iteration in range(x):\n",
    "            ims = []\n",
    "            for i in range(layer_activation.shape[1]):\n",
    "                im = plt.imshow(layer_activation[0, i, :,:,layer_iteration], cmap='viridis')\n",
    "                ims.append([im])\n",
    "            ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                            repeat_delay=1000)\n",
    "            ani.save(\"E:/Jupyter/Project/deep_activations/\"+str(layer_num) +\"/\"+layer_name+ 'activation' + str(layer_iteration) + '.mp4')\n",
    "        layer_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
