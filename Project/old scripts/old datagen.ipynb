{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=64,64\n",
    "nb_frames = 663    # img_depth or number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "weight_decay = 0.00005\n",
    "import tensorflow as tf\n",
    "keras=tf.contrib.keras\n",
    "l2=keras.regularizers.l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16,(3,3,3),\n",
    "                        input_shape=(nb_frames, img_cols, img_rows, channels),\n",
    "                        activation='relu'))\n",
    "model.add(Conv3D(16,(3,3,3), strides=(2,2,2),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_1', activation = 'relu'))\n",
    "model.add(Conv3D(4,(4,4,4), strides=(2,2,2),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2', activation = 'relu'))\n",
    "model.add(Conv3D(4,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_3', activation = 'relu'))\n",
    "model.add(Conv3D(4,(2,2,2), strides=(2,2,2),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_4', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_5', activation = 'relu'))\n",
    "model.add(Conv3D(8,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_6', activation = 'relu'))\n",
    "model.add(Conv3D(8,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_7', activation = 'relu'))\n",
    "model.add(Conv3D(8,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_8', activation = 'relu'))\n",
    "model.add(Conv3D(32,(2,2,2), strides=(2,2,2),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_9', activation = 'relu'))\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_10', activation = 'relu'))\n",
    "model.add(Conv3D(16,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_11', activation = 'relu'))\n",
    "model.add(Conv3D(16,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_12', activation = 'relu'))\n",
    "model.add(Conv3D(64,(2,2,2), strides=(2,2,2),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_13', activation = 'relu'))\n",
    "model.add(Conv3D(16,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_14', activation = 'relu'))\n",
    "model.add(Conv3D(16,(1,1,1), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_15', activation = 'relu'))\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm1'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm3'))\n",
    "\n",
    "\n",
    "#model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 661, 62, 62, 16)   880       \n",
      "_________________________________________________________________\n",
      "Conv3D_1 (Conv3D)            (None, 331, 31, 31, 16)   6912      \n",
      "_________________________________________________________________\n",
      "Conv3D_2 (Conv3D)            (None, 166, 16, 16, 4)    4096      \n",
      "_________________________________________________________________\n",
      "Conv3D_3 (Conv3D)            (None, 166, 16, 16, 4)    16        \n",
      "_________________________________________________________________\n",
      "Conv3D_4 (Conv3D)            (None, 83, 8, 8, 4)       128       \n",
      "_________________________________________________________________\n",
      "Conv3D_5 (Conv3D)            (None, 83, 8, 8, 64)      6912      \n",
      "_________________________________________________________________\n",
      "Conv3D_6 (Conv3D)            (None, 83, 8, 8, 8)       512       \n",
      "_________________________________________________________________\n",
      "Conv3D_7 (Conv3D)            (None, 83, 8, 8, 8)       64        \n",
      "_________________________________________________________________\n",
      "Conv3D_8 (Conv3D)            (None, 83, 8, 8, 8)       64        \n",
      "_________________________________________________________________\n",
      "Conv3D_9 (Conv3D)            (None, 42, 4, 4, 32)      2048      \n",
      "_________________________________________________________________\n",
      "Conv3D_10 (Conv3D)           (None, 42, 4, 4, 128)     110592    \n",
      "_________________________________________________________________\n",
      "Conv3D_11 (Conv3D)           (None, 42, 4, 4, 16)      2048      \n",
      "_________________________________________________________________\n",
      "Conv3D_12 (Conv3D)           (None, 42, 4, 4, 16)      256       \n",
      "_________________________________________________________________\n",
      "Conv3D_13 (Conv3D)           (None, 21, 2, 2, 64)      8192      \n",
      "_________________________________________________________________\n",
      "Conv3D_14 (Conv3D)           (None, 21, 2, 2, 16)      1024      \n",
      "_________________________________________________________________\n",
      "Conv3D_15 (Conv3D)           (None, 21, 2, 2, 16)      256       \n",
      "_________________________________________________________________\n",
      "gatedclstm1 (ConvLSTM2D)     (None, 21, 2, 2, 64)      184576    \n",
      "_________________________________________________________________\n",
      "gatedclstm2 (ConvLSTM2D)     (None, 21, 2, 2, 64)      295168    \n",
      "_________________________________________________________________\n",
      "gatedclstm3 (ConvLSTM2D)     (None, 21, 2, 2, 64)      295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 27)                1755      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 920,667\n",
      "Trainable params: 920,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"3DCNN+3LSTM_64_6_jester\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.003,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_gen(id_list):\n",
    "    while True:\n",
    "        yield random.sample(id_list,64)\n",
    "\n",
    "def data_gen(train_batches):\n",
    "    while True:\n",
    "        batch_IDs = next(train_batches)\n",
    "        \n",
    "        for vid_ID in batch_IDs:\n",
    "            X_tr=[]\n",
    "            label=[]\n",
    "            frames = []\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                if frame_count < nb_frames:\n",
    "                    pos = os.path.join(pos_dir,img_ID)\n",
    "                    neg = os.path.join(neg_dir,img_ID)\n",
    "                    p_img = cv2.imread(pos,0)\n",
    "                    p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    n_img = cv2.imread(neg,0)\n",
    "                    n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    frame = cv2.merge((p_img,n_img))\n",
    "                    frames.append(frame)\n",
    "                    frame_count+=1\n",
    "                else:\n",
    "                    break\n",
    "            while frame_count < nb_frames:\n",
    "                frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "                frame_count+=1\n",
    "            input_img = np.array(frames)\n",
    "            ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "            ipt=np.rollaxis(ipt,2,0)\n",
    "            X_tr.append(ipt)\n",
    "            label.append(labels_dict[vid_ID])\n",
    "        num_samples = len(X_tr) \n",
    "\n",
    "        X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "        Y_train = np_utils.to_categorical(label, nb_classes)\n",
    "\n",
    "        yield X_tr_array,Y_train\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (nb_frames,img_cols,img_rows),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': nb_classes,\n",
    "          'n_channels': channels,\n",
    "          'shuffle': True}\n",
    "\n",
    "training_generator = data_gen(id_gen(train[\"Video\"].tolist()))\n",
    "validation_generator = data_gen(id_gen(validation[\"Video\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28460328be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = training_generator\n",
    "x_batch, y_batch = next(batches)\n",
    "\n",
    "p,n = cv2.split (x_batch[0][0])\n",
    "plt.imshow(p)\n",
    "#print(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object data_gen at 0x000002845E8CC518>\n",
      "(array([[[[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]],\n",
      "\n",
      "         [[0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          ...,\n",
      "          [0, 0],\n",
      "          [0, 0],\n",
      "          [0, 0]]]]], dtype=uint8), array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(training_generator)\n",
    "print(next(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      " - 5423s - loss: 3.4941 - acc: 0.0000e+00 - val_loss: 3.4904 - val_acc: 0.0234\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.02344, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 2/512\n",
      " - 30366s - loss: 3.4686 - acc: 0.0000e+00 - val_loss: 3.4903 - val_acc: 0.0156\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.02344\n",
      "Epoch 3/512\n",
      " - 455s - loss: 3.4491 - acc: 1.0000 - val_loss: 3.4900 - val_acc: 0.0312\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.02344 to 0.03125, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 4/512\n",
      " - 378s - loss: 3.4927 - acc: 0.0000e+00 - val_loss: 3.4897 - val_acc: 0.0234\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.03125\n",
      "Epoch 5/512\n",
      " - 357s - loss: 3.4873 - acc: 0.0000e+00 - val_loss: 3.4918 - val_acc: 0.0273\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.03125\n",
      "Epoch 6/512\n",
      " - 351s - loss: 3.4801 - acc: 0.0000e+00 - val_loss: 3.4896 - val_acc: 0.0273\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.03125\n",
      "Epoch 7/512\n",
      " - 354s - loss: 3.4875 - acc: 0.0000e+00 - val_loss: 3.4871 - val_acc: 0.0469\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.03125 to 0.04688, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 8/512\n",
      " - 346s - loss: 3.4794 - acc: 0.0000e+00 - val_loss: 3.4873 - val_acc: 0.0703\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.04688 to 0.07031, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 9/512\n",
      " - 571s - loss: 3.4657 - acc: 0.0000e+00 - val_loss: 3.4862 - val_acc: 0.0469\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.07031\n",
      "Epoch 10/512\n",
      " - 528s - loss: 3.4429 - acc: 0.0000e+00 - val_loss: 3.4871 - val_acc: 0.0352\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.07031\n",
      "Epoch 11/512\n",
      " - 551s - loss: 3.4442 - acc: 0.0000e+00 - val_loss: 3.4894 - val_acc: 0.0352\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.07031\n",
      "Epoch 12/512\n",
      " - 485s - loss: 3.5242 - acc: 0.0000e+00 - val_loss: 3.4853 - val_acc: 0.0508\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.07031\n",
      "Epoch 13/512\n",
      " - 530s - loss: 3.4655 - acc: 0.0000e+00 - val_loss: 3.4837 - val_acc: 0.0742\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.07031 to 0.07422, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 14/512\n",
      " - 442s - loss: 3.4993 - acc: 0.0000e+00 - val_loss: 3.4836 - val_acc: 0.0703\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.07422\n",
      "Epoch 15/512\n",
      " - 503s - loss: 3.5093 - acc: 0.0000e+00 - val_loss: 3.4815 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.07422 to 0.11719, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 16/512\n",
      " - 558s - loss: 3.5132 - acc: 0.0000e+00 - val_loss: 3.4880 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.11719\n",
      "Epoch 17/512\n",
      " - 508s - loss: 3.4973 - acc: 0.0000e+00 - val_loss: 3.4866 - val_acc: 0.0703\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.11719\n",
      "Epoch 18/512\n",
      " - 537s - loss: 3.3988 - acc: 1.0000 - val_loss: 3.4851 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.11719\n",
      "Epoch 19/512\n",
      " - 513s - loss: 3.4902 - acc: 0.0000e+00 - val_loss: 3.4824 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.11719\n",
      "Epoch 20/512\n",
      " - 498s - loss: 3.5271 - acc: 0.0000e+00 - val_loss: 3.4838 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.11719\n",
      "Epoch 21/512\n",
      " - 523s - loss: 3.3844 - acc: 1.0000 - val_loss: 3.4858 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.11719\n",
      "Epoch 22/512\n",
      " - 503s - loss: 3.4725 - acc: 0.0000e+00 - val_loss: 3.4826 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.11719\n",
      "Epoch 23/512\n",
      " - 532s - loss: 3.5080 - acc: 0.0000e+00 - val_loss: 3.4854 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.11719\n",
      "Epoch 24/512\n",
      " - 512s - loss: 3.4885 - acc: 0.0000e+00 - val_loss: 3.4800 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.11719\n",
      "Epoch 25/512\n",
      " - 522s - loss: 3.4081 - acc: 0.0000e+00 - val_loss: 3.4828 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.11719\n",
      "Epoch 26/512\n",
      " - 407s - loss: 3.3451 - acc: 1.0000 - val_loss: 3.4911 - val_acc: 0.0547\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.11719\n",
      "Epoch 27/512\n",
      " - 440s - loss: 3.4903 - acc: 0.0000e+00 - val_loss: 3.4781 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.11719\n",
      "Epoch 28/512\n",
      " - 565s - loss: 3.5228 - acc: 0.0000e+00 - val_loss: 3.4820 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.11719\n",
      "Epoch 29/512\n",
      " - 480s - loss: 3.5047 - acc: 0.0000e+00 - val_loss: 3.4830 - val_acc: 0.0664\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.11719\n",
      "Epoch 30/512\n",
      " - 407s - loss: 3.5378 - acc: 0.0000e+00 - val_loss: 3.4790 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.11719\n",
      "Epoch 31/512\n",
      " - 354s - loss: 3.3292 - acc: 1.0000 - val_loss: 3.4812 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.11719\n",
      "Epoch 32/512\n",
      " - 350s - loss: 3.4861 - acc: 0.0000e+00 - val_loss: 3.4771 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.11719\n",
      "Epoch 33/512\n",
      " - 349s - loss: 3.4272 - acc: 0.0000e+00 - val_loss: 3.4823 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.11719\n",
      "Epoch 34/512\n",
      " - 360s - loss: 3.5356 - acc: 0.0000e+00 - val_loss: 3.4847 - val_acc: 0.0703\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.11719\n",
      "Epoch 35/512\n",
      " - 492s - loss: 3.4241 - acc: 0.0000e+00 - val_loss: 3.4793 - val_acc: 0.0703\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.11719\n",
      "Epoch 36/512\n",
      " - 528s - loss: 3.4591 - acc: 0.0000e+00 - val_loss: 3.4801 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.11719\n",
      "Epoch 37/512\n",
      " - 552s - loss: 3.5779 - acc: 0.0000e+00 - val_loss: 3.4811 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.11719\n",
      "Epoch 38/512\n",
      " - 541s - loss: 3.4488 - acc: 0.0000e+00 - val_loss: 3.4845 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.11719\n",
      "Epoch 39/512\n",
      " - 544s - loss: 3.5359 - acc: 0.0000e+00 - val_loss: 3.4815 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.11719\n",
      "Epoch 40/512\n",
      " - 656s - loss: 3.5397 - acc: 0.0000e+00 - val_loss: 3.4857 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.11719\n",
      "Epoch 41/512\n",
      " - 566s - loss: 3.4748 - acc: 0.0000e+00 - val_loss: 3.4726 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.11719\n",
      "Epoch 42/512\n",
      " - 413s - loss: 3.5688 - acc: 0.0000e+00 - val_loss: 3.4736 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.11719\n",
      "Epoch 43/512\n",
      " - 417s - loss: 3.4138 - acc: 0.0000e+00 - val_loss: 3.4761 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.11719\n",
      "Epoch 44/512\n",
      " - 369s - loss: 3.4937 - acc: 0.0000e+00 - val_loss: 3.4806 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.11719\n",
      "Epoch 45/512\n",
      " - 337s - loss: 3.4787 - acc: 0.0000e+00 - val_loss: 3.4797 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.11719\n",
      "Epoch 46/512\n",
      " - 325s - loss: 3.3088 - acc: 1.0000 - val_loss: 3.4759 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.11719\n",
      "Epoch 47/512\n",
      " - 317s - loss: 3.2778 - acc: 1.0000 - val_loss: 3.4726 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.11719\n",
      "Epoch 48/512\n",
      " - 323s - loss: 3.4708 - acc: 0.0000e+00 - val_loss: 3.4689 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.11719 to 0.13281, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 49/512\n",
      " - 342s - loss: 3.5458 - acc: 0.0000e+00 - val_loss: 3.4792 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.13281\n",
      "Epoch 50/512\n",
      " - 348s - loss: 3.5400 - acc: 0.0000e+00 - val_loss: 3.4754 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.13281\n",
      "Epoch 51/512\n",
      " - 330s - loss: 3.4205 - acc: 0.0000e+00 - val_loss: 3.4711 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.13281\n",
      "Epoch 52/512\n",
      " - 346s - loss: 3.4185 - acc: 0.0000e+00 - val_loss: 3.4746 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.13281\n",
      "Epoch 53/512\n",
      " - 323s - loss: 3.4614 - acc: 0.0000e+00 - val_loss: 3.4774 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.13281\n",
      "Epoch 54/512\n",
      " - 338s - loss: 3.5124 - acc: 0.0000e+00 - val_loss: 3.4694 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.13281\n",
      "Epoch 55/512\n",
      " - 335s - loss: 3.5564 - acc: 0.0000e+00 - val_loss: 3.4803 - val_acc: 0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_acc did not improve from 0.13281\n",
      "Epoch 56/512\n",
      " - 359s - loss: 3.5998 - acc: 0.0000e+00 - val_loss: 3.4760 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.13281\n",
      "Epoch 57/512\n",
      " - 368s - loss: 3.5107 - acc: 0.0000e+00 - val_loss: 3.4754 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.13281\n",
      "Epoch 58/512\n",
      " - 351s - loss: 3.3418 - acc: 0.0000e+00 - val_loss: 3.4826 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.13281\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 59/512\n",
      " - 342s - loss: 3.3300 - acc: 0.0000e+00 - val_loss: 3.4734 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.13281\n",
      "Epoch 60/512\n",
      " - 364s - loss: 3.4386 - acc: 0.0000e+00 - val_loss: 3.4748 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.13281\n",
      "Epoch 61/512\n",
      " - 337s - loss: 3.4811 - acc: 0.0000e+00 - val_loss: 3.4650 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.13281\n",
      "Epoch 62/512\n",
      " - 331s - loss: 3.4555 - acc: 0.0000e+00 - val_loss: 3.4718 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.13281\n",
      "Epoch 63/512\n",
      " - 349s - loss: 3.2679 - acc: 1.0000 - val_loss: 3.4660 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.13281\n",
      "Epoch 64/512\n",
      " - 337s - loss: 3.4472 - acc: 0.0000e+00 - val_loss: 3.4788 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.13281\n",
      "Epoch 65/512\n",
      " - 358s - loss: 3.5740 - acc: 0.0000e+00 - val_loss: 3.4815 - val_acc: 0.0742\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.13281\n",
      "Epoch 66/512\n",
      " - 344s - loss: 3.2449 - acc: 1.0000 - val_loss: 3.4827 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.13281\n",
      "Epoch 67/512\n",
      " - 350s - loss: 3.4644 - acc: 0.0000e+00 - val_loss: 3.4836 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.13281\n",
      "Epoch 68/512\n",
      " - 332s - loss: 3.5108 - acc: 0.0000e+00 - val_loss: 3.4781 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.13281\n",
      "Epoch 69/512\n",
      " - 339s - loss: 3.2457 - acc: 1.0000 - val_loss: 3.4818 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.13281\n",
      "Epoch 70/512\n",
      " - 353s - loss: 3.5544 - acc: 0.0000e+00 - val_loss: 3.4743 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.13281\n",
      "Epoch 71/512\n",
      " - 342s - loss: 3.5484 - acc: 0.0000e+00 - val_loss: 3.4796 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.13281\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 72/512\n",
      " - 333s - loss: 3.4702 - acc: 0.0000e+00 - val_loss: 3.4853 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.13281\n",
      "Epoch 73/512\n",
      " - 359s - loss: 3.5196 - acc: 0.0000e+00 - val_loss: 3.4747 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.13281\n",
      "Epoch 74/512\n",
      " - 354s - loss: 3.4468 - acc: 0.0000e+00 - val_loss: 3.4839 - val_acc: 0.0664\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.13281\n",
      "Epoch 75/512\n",
      " - 342s - loss: 3.4631 - acc: 0.0000e+00 - val_loss: 3.4604 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.13281\n",
      "Epoch 76/512\n",
      " - 343s - loss: 3.4026 - acc: 0.0000e+00 - val_loss: 3.4784 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.13281\n",
      "Epoch 77/512\n",
      " - 335s - loss: 3.5940 - acc: 0.0000e+00 - val_loss: 3.4803 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.13281\n",
      "Epoch 78/512\n",
      " - 336s - loss: 3.6281 - acc: 0.0000e+00 - val_loss: 3.4775 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.13281\n",
      "Epoch 79/512\n",
      " - 325s - loss: 3.4807 - acc: 0.0000e+00 - val_loss: 3.4841 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.13281\n",
      "Epoch 80/512\n",
      " - 356s - loss: 3.2189 - acc: 1.0000 - val_loss: 3.4747 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.13281\n",
      "Epoch 81/512\n",
      " - 335s - loss: 3.2993 - acc: 0.0000e+00 - val_loss: 3.4673 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.13281\n",
      "Epoch 82/512\n",
      " - 335s - loss: 3.6030 - acc: 0.0000e+00 - val_loss: 3.4744 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.13281\n",
      "Epoch 83/512\n",
      " - 330s - loss: 3.5441 - acc: 0.0000e+00 - val_loss: 3.4802 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.13281\n",
      "Epoch 84/512\n",
      " - 335s - loss: 3.2562 - acc: 0.0000e+00 - val_loss: 3.4911 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.13281\n",
      "Epoch 85/512\n",
      " - 317s - loss: 3.3670 - acc: 0.0000e+00 - val_loss: 3.4763 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.13281\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 86/512\n",
      " - 336s - loss: 3.5500 - acc: 0.0000e+00 - val_loss: 3.4782 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.13281\n",
      "Epoch 87/512\n",
      " - 351s - loss: 3.4959 - acc: 0.0000e+00 - val_loss: 3.4671 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.13281\n",
      "Epoch 88/512\n",
      " - 338s - loss: 3.4799 - acc: 0.0000e+00 - val_loss: 3.4850 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.13281\n",
      "Epoch 89/512\n",
      " - 346s - loss: 3.4445 - acc: 0.0000e+00 - val_loss: 3.4638 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.13281\n",
      "Epoch 90/512\n",
      " - 351s - loss: 3.5461 - acc: 0.0000e+00 - val_loss: 3.4755 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.13281\n",
      "Epoch 91/512\n",
      " - 337s - loss: 3.5328 - acc: 0.0000e+00 - val_loss: 3.4760 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.13281\n",
      "Epoch 92/512\n",
      " - 354s - loss: 3.5860 - acc: 0.0000e+00 - val_loss: 3.4905 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.13281\n",
      "Epoch 93/512\n",
      " - 349s - loss: 3.5152 - acc: 0.0000e+00 - val_loss: 3.4765 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.13281\n",
      "Epoch 94/512\n",
      " - 346s - loss: 3.4318 - acc: 0.0000e+00 - val_loss: 3.4727 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.13281\n",
      "Epoch 95/512\n",
      " - 331s - loss: 3.4654 - acc: 0.0000e+00 - val_loss: 3.4858 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.13281\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 96/512\n",
      " - 324s - loss: 3.5849 - acc: 0.0000e+00 - val_loss: 3.4782 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.13281\n",
      "Epoch 97/512\n",
      " - 332s - loss: 3.4637 - acc: 0.0000e+00 - val_loss: 3.4736 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.13281\n",
      "Epoch 98/512\n",
      " - 332s - loss: 3.4195 - acc: 0.0000e+00 - val_loss: 3.4606 - val_acc: 0.1367\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.13281 to 0.13672, saving model to E:\\Jupyter\\Project\\save_model\\3DCNN+3LSTM_64_6_jester\n",
      "Epoch 99/512\n",
      " - 352s - loss: 3.5982 - acc: 0.0000e+00 - val_loss: 3.4725 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.13672\n",
      "Epoch 100/512\n",
      " - 353s - loss: 3.5349 - acc: 0.0000e+00 - val_loss: 3.4740 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.13672\n",
      "Epoch 101/512\n",
      " - 371s - loss: 3.5762 - acc: 0.0000e+00 - val_loss: 3.4771 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.13672\n",
      "Epoch 102/512\n",
      " - 405s - loss: 3.6012 - acc: 0.0000e+00 - val_loss: 3.4704 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.13672\n",
      "Epoch 103/512\n",
      " - 372s - loss: 3.5203 - acc: 0.0000e+00 - val_loss: 3.4691 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.13672\n",
      "Epoch 104/512\n",
      " - 366s - loss: 3.4603 - acc: 0.0000e+00 - val_loss: 3.4826 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.13672\n",
      "Epoch 105/512\n",
      " - 348s - loss: 3.4794 - acc: 0.0000e+00 - val_loss: 3.4870 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 106/512\n",
      " - 348s - loss: 3.5189 - acc: 0.0000e+00 - val_loss: 3.4616 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.13672\n",
      "Epoch 107/512\n",
      " - 347s - loss: 3.4832 - acc: 0.0000e+00 - val_loss: 3.4909 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.13672\n",
      "Epoch 108/512\n",
      " - 338s - loss: 3.5236 - acc: 0.0000e+00 - val_loss: 3.4669 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.13672\n",
      "Epoch 109/512\n",
      " - 331s - loss: 3.4062 - acc: 0.0000e+00 - val_loss: 3.4929 - val_acc: 0.0586\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.13672\n",
      "Epoch 110/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 325s - loss: 3.6208 - acc: 0.0000e+00 - val_loss: 3.4707 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.13672\n",
      "Epoch 111/512\n",
      " - 348s - loss: 3.5873 - acc: 0.0000e+00 - val_loss: 3.4780 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.13672\n",
      "Epoch 112/512\n",
      " - 341s - loss: 3.2170 - acc: 1.0000 - val_loss: 3.4736 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.13672\n",
      "Epoch 113/512\n",
      " - 341s - loss: 3.5756 - acc: 0.0000e+00 - val_loss: 3.4614 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.13672\n",
      "Epoch 114/512\n",
      " - 408s - loss: 3.5775 - acc: 0.0000e+00 - val_loss: 3.4814 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.13672\n",
      "Epoch 115/512\n",
      " - 413s - loss: 3.4315 - acc: 0.0000e+00 - val_loss: 3.4848 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 116/512\n",
      " - 400s - loss: 3.6420 - acc: 0.0000e+00 - val_loss: 3.4642 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.13672\n",
      "Epoch 117/512\n",
      " - 381s - loss: 3.6008 - acc: 0.0000e+00 - val_loss: 3.4747 - val_acc: 0.0898\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.13672\n",
      "Epoch 118/512\n",
      " - 389s - loss: 3.4220 - acc: 0.0000e+00 - val_loss: 3.4806 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.13672\n",
      "Epoch 119/512\n",
      " - 383s - loss: 3.4051 - acc: 0.0000e+00 - val_loss: 3.4753 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.13672\n",
      "Epoch 120/512\n",
      " - 372s - loss: 3.5379 - acc: 0.0000e+00 - val_loss: 3.4765 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.13672\n",
      "Epoch 121/512\n",
      " - 395s - loss: 3.4852 - acc: 0.0000e+00 - val_loss: 3.4759 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.13672\n",
      "Epoch 122/512\n",
      " - 377s - loss: 3.4007 - acc: 0.0000e+00 - val_loss: 3.4773 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.13672\n",
      "Epoch 123/512\n",
      " - 363s - loss: 3.2099 - acc: 1.0000 - val_loss: 3.4787 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.13672\n",
      "Epoch 124/512\n",
      " - 353s - loss: 3.4188 - acc: 0.0000e+00 - val_loss: 3.4832 - val_acc: 0.0859\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.13672\n",
      "Epoch 125/512\n",
      " - 373s - loss: 3.4168 - acc: 0.0000e+00 - val_loss: 3.4690 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 126/512\n",
      " - 417s - loss: 3.4893 - acc: 0.0000e+00 - val_loss: 3.4762 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.13672\n",
      "Epoch 127/512\n",
      " - 363s - loss: 3.6121 - acc: 0.0000e+00 - val_loss: 3.4768 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.13672\n",
      "Epoch 128/512\n",
      " - 352s - loss: 3.4793 - acc: 0.0000e+00 - val_loss: 3.4654 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.13672\n",
      "Epoch 129/512\n",
      " - 348s - loss: 3.6058 - acc: 0.0000e+00 - val_loss: 3.4707 - val_acc: 0.1055\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.13672\n",
      "Epoch 130/512\n",
      " - 454s - loss: 3.6284 - acc: 0.0000e+00 - val_loss: 3.4763 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.13672\n",
      "Epoch 131/512\n",
      " - 388s - loss: 3.6231 - acc: 0.0000e+00 - val_loss: 3.4734 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.13672\n",
      "Epoch 132/512\n",
      " - 350s - loss: 3.3536 - acc: 0.0000e+00 - val_loss: 3.4819 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.13672\n",
      "Epoch 133/512\n",
      " - 361s - loss: 3.5240 - acc: 0.0000e+00 - val_loss: 3.4831 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.13672\n",
      "Epoch 134/512\n",
      " - 346s - loss: 3.4686 - acc: 0.0000e+00 - val_loss: 3.4771 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.13672\n",
      "Epoch 135/512\n",
      " - 340s - loss: 3.5876 - acc: 0.0000e+00 - val_loss: 3.4765 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 136/512\n",
      " - 345s - loss: 3.6008 - acc: 0.0000e+00 - val_loss: 3.4619 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.13672\n",
      "Epoch 137/512\n",
      " - 332s - loss: 3.6324 - acc: 0.0000e+00 - val_loss: 3.4696 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.13672\n",
      "Epoch 138/512\n",
      " - 346s - loss: 3.5306 - acc: 0.0000e+00 - val_loss: 3.4640 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.13672\n",
      "Epoch 139/512\n",
      " - 342s - loss: 3.4672 - acc: 0.0000e+00 - val_loss: 3.4712 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.13672\n",
      "Epoch 140/512\n",
      " - 342s - loss: 3.4873 - acc: 0.0000e+00 - val_loss: 3.4730 - val_acc: 0.1172\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.13672\n",
      "Epoch 141/512\n",
      " - 355s - loss: 3.4604 - acc: 0.0000e+00 - val_loss: 3.4771 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.13672\n",
      "Epoch 142/512\n",
      " - 353s - loss: 3.6134 - acc: 0.0000e+00 - val_loss: 3.4726 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.13672\n",
      "Epoch 143/512\n",
      " - 343s - loss: 3.4613 - acc: 0.0000e+00 - val_loss: 3.4707 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.13672\n",
      "Epoch 144/512\n",
      " - 356s - loss: 3.3520 - acc: 0.0000e+00 - val_loss: 3.4701 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.13672\n",
      "Epoch 145/512\n",
      " - 354s - loss: 3.4837 - acc: 0.0000e+00 - val_loss: 3.4671 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 146/512\n",
      " - 351s - loss: 3.4986 - acc: 0.0000e+00 - val_loss: 3.4716 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.13672\n",
      "Epoch 147/512\n",
      " - 358s - loss: 3.5747 - acc: 0.0000e+00 - val_loss: 3.4720 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.13672\n",
      "Epoch 148/512\n",
      " - 346s - loss: 3.5644 - acc: 0.0000e+00 - val_loss: 3.4616 - val_acc: 0.1133\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.13672\n",
      "Epoch 149/512\n",
      " - 343s - loss: 3.5535 - acc: 0.0000e+00 - val_loss: 3.4674 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.13672\n",
      "Epoch 150/512\n",
      " - 326s - loss: 3.5968 - acc: 0.0000e+00 - val_loss: 3.4787 - val_acc: 0.0938\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.13672\n",
      "Epoch 151/512\n",
      " - 328s - loss: 3.5827 - acc: 0.0000e+00 - val_loss: 3.4915 - val_acc: 0.0664\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.13672\n",
      "Epoch 152/512\n",
      " - 329s - loss: 3.4729 - acc: 0.0000e+00 - val_loss: 3.4681 - val_acc: 0.1094\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.13672\n",
      "Epoch 153/512\n",
      " - 341s - loss: 3.5425 - acc: 0.0000e+00 - val_loss: 3.4758 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.13672\n",
      "Epoch 154/512\n",
      " - 349s - loss: 3.5734 - acc: 0.0000e+00 - val_loss: 3.4764 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.13672\n",
      "Epoch 155/512\n",
      " - 347s - loss: 3.4812 - acc: 0.0000e+00 - val_loss: 3.4798 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.13672\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 156/512\n",
      " - 345s - loss: 3.3943 - acc: 0.0000e+00 - val_loss: 3.4701 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.13672\n",
      "Epoch 157/512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dd0113290387>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             workers=0)\n\u001b[0m\u001b[0;32m    235\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                         \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                  \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                                  str(generator_output))\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 512\n",
    "#nb_epoch = 131072\n",
    "hist = model.fit_generator(\n",
    "    generator=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs = nb_epoch,\n",
    "    callbacks=[checkpoint,lr_reducer],\n",
    "    steps_per_epoch = 1,\n",
    "    validation_steps = 256,\n",
    "    verbose = 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0c97049ad240>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"training_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"3DCNN+3LSTM_64_6_jester\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_pred =model1.predict_generator(validation_generator, steps = 256)\n",
    "result = np.argmax(test_pred, axis =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5575e50903ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_val_new' is not defined"
     ]
    }
   ],
   "source": [
    "img_array = X_train_new[50]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "met = confusion_matrix(np.argmax(y_val_new,axis =1), np.argmax(model1.predict(X_val_new),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'met' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-422ff2f1adce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'met' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix_plot(met, classes=labels[\"Class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model2_name = \"3DCNN+3LSTM_64_6_jester\"\n",
    "#model2_name = \"3DCNN_LRN_300_6_jester\"\n",
    "#model2_name = \"3DCNN_HRN_300_6_jester\"\n",
    "model2_path = os.path.join(save_dir, model2_name)\n",
    "model2 = load_model(model2_path)\n",
    "met = confusion_matrix(np.argmax(y_val_new,axis =1), np.argmax(model2.predict(X_val_new),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_val_new,y_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    we=(i+1)/10\n",
    "    we_2=1-we\n",
    "    met = confusion_matrix(np.argmax(y_val_new,axis =1), np.argmax(we*model2.predict(X_val_new)+we_2*model1.predict(X_val_new),axis =1))\n",
    "    print((met[0,0]+met[1,1]+met[2,2]+met[3,3]+met[4,4]+met[5,5])/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
