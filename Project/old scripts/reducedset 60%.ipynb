{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils, Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_cols,img_rows=100,176\n",
    "nb_frames = 16    # img_depth or number of frames used for each video\n",
    "# CNN Training parameters\n",
    "nb_classes = 27\n",
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# integer encode\n",
    "labels = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-labels.csv',sep=';',header=None,names=['Class'])     # reading the csv file\n",
    "label_encoder = LabelEncoder()\n",
    "labels['Label'] = label_encoder.fit_transform(labels['Class'])\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-train.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-validation.csv',sep=';',header=None,names=['Video','Class'])     # reading the csv file\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25025"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "train = train[train[\"Class\"].isin([\"No gesture\",\"Swiping Left\",\"Swiping Right\",\"Stop Sign\",\"Rolling Hand Forward\",\"Rolling Hand Backward\"])]\n",
    "train['Label'] = label_encoder.fit_transform(train['Class'])\n",
    "\n",
    "#validation\n",
    "validation = validation[validation[\"Class\"].isin([\"No gesture\",\"Swiping Left\",\"Swiping Right\",\"Stop Sign\",\"Rolling Hand Forward\",\"Rolling Hand Backward\"])]\n",
    "validation['Label'] = label_encoder.fit_transform(validation['Class'])\n",
    "\n",
    "#test\n",
    "#test = pd.read_csv('E:\\Jupyter\\Project\\jester-v1-test.csv',sep=';',header=None,names=['Video'])     # reading the csv file\n",
    "\n",
    "#print labels\n",
    "#labels\n",
    "\"\"\"\n",
    "partition_dict = {\n",
    "    \"train\": train[\"Video\"].tolist(),\n",
    "    \"validation\": validation[\"Video\"].tolist()\n",
    "}\"\"\"\n",
    "temp = pd.concat([train, validation])\n",
    "temp = temp.set_index(\"Video\")\n",
    "#temp = train.set_index(\"Video\")\n",
    "temp.transpose()\n",
    "labels_dict = {}\n",
    "labels_dict = temp[\"Label\"].to_dict()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def data_gen(train_list, batch_size=64):\n",
    "    while True:\n",
    "        X_tr=[]\n",
    "        label=[]\n",
    "        for vid_ID in random.sample(train_list,batch_size):\n",
    "            frames = []\n",
    "            frame_count=0\n",
    "            pos_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/pos\",str(vid_ID))\n",
    "            neg_dir = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled/neg\",str(vid_ID))\n",
    "            for img_ID in sorted(os.listdir(pos_dir)):\n",
    "                if frame_count < nb_frames:\n",
    "                    pos = os.path.join(pos_dir,img_ID)\n",
    "                    neg = os.path.join(neg_dir,img_ID)\n",
    "                    p_img = cv2.imread(pos,0)\n",
    "                    p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    n_img = cv2.imread(neg,0)\n",
    "                    n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "                    frame = cv2.merge((p_img,n_img))\n",
    "                    frames.append(frame)\n",
    "                    frame_count+=1\n",
    "                else:\n",
    "                    break\n",
    "            while frame_count < nb_frames:\n",
    "                frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "                frame_count+=1\n",
    "            input_img = np.array(frames)\n",
    "            ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "            ipt=np.rollaxis(ipt,2,0)\n",
    "            X_tr.append(ipt)\n",
    "            label.append(labels_dict[vid_ID])\n",
    "\n",
    "        X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "        Y_train = np_utils.to_categorical(label, nb_classes)\n",
    "\n",
    "        yield X_tr_array,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16, 100, 176, 2)\n"
     ]
    }
   ],
   "source": [
    "print(next(data_gen(train[\"Video\"].tolist()))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#low resolution network\n",
    "weight_decay = 0.005\n",
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(nb_frames,  img_cols, img_rows, channels)))\n",
    "\n",
    "model.add(Conv3D(8,(1,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(8,(5,1,1),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32,(1,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(32,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64,(1,3,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv3D(64,(3,1,1), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 4 )))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling3d_1 (MaxPooling3 (None, 16, 50, 88, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 16, 46, 84, 8)     408       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 46, 84, 8)     328       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 23, 42, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 12, 19, 38, 32)    6432      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 19, 38, 32)    3104      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 5, 9, 19, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 5, 7, 15, 64)      30784     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 3, 7, 15, 64)      12352     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 7, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2064896   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 27)                6939      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 2,256,571\n",
      "Trainable params: 2,256,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'save_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"working\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.003,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      " 79/391 [=====>........................] - ETA: 13:51 - loss: 0.8229 - acc: 0.78 - ETA: 12:02 - loss: 0.7898 - acc: 0.79 - ETA: 11:13 - loss: 0.8415 - acc: 0.78 - ETA: 11:12 - loss: 0.8170 - acc: 0.79 - ETA: 11:06 - loss: 0.8255 - acc: 0.79 - ETA: 11:04 - loss: 0.8423 - acc: 0.78 - ETA: 11:01 - loss: 0.8317 - acc: 0.79 - ETA: 10:56 - loss: 0.8306 - acc: 0.79 - ETA: 10:59 - loss: 0.8216 - acc: 0.79 - ETA: 10:55 - loss: 0.8130 - acc: 0.80 - ETA: 10:58 - loss: 0.8092 - acc: 0.80 - ETA: 10:58 - loss: 0.8115 - acc: 0.79 - ETA: 10:51 - loss: 0.8115 - acc: 0.80 - ETA: 10:51 - loss: 0.8034 - acc: 0.80 - ETA: 10:47 - loss: 0.8074 - acc: 0.80 - ETA: 10:47 - loss: 0.8025 - acc: 0.80 - ETA: 10:46 - loss: 0.7996 - acc: 0.80 - ETA: 10:42 - loss: 0.8060 - acc: 0.80 - ETA: 10:39 - loss: 0.8035 - acc: 0.80 - ETA: 10:36 - loss: 0.8050 - acc: 0.80 - ETA: 10:36 - loss: 0.8058 - acc: 0.80 - ETA: 10:34 - loss: 0.8035 - acc: 0.80 - ETA: 10:31 - loss: 0.8017 - acc: 0.80 - ETA: 10:28 - loss: 0.8031 - acc: 0.80 - ETA: 10:24 - loss: 0.8009 - acc: 0.80 - ETA: 10:22 - loss: 0.7961 - acc: 0.81 - ETA: 10:19 - loss: 0.7963 - acc: 0.81 - ETA: 10:15 - loss: 0.7911 - acc: 0.81 - ETA: 10:14 - loss: 0.7896 - acc: 0.81 - ETA: 10:12 - loss: 0.7922 - acc: 0.81 - ETA: 10:11 - loss: 0.7911 - acc: 0.81 - ETA: 10:11 - loss: 0.7931 - acc: 0.81 - ETA: 10:08 - loss: 0.7992 - acc: 0.81 - ETA: 10:05 - loss: 0.7968 - acc: 0.81 - ETA: 10:03 - loss: 0.7984 - acc: 0.81 - ETA: 10:01 - loss: 0.7980 - acc: 0.81 - ETA: 9:58 - loss: 0.7967 - acc: 0.8155 - ETA: 9:56 - loss: 0.7953 - acc: 0.816 - ETA: 9:53 - loss: 0.7925 - acc: 0.816 - ETA: 9:50 - loss: 0.7912 - acc: 0.818 - ETA: 9:48 - loss: 0.7992 - acc: 0.816 - ETA: 9:46 - loss: 0.7977 - acc: 0.816 - ETA: 9:45 - loss: 0.7976 - acc: 0.817 - ETA: 9:44 - loss: 0.7941 - acc: 0.820 - ETA: 9:42 - loss: 0.7946 - acc: 0.820 - ETA: 9:39 - loss: 0.7958 - acc: 0.820 - ETA: 9:38 - loss: 0.7973 - acc: 0.819 - ETA: 9:36 - loss: 0.7989 - acc: 0.818 - ETA: 9:35 - loss: 0.7980 - acc: 0.819 - ETA: 9:33 - loss: 0.7957 - acc: 0.820 - ETA: 9:30 - loss: 0.7960 - acc: 0.821 - ETA: 9:28 - loss: 0.7949 - acc: 0.822 - ETA: 9:27 - loss: 0.7923 - acc: 0.823 - ETA: 9:26 - loss: 0.7931 - acc: 0.822 - ETA: 9:24 - loss: 0.7942 - acc: 0.821 - ETA: 9:22 - loss: 0.7968 - acc: 0.820 - ETA: 9:20 - loss: 0.8014 - acc: 0.819 - ETA: 9:18 - loss: 0.7986 - acc: 0.820 - ETA: 9:16 - loss: 0.7978 - acc: 0.819 - ETA: 9:15 - loss: 0.7979 - acc: 0.818 - ETA: 9:14 - loss: 0.7992 - acc: 0.817 - ETA: 9:12 - loss: 0.7989 - acc: 0.817 - ETA: 9:10 - loss: 0.7981 - acc: 0.817 - ETA: 9:08 - loss: 0.7973 - acc: 0.818 - ETA: 9:05 - loss: 0.7957 - acc: 0.819 - ETA: 9:02 - loss: 0.8004 - acc: 0.817 - ETA: 9:00 - loss: 0.8009 - acc: 0.817 - ETA: 8:59 - loss: 0.8011 - acc: 0.817 - ETA: 8:58 - loss: 0.8001 - acc: 0.818 - ETA: 8:54 - loss: 0.7998 - acc: 0.818 - ETA: 8:52 - loss: 0.7988 - acc: 0.818 - ETA: 8:49 - loss: 0.8002 - acc: 0.817 - ETA: 8:48 - loss: 0.8014 - acc: 0.817 - ETA: 8:46 - loss: 0.8038 - acc: 0.816 - ETA: 8:43 - loss: 0.8033 - acc: 0.816 - ETA: 8:42 - loss: 0.8034 - acc: 0.816 - ETA: 8:39 - loss: 0.8035 - acc: 0.816 - ETA: 8:36 - loss: 0.8050 - acc: 0.815 - ETA: 8:33 - loss: 0.8038 - acc: 0.8174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-43ed207aad75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                            \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                            \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                           )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 300\n",
    "batch_size=64\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:1500],batch_size),\n",
    "                           steps_per_epoch=64,\n",
    "                           validation_steps=8,\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "64/64 [==============================] - ETA: 1:58 - loss: 0.7752 - acc: 0.781 - ETA: 1:39 - loss: 0.6924 - acc: 0.843 - ETA: 1:32 - loss: 0.6885 - acc: 0.843 - ETA: 1:27 - loss: 0.6807 - acc: 0.851 - ETA: 1:23 - loss: 0.6826 - acc: 0.865 - ETA: 1:21 - loss: 0.6668 - acc: 0.872 - ETA: 1:19 - loss: 0.6832 - acc: 0.863 - ETA: 1:16 - loss: 0.7077 - acc: 0.859 - ETA: 1:15 - loss: 0.7179 - acc: 0.857 - ETA: 1:13 - loss: 0.7166 - acc: 0.857 - ETA: 1:11 - loss: 0.7075 - acc: 0.860 - ETA: 1:10 - loss: 0.7049 - acc: 0.863 - ETA: 1:08 - loss: 0.7121 - acc: 0.855 - ETA: 1:07 - loss: 0.7159 - acc: 0.853 - ETA: 1:05 - loss: 0.7144 - acc: 0.855 - ETA: 1:04 - loss: 0.7205 - acc: 0.847 - ETA: 1:02 - loss: 0.7171 - acc: 0.848 - ETA: 1:00 - loss: 0.7189 - acc: 0.845 - ETA: 59s - loss: 0.7153 - acc: 0.846 - ETA: 57s - loss: 0.7118 - acc: 0.84 - ETA: 56s - loss: 0.7176 - acc: 0.84 - ETA: 54s - loss: 0.7183 - acc: 0.84 - ETA: 53s - loss: 0.7238 - acc: 0.84 - ETA: 51s - loss: 0.7215 - acc: 0.84 - ETA: 50s - loss: 0.7173 - acc: 0.84 - ETA: 49s - loss: 0.7134 - acc: 0.84 - ETA: 48s - loss: 0.7079 - acc: 0.84 - ETA: 46s - loss: 0.7098 - acc: 0.84 - ETA: 45s - loss: 0.7099 - acc: 0.84 - ETA: 43s - loss: 0.7082 - acc: 0.84 - ETA: 42s - loss: 0.7082 - acc: 0.84 - ETA: 41s - loss: 0.7043 - acc: 0.85 - ETA: 39s - loss: 0.7012 - acc: 0.85 - ETA: 38s - loss: 0.7044 - acc: 0.85 - ETA: 37s - loss: 0.7021 - acc: 0.85 - ETA: 36s - loss: 0.6985 - acc: 0.85 - ETA: 34s - loss: 0.6968 - acc: 0.85 - ETA: 33s - loss: 0.6956 - acc: 0.85 - ETA: 32s - loss: 0.6987 - acc: 0.85 - ETA: 30s - loss: 0.6972 - acc: 0.85 - ETA: 29s - loss: 0.6968 - acc: 0.85 - ETA: 28s - loss: 0.7024 - acc: 0.85 - ETA: 26s - loss: 0.6995 - acc: 0.85 - ETA: 25s - loss: 0.7003 - acc: 0.85 - ETA: 24s - loss: 0.7000 - acc: 0.85 - ETA: 23s - loss: 0.6988 - acc: 0.85 - ETA: 21s - loss: 0.6976 - acc: 0.85 - ETA: 20s - loss: 0.6974 - acc: 0.85 - ETA: 19s - loss: 0.6966 - acc: 0.85 - ETA: 17s - loss: 0.6956 - acc: 0.85 - ETA: 16s - loss: 0.6940 - acc: 0.85 - ETA: 15s - loss: 0.6934 - acc: 0.85 - ETA: 14s - loss: 0.6928 - acc: 0.85 - ETA: 12s - loss: 0.6937 - acc: 0.85 - ETA: 11s - loss: 0.6946 - acc: 0.85 - ETA: 10s - loss: 0.6955 - acc: 0.85 - ETA: 8s - loss: 0.6945 - acc: 0.8542 - ETA: 7s - loss: 0.6949 - acc: 0.854 - ETA: 6s - loss: 0.6932 - acc: 0.854 - ETA: 5s - loss: 0.6942 - acc: 0.854 - ETA: 3s - loss: 0.7005 - acc: 0.852 - ETA: 2s - loss: 0.6991 - acc: 0.853 - ETA: 1s - loss: 0.6994 - acc: 0.852 - 82s 1s/step - loss: 0.6983 - acc: 0.8530 - val_loss: 0.9631 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.80078\n",
      "Epoch 2/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.7767 - acc: 0.81 - ETA: 36s - loss: 0.7072 - acc: 0.87 - ETA: 48s - loss: 0.6757 - acc: 0.86 - ETA: 55s - loss: 0.6619 - acc: 0.87 - ETA: 57s - loss: 0.6700 - acc: 0.87 - ETA: 1:00 - loss: 0.6823 - acc: 0.867 - ETA: 1:00 - loss: 0.6790 - acc: 0.870 - ETA: 1:00 - loss: 0.7016 - acc: 0.853 - ETA: 1:01 - loss: 0.7024 - acc: 0.857 - ETA: 1:00 - loss: 0.7146 - acc: 0.846 - ETA: 59s - loss: 0.7032 - acc: 0.849 - ETA: 58s - loss: 0.7024 - acc: 0.84 - ETA: 57s - loss: 0.7040 - acc: 0.84 - ETA: 57s - loss: 0.7093 - acc: 0.84 - ETA: 56s - loss: 0.7058 - acc: 0.84 - ETA: 54s - loss: 0.7030 - acc: 0.84 - ETA: 53s - loss: 0.7067 - acc: 0.85 - ETA: 52s - loss: 0.7084 - acc: 0.84 - ETA: 50s - loss: 0.7086 - acc: 0.84 - ETA: 49s - loss: 0.7028 - acc: 0.84 - ETA: 48s - loss: 0.7045 - acc: 0.84 - ETA: 47s - loss: 0.6973 - acc: 0.85 - ETA: 46s - loss: 0.6963 - acc: 0.85 - ETA: 45s - loss: 0.7035 - acc: 0.84 - ETA: 44s - loss: 0.7003 - acc: 0.84 - ETA: 43s - loss: 0.7038 - acc: 0.84 - ETA: 41s - loss: 0.7011 - acc: 0.84 - ETA: 40s - loss: 0.7058 - acc: 0.84 - ETA: 39s - loss: 0.7033 - acc: 0.84 - ETA: 38s - loss: 0.6994 - acc: 0.84 - ETA: 37s - loss: 0.6971 - acc: 0.84 - ETA: 36s - loss: 0.6968 - acc: 0.84 - ETA: 34s - loss: 0.7008 - acc: 0.84 - ETA: 33s - loss: 0.6975 - acc: 0.84 - ETA: 32s - loss: 0.6960 - acc: 0.84 - ETA: 31s - loss: 0.6951 - acc: 0.84 - ETA: 30s - loss: 0.6964 - acc: 0.84 - ETA: 29s - loss: 0.6969 - acc: 0.84 - ETA: 27s - loss: 0.7001 - acc: 0.84 - ETA: 26s - loss: 0.6969 - acc: 0.84 - ETA: 25s - loss: 0.7017 - acc: 0.84 - ETA: 24s - loss: 0.7013 - acc: 0.84 - ETA: 23s - loss: 0.7016 - acc: 0.84 - ETA: 22s - loss: 0.7022 - acc: 0.84 - ETA: 21s - loss: 0.7057 - acc: 0.84 - ETA: 19s - loss: 0.7033 - acc: 0.84 - ETA: 18s - loss: 0.7009 - acc: 0.84 - ETA: 17s - loss: 0.6986 - acc: 0.84 - ETA: 16s - loss: 0.6993 - acc: 0.84 - ETA: 15s - loss: 0.6985 - acc: 0.84 - ETA: 14s - loss: 0.6993 - acc: 0.84 - ETA: 13s - loss: 0.7002 - acc: 0.84 - ETA: 12s - loss: 0.6993 - acc: 0.84 - ETA: 10s - loss: 0.6974 - acc: 0.84 - ETA: 9s - loss: 0.6987 - acc: 0.8489 - ETA: 8s - loss: 0.6980 - acc: 0.849 - ETA: 7s - loss: 0.6969 - acc: 0.849 - ETA: 6s - loss: 0.6952 - acc: 0.850 - ETA: 5s - loss: 0.6935 - acc: 0.850 - ETA: 4s - loss: 0.6923 - acc: 0.851 - ETA: 3s - loss: 0.6926 - acc: 0.851 - ETA: 2s - loss: 0.6940 - acc: 0.851 - ETA: 1s - loss: 0.6944 - acc: 0.850 - 71s 1s/step - loss: 0.6940 - acc: 0.8521 - val_loss: 1.0836 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80078\n",
      "Epoch 3/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.6457 - acc: 0.90 - ETA: 32s - loss: 0.6879 - acc: 0.88 - ETA: 44s - loss: 0.7176 - acc: 0.85 - ETA: 51s - loss: 0.7384 - acc: 0.85 - ETA: 53s - loss: 0.7356 - acc: 0.86 - ETA: 54s - loss: 0.7277 - acc: 0.85 - ETA: 54s - loss: 0.7527 - acc: 0.85 - ETA: 53s - loss: 0.7394 - acc: 0.86 - ETA: 53s - loss: 0.7289 - acc: 0.86 - ETA: 52s - loss: 0.7380 - acc: 0.85 - ETA: 51s - loss: 0.7308 - acc: 0.86 - ETA: 51s - loss: 0.7379 - acc: 0.85 - ETA: 50s - loss: 0.7468 - acc: 0.85 - ETA: 49s - loss: 0.7415 - acc: 0.85 - ETA: 48s - loss: 0.7376 - acc: 0.85 - ETA: 47s - loss: 0.7368 - acc: 0.85 - ETA: 47s - loss: 0.7412 - acc: 0.85 - ETA: 46s - loss: 0.7382 - acc: 0.85 - ETA: 45s - loss: 0.7379 - acc: 0.85 - ETA: 44s - loss: 0.7421 - acc: 0.85 - ETA: 43s - loss: 0.7411 - acc: 0.85 - ETA: 41s - loss: 0.7368 - acc: 0.85 - ETA: 40s - loss: 0.7351 - acc: 0.85 - ETA: 40s - loss: 0.7357 - acc: 0.85 - ETA: 39s - loss: 0.7468 - acc: 0.85 - ETA: 38s - loss: 0.7483 - acc: 0.84 - ETA: 37s - loss: 0.7485 - acc: 0.85 - ETA: 36s - loss: 0.7417 - acc: 0.85 - ETA: 35s - loss: 0.7443 - acc: 0.85 - ETA: 34s - loss: 0.7436 - acc: 0.85 - ETA: 33s - loss: 0.7409 - acc: 0.85 - ETA: 32s - loss: 0.7372 - acc: 0.85 - ETA: 30s - loss: 0.7329 - acc: 0.85 - ETA: 29s - loss: 0.7316 - acc: 0.85 - ETA: 28s - loss: 0.7328 - acc: 0.85 - ETA: 27s - loss: 0.7328 - acc: 0.85 - ETA: 26s - loss: 0.7337 - acc: 0.85 - ETA: 25s - loss: 0.7315 - acc: 0.85 - ETA: 25s - loss: 0.7319 - acc: 0.85 - ETA: 23s - loss: 0.7292 - acc: 0.85 - ETA: 22s - loss: 0.7280 - acc: 0.85 - ETA: 21s - loss: 0.7265 - acc: 0.85 - ETA: 20s - loss: 0.7243 - acc: 0.85 - ETA: 19s - loss: 0.7269 - acc: 0.85 - ETA: 18s - loss: 0.7306 - acc: 0.85 - ETA: 17s - loss: 0.7274 - acc: 0.85 - ETA: 16s - loss: 0.7279 - acc: 0.85 - ETA: 15s - loss: 0.7261 - acc: 0.85 - ETA: 14s - loss: 0.7279 - acc: 0.86 - ETA: 13s - loss: 0.7271 - acc: 0.86 - ETA: 12s - loss: 0.7315 - acc: 0.85 - ETA: 11s - loss: 0.7300 - acc: 0.85 - ETA: 10s - loss: 0.7271 - acc: 0.85 - ETA: 9s - loss: 0.7263 - acc: 0.8597 - ETA: 8s - loss: 0.7286 - acc: 0.858 - ETA: 7s - loss: 0.7296 - acc: 0.857 - ETA: 6s - loss: 0.7287 - acc: 0.857 - ETA: 5s - loss: 0.7289 - acc: 0.856 - ETA: 4s - loss: 0.7281 - acc: 0.857 - ETA: 3s - loss: 0.7280 - acc: 0.856 - ETA: 2s - loss: 0.7306 - acc: 0.855 - ETA: 1s - loss: 0.7303 - acc: 0.855 - ETA: 0s - loss: 0.7281 - acc: 0.856 - 65s 1s/step - loss: 0.7263 - acc: 0.8564 - val_loss: 0.9632 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80078\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 24s - loss: 0.8160 - acc: 0.82 - ETA: 24s - loss: 0.7037 - acc: 0.86 - ETA: 32s - loss: 0.7289 - acc: 0.86 - ETA: 40s - loss: 0.7803 - acc: 0.83 - ETA: 44s - loss: 0.7937 - acc: 0.81 - ETA: 47s - loss: 0.7906 - acc: 0.82 - ETA: 46s - loss: 0.7918 - acc: 0.81 - ETA: 48s - loss: 0.7903 - acc: 0.82 - ETA: 47s - loss: 0.7679 - acc: 0.83 - ETA: 47s - loss: 0.7786 - acc: 0.82 - ETA: 47s - loss: 0.7690 - acc: 0.83 - ETA: 46s - loss: 0.7556 - acc: 0.83 - ETA: 46s - loss: 0.7557 - acc: 0.83 - ETA: 45s - loss: 0.7494 - acc: 0.83 - ETA: 45s - loss: 0.7524 - acc: 0.83 - ETA: 44s - loss: 0.7513 - acc: 0.83 - ETA: 43s - loss: 0.7457 - acc: 0.83 - ETA: 42s - loss: 0.7368 - acc: 0.84 - ETA: 41s - loss: 0.7301 - acc: 0.84 - ETA: 40s - loss: 0.7272 - acc: 0.84 - ETA: 39s - loss: 0.7398 - acc: 0.84 - ETA: 38s - loss: 0.7381 - acc: 0.84 - ETA: 37s - loss: 0.7356 - acc: 0.84 - ETA: 36s - loss: 0.7391 - acc: 0.83 - ETA: 35s - loss: 0.7370 - acc: 0.84 - ETA: 34s - loss: 0.7321 - acc: 0.84 - ETA: 33s - loss: 0.7356 - acc: 0.83 - ETA: 32s - loss: 0.7316 - acc: 0.84 - ETA: 32s - loss: 0.7285 - acc: 0.84 - ETA: 31s - loss: 0.7309 - acc: 0.84 - ETA: 30s - loss: 0.7305 - acc: 0.84 - ETA: 29s - loss: 0.7261 - acc: 0.84 - ETA: 28s - loss: 0.7224 - acc: 0.84 - ETA: 27s - loss: 0.7208 - acc: 0.84 - ETA: 26s - loss: 0.7173 - acc: 0.85 - ETA: 25s - loss: 0.7184 - acc: 0.84 - ETA: 24s - loss: 0.7158 - acc: 0.85 - ETA: 23s - loss: 0.7152 - acc: 0.85 - ETA: 22s - loss: 0.7117 - acc: 0.85 - ETA: 21s - loss: 0.7137 - acc: 0.85 - ETA: 21s - loss: 0.7096 - acc: 0.85 - ETA: 20s - loss: 0.7050 - acc: 0.85 - ETA: 19s - loss: 0.7024 - acc: 0.85 - ETA: 18s - loss: 0.7028 - acc: 0.85 - ETA: 17s - loss: 0.7047 - acc: 0.85 - ETA: 16s - loss: 0.7052 - acc: 0.85 - ETA: 15s - loss: 0.7042 - acc: 0.85 - ETA: 14s - loss: 0.7019 - acc: 0.85 - ETA: 13s - loss: 0.7037 - acc: 0.85 - ETA: 12s - loss: 0.7013 - acc: 0.85 - ETA: 11s - loss: 0.7004 - acc: 0.85 - ETA: 10s - loss: 0.7000 - acc: 0.85 - ETA: 10s - loss: 0.6997 - acc: 0.85 - ETA: 9s - loss: 0.7024 - acc: 0.8582 - ETA: 8s - loss: 0.7020 - acc: 0.858 - ETA: 7s - loss: 0.7046 - acc: 0.856 - ETA: 6s - loss: 0.7020 - acc: 0.857 - ETA: 5s - loss: 0.7020 - acc: 0.857 - ETA: 4s - loss: 0.7020 - acc: 0.857 - ETA: 3s - loss: 0.7014 - acc: 0.856 - ETA: 2s - loss: 0.6990 - acc: 0.857 - ETA: 1s - loss: 0.7040 - acc: 0.856 - ETA: 0s - loss: 0.7016 - acc: 0.856 - 60s 938ms/step - loss: 0.7047 - acc: 0.8572 - val_loss: 0.9196 - val_acc: 0.7852\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80078\n",
      "Epoch 5/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.4824 - acc: 0.93 - ETA: 24s - loss: 0.5519 - acc: 0.90 - ETA: 39s - loss: 0.6571 - acc: 0.85 - ETA: 45s - loss: 0.6669 - acc: 0.85 - ETA: 48s - loss: 0.6536 - acc: 0.85 - ETA: 48s - loss: 0.6726 - acc: 0.85 - ETA: 47s - loss: 0.6563 - acc: 0.86 - ETA: 46s - loss: 0.6506 - acc: 0.86 - ETA: 46s - loss: 0.6485 - acc: 0.86 - ETA: 46s - loss: 0.6436 - acc: 0.87 - ETA: 45s - loss: 0.6596 - acc: 0.86 - ETA: 45s - loss: 0.6539 - acc: 0.87 - ETA: 44s - loss: 0.6660 - acc: 0.86 - ETA: 43s - loss: 0.6652 - acc: 0.86 - ETA: 42s - loss: 0.6642 - acc: 0.86 - ETA: 41s - loss: 0.6651 - acc: 0.86 - ETA: 40s - loss: 0.6637 - acc: 0.87 - ETA: 39s - loss: 0.6644 - acc: 0.86 - ETA: 38s - loss: 0.6692 - acc: 0.86 - ETA: 37s - loss: 0.6752 - acc: 0.86 - ETA: 37s - loss: 0.6749 - acc: 0.86 - ETA: 36s - loss: 0.6834 - acc: 0.86 - ETA: 35s - loss: 0.6850 - acc: 0.86 - ETA: 34s - loss: 0.6949 - acc: 0.85 - ETA: 33s - loss: 0.6979 - acc: 0.85 - ETA: 32s - loss: 0.6968 - acc: 0.85 - ETA: 31s - loss: 0.7008 - acc: 0.85 - ETA: 30s - loss: 0.6964 - acc: 0.85 - ETA: 29s - loss: 0.7071 - acc: 0.85 - ETA: 28s - loss: 0.7065 - acc: 0.85 - ETA: 28s - loss: 0.7091 - acc: 0.85 - ETA: 27s - loss: 0.7061 - acc: 0.85 - ETA: 26s - loss: 0.7042 - acc: 0.85 - ETA: 25s - loss: 0.7044 - acc: 0.85 - ETA: 24s - loss: 0.7013 - acc: 0.85 - ETA: 23s - loss: 0.7053 - acc: 0.85 - ETA: 22s - loss: 0.7044 - acc: 0.85 - ETA: 22s - loss: 0.7043 - acc: 0.85 - ETA: 21s - loss: 0.7044 - acc: 0.85 - ETA: 20s - loss: 0.7053 - acc: 0.85 - ETA: 19s - loss: 0.7041 - acc: 0.85 - ETA: 18s - loss: 0.7038 - acc: 0.85 - ETA: 17s - loss: 0.7058 - acc: 0.85 - ETA: 17s - loss: 0.7051 - acc: 0.85 - ETA: 16s - loss: 0.7056 - acc: 0.85 - ETA: 15s - loss: 0.7018 - acc: 0.85 - ETA: 14s - loss: 0.7012 - acc: 0.85 - ETA: 13s - loss: 0.7014 - acc: 0.85 - ETA: 12s - loss: 0.7004 - acc: 0.85 - ETA: 12s - loss: 0.6982 - acc: 0.85 - ETA: 11s - loss: 0.6980 - acc: 0.85 - ETA: 10s - loss: 0.6980 - acc: 0.85 - ETA: 9s - loss: 0.6972 - acc: 0.8535 - ETA: 8s - loss: 0.6972 - acc: 0.853 - ETA: 7s - loss: 0.6957 - acc: 0.854 - ETA: 6s - loss: 0.6953 - acc: 0.853 - ETA: 6s - loss: 0.6941 - acc: 0.853 - ETA: 5s - loss: 0.6915 - acc: 0.854 - ETA: 4s - loss: 0.6935 - acc: 0.854 - ETA: 3s - loss: 0.6928 - acc: 0.854 - ETA: 2s - loss: 0.6912 - acc: 0.854 - ETA: 1s - loss: 0.6915 - acc: 0.854 - ETA: 0s - loss: 0.6915 - acc: 0.854 - 57s 892ms/step - loss: 0.6899 - acc: 0.8552 - val_loss: 0.9834 - val_acc: 0.7793\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80078\n",
      "Epoch 6/25\n",
      "64/64 [==============================] - ETA: 23s - loss: 0.7033 - acc: 0.84 - ETA: 24s - loss: 0.6657 - acc: 0.85 - ETA: 24s - loss: 0.6710 - acc: 0.85 - ETA: 33s - loss: 0.6805 - acc: 0.85 - ETA: 38s - loss: 0.6700 - acc: 0.86 - ETA: 39s - loss: 0.6744 - acc: 0.87 - ETA: 40s - loss: 0.6807 - acc: 0.87 - ETA: 39s - loss: 0.6850 - acc: 0.87 - ETA: 39s - loss: 0.6924 - acc: 0.87 - ETA: 39s - loss: 0.6953 - acc: 0.86 - ETA: 38s - loss: 0.6924 - acc: 0.87 - ETA: 38s - loss: 0.6987 - acc: 0.86 - ETA: 37s - loss: 0.7122 - acc: 0.86 - ETA: 37s - loss: 0.7184 - acc: 0.86 - ETA: 36s - loss: 0.7181 - acc: 0.86 - ETA: 35s - loss: 0.7119 - acc: 0.86 - ETA: 35s - loss: 0.7159 - acc: 0.86 - ETA: 34s - loss: 0.7187 - acc: 0.85 - ETA: 34s - loss: 0.7215 - acc: 0.85 - ETA: 33s - loss: 0.7167 - acc: 0.85 - ETA: 32s - loss: 0.7171 - acc: 0.85 - ETA: 31s - loss: 0.7105 - acc: 0.86 - ETA: 31s - loss: 0.7090 - acc: 0.86 - ETA: 30s - loss: 0.7085 - acc: 0.85 - ETA: 29s - loss: 0.7044 - acc: 0.86 - ETA: 28s - loss: 0.7018 - acc: 0.86 - ETA: 28s - loss: 0.6995 - acc: 0.86 - ETA: 27s - loss: 0.6981 - acc: 0.85 - ETA: 26s - loss: 0.6917 - acc: 0.86 - ETA: 26s - loss: 0.6886 - acc: 0.86 - ETA: 25s - loss: 0.6885 - acc: 0.86 - ETA: 24s - loss: 0.6951 - acc: 0.85 - ETA: 23s - loss: 0.6895 - acc: 0.86 - ETA: 23s - loss: 0.6930 - acc: 0.86 - ETA: 22s - loss: 0.6943 - acc: 0.85 - ETA: 21s - loss: 0.6943 - acc: 0.86 - ETA: 20s - loss: 0.6922 - acc: 0.86 - ETA: 19s - loss: 0.6944 - acc: 0.85 - ETA: 19s - loss: 0.6979 - acc: 0.85 - ETA: 18s - loss: 0.6954 - acc: 0.85 - ETA: 17s - loss: 0.6995 - acc: 0.85 - ETA: 16s - loss: 0.7013 - acc: 0.85 - ETA: 16s - loss: 0.7008 - acc: 0.85 - ETA: 15s - loss: 0.7019 - acc: 0.85 - ETA: 14s - loss: 0.6999 - acc: 0.85 - ETA: 13s - loss: 0.6986 - acc: 0.85 - ETA: 13s - loss: 0.6957 - acc: 0.85 - ETA: 12s - loss: 0.6932 - acc: 0.86 - ETA: 11s - loss: 0.6941 - acc: 0.86 - ETA: 10s - loss: 0.6970 - acc: 0.85 - ETA: 10s - loss: 0.6984 - acc: 0.85 - ETA: 9s - loss: 0.6988 - acc: 0.8582 - ETA: 8s - loss: 0.6973 - acc: 0.858 - ETA: 7s - loss: 0.7003 - acc: 0.857 - ETA: 7s - loss: 0.6990 - acc: 0.857 - ETA: 6s - loss: 0.7008 - acc: 0.856 - ETA: 5s - loss: 0.7026 - acc: 0.855 - ETA: 4s - loss: 0.7027 - acc: 0.854 - ETA: 3s - loss: 0.7042 - acc: 0.854 - ETA: 3s - loss: 0.7030 - acc: 0.854 - ETA: 2s - loss: 0.7004 - acc: 0.855 - ETA: 1s - loss: 0.7011 - acc: 0.854 - ETA: 0s - loss: 0.7000 - acc: 0.855 - 51s 803ms/step - loss: 0.7001 - acc: 0.8542 - val_loss: 1.0484 - val_acc: 0.7598\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80078\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 24s - loss: 0.8683 - acc: 0.76 - ETA: 24s - loss: 0.8348 - acc: 0.82 - ETA: 27s - loss: 0.7902 - acc: 0.82 - ETA: 31s - loss: 0.7357 - acc: 0.85 - ETA: 36s - loss: 0.7470 - acc: 0.84 - ETA: 38s - loss: 0.7637 - acc: 0.83 - ETA: 39s - loss: 0.7520 - acc: 0.85 - ETA: 39s - loss: 0.7281 - acc: 0.85 - ETA: 38s - loss: 0.7195 - acc: 0.86 - ETA: 37s - loss: 0.7078 - acc: 0.86 - ETA: 37s - loss: 0.7123 - acc: 0.85 - ETA: 36s - loss: 0.7123 - acc: 0.85 - ETA: 36s - loss: 0.7065 - acc: 0.86 - ETA: 35s - loss: 0.7004 - acc: 0.86 - ETA: 35s - loss: 0.6942 - acc: 0.86 - ETA: 34s - loss: 0.6932 - acc: 0.86 - ETA: 33s - loss: 0.6923 - acc: 0.85 - ETA: 33s - loss: 0.6859 - acc: 0.86 - ETA: 32s - loss: 0.6825 - acc: 0.86 - ETA: 32s - loss: 0.6855 - acc: 0.86 - ETA: 31s - loss: 0.6886 - acc: 0.86 - ETA: 30s - loss: 0.6821 - acc: 0.86 - ETA: 30s - loss: 0.6888 - acc: 0.86 - ETA: 29s - loss: 0.6891 - acc: 0.86 - ETA: 28s - loss: 0.6841 - acc: 0.86 - ETA: 27s - loss: 0.6815 - acc: 0.86 - ETA: 27s - loss: 0.6816 - acc: 0.86 - ETA: 26s - loss: 0.6831 - acc: 0.86 - ETA: 25s - loss: 0.6773 - acc: 0.86 - ETA: 24s - loss: 0.6746 - acc: 0.86 - ETA: 24s - loss: 0.6798 - acc: 0.86 - ETA: 23s - loss: 0.6870 - acc: 0.86 - ETA: 22s - loss: 0.6873 - acc: 0.86 - ETA: 21s - loss: 0.6878 - acc: 0.86 - ETA: 21s - loss: 0.6903 - acc: 0.86 - ETA: 20s - loss: 0.6896 - acc: 0.86 - ETA: 19s - loss: 0.6891 - acc: 0.86 - ETA: 18s - loss: 0.6929 - acc: 0.86 - ETA: 18s - loss: 0.6953 - acc: 0.86 - ETA: 17s - loss: 0.6940 - acc: 0.86 - ETA: 16s - loss: 0.6946 - acc: 0.86 - ETA: 15s - loss: 0.6921 - acc: 0.86 - ETA: 15s - loss: 0.6920 - acc: 0.86 - ETA: 14s - loss: 0.6937 - acc: 0.86 - ETA: 13s - loss: 0.6932 - acc: 0.86 - ETA: 12s - loss: 0.6946 - acc: 0.86 - ETA: 12s - loss: 0.6947 - acc: 0.86 - ETA: 11s - loss: 0.6962 - acc: 0.86 - ETA: 10s - loss: 0.6971 - acc: 0.86 - ETA: 10s - loss: 0.6970 - acc: 0.86 - ETA: 9s - loss: 0.6954 - acc: 0.8621 - ETA: 8s - loss: 0.6958 - acc: 0.861 - ETA: 7s - loss: 0.6966 - acc: 0.860 - ETA: 7s - loss: 0.6957 - acc: 0.860 - ETA: 6s - loss: 0.6938 - acc: 0.861 - ETA: 5s - loss: 0.6942 - acc: 0.859 - ETA: 5s - loss: 0.6946 - acc: 0.860 - ETA: 4s - loss: 0.6963 - acc: 0.858 - ETA: 3s - loss: 0.6944 - acc: 0.858 - ETA: 2s - loss: 0.6939 - acc: 0.858 - ETA: 2s - loss: 0.6931 - acc: 0.858 - ETA: 1s - loss: 0.6923 - acc: 0.859 - ETA: 0s - loss: 0.6926 - acc: 0.858 - 48s 748ms/step - loss: 0.6948 - acc: 0.8574 - val_loss: 0.9717 - val_acc: 0.7949\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80078\n",
      "Epoch 8/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.6426 - acc: 0.87 - ETA: 25s - loss: 0.6029 - acc: 0.89 - ETA: 24s - loss: 0.6655 - acc: 0.85 - ETA: 27s - loss: 0.6618 - acc: 0.85 - ETA: 29s - loss: 0.6669 - acc: 0.85 - ETA: 31s - loss: 0.6495 - acc: 0.86 - ETA: 32s - loss: 0.6508 - acc: 0.86 - ETA: 32s - loss: 0.6557 - acc: 0.86 - ETA: 32s - loss: 0.6710 - acc: 0.86 - ETA: 32s - loss: 0.6799 - acc: 0.85 - ETA: 32s - loss: 0.6878 - acc: 0.86 - ETA: 31s - loss: 0.6769 - acc: 0.86 - ETA: 32s - loss: 0.6662 - acc: 0.87 - ETA: 31s - loss: 0.6727 - acc: 0.87 - ETA: 31s - loss: 0.6778 - acc: 0.87 - ETA: 30s - loss: 0.6753 - acc: 0.87 - ETA: 30s - loss: 0.6745 - acc: 0.86 - ETA: 29s - loss: 0.6737 - acc: 0.87 - ETA: 28s - loss: 0.6721 - acc: 0.87 - ETA: 27s - loss: 0.6706 - acc: 0.87 - ETA: 27s - loss: 0.6759 - acc: 0.87 - ETA: 26s - loss: 0.6757 - acc: 0.87 - ETA: 25s - loss: 0.6752 - acc: 0.86 - ETA: 25s - loss: 0.6722 - acc: 0.86 - ETA: 24s - loss: 0.6708 - acc: 0.86 - ETA: 24s - loss: 0.6756 - acc: 0.86 - ETA: 23s - loss: 0.6762 - acc: 0.86 - ETA: 23s - loss: 0.6760 - acc: 0.86 - ETA: 22s - loss: 0.6816 - acc: 0.86 - ETA: 21s - loss: 0.6804 - acc: 0.86 - ETA: 21s - loss: 0.6864 - acc: 0.86 - ETA: 20s - loss: 0.6836 - acc: 0.86 - ETA: 19s - loss: 0.6837 - acc: 0.86 - ETA: 19s - loss: 0.6800 - acc: 0.86 - ETA: 18s - loss: 0.6792 - acc: 0.86 - ETA: 18s - loss: 0.6776 - acc: 0.86 - ETA: 17s - loss: 0.6771 - acc: 0.86 - ETA: 16s - loss: 0.6756 - acc: 0.86 - ETA: 16s - loss: 0.6763 - acc: 0.86 - ETA: 15s - loss: 0.6783 - acc: 0.86 - ETA: 14s - loss: 0.6819 - acc: 0.86 - ETA: 14s - loss: 0.6781 - acc: 0.86 - ETA: 13s - loss: 0.6765 - acc: 0.86 - ETA: 12s - loss: 0.6768 - acc: 0.86 - ETA: 12s - loss: 0.6779 - acc: 0.86 - ETA: 11s - loss: 0.6735 - acc: 0.86 - ETA: 11s - loss: 0.6752 - acc: 0.86 - ETA: 10s - loss: 0.6750 - acc: 0.86 - ETA: 9s - loss: 0.6765 - acc: 0.8689 - ETA: 9s - loss: 0.6763 - acc: 0.868 - ETA: 8s - loss: 0.6765 - acc: 0.868 - ETA: 7s - loss: 0.6776 - acc: 0.866 - ETA: 7s - loss: 0.6763 - acc: 0.866 - ETA: 6s - loss: 0.6789 - acc: 0.865 - ETA: 5s - loss: 0.6771 - acc: 0.867 - ETA: 5s - loss: 0.6788 - acc: 0.866 - ETA: 4s - loss: 0.6802 - acc: 0.865 - ETA: 3s - loss: 0.6826 - acc: 0.864 - ETA: 3s - loss: 0.6825 - acc: 0.863 - ETA: 2s - loss: 0.6853 - acc: 0.862 - ETA: 1s - loss: 0.6853 - acc: 0.861 - ETA: 1s - loss: 0.6854 - acc: 0.861 - ETA: 0s - loss: 0.6854 - acc: 0.861 - 44s 682ms/step - loss: 0.6849 - acc: 0.8625 - val_loss: 0.9737 - val_acc: 0.7637\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80078\n",
      "Epoch 9/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.5891 - acc: 0.92 - ETA: 24s - loss: 0.6081 - acc: 0.89 - ETA: 24s - loss: 0.6043 - acc: 0.89 - ETA: 23s - loss: 0.6215 - acc: 0.89 - ETA: 25s - loss: 0.6311 - acc: 0.89 - ETA: 28s - loss: 0.6299 - acc: 0.88 - ETA: 30s - loss: 0.6553 - acc: 0.87 - ETA: 30s - loss: 0.6591 - acc: 0.86 - ETA: 30s - loss: 0.6451 - acc: 0.87 - ETA: 30s - loss: 0.6490 - acc: 0.87 - ETA: 30s - loss: 0.6540 - acc: 0.87 - ETA: 30s - loss: 0.6489 - acc: 0.88 - ETA: 29s - loss: 0.6603 - acc: 0.87 - ETA: 29s - loss: 0.6640 - acc: 0.87 - ETA: 28s - loss: 0.6562 - acc: 0.87 - ETA: 28s - loss: 0.6648 - acc: 0.87 - ETA: 28s - loss: 0.6660 - acc: 0.87 - ETA: 27s - loss: 0.6728 - acc: 0.87 - ETA: 27s - loss: 0.6798 - acc: 0.86 - ETA: 26s - loss: 0.6861 - acc: 0.86 - ETA: 26s - loss: 0.6844 - acc: 0.86 - ETA: 25s - loss: 0.6824 - acc: 0.86 - ETA: 24s - loss: 0.6763 - acc: 0.86 - ETA: 24s - loss: 0.6729 - acc: 0.86 - ETA: 23s - loss: 0.6741 - acc: 0.86 - ETA: 23s - loss: 0.6764 - acc: 0.86 - ETA: 22s - loss: 0.6814 - acc: 0.86 - ETA: 21s - loss: 0.6851 - acc: 0.86 - ETA: 21s - loss: 0.6850 - acc: 0.85 - ETA: 20s - loss: 0.6839 - acc: 0.86 - ETA: 20s - loss: 0.6839 - acc: 0.86 - ETA: 19s - loss: 0.6838 - acc: 0.86 - ETA: 19s - loss: 0.6844 - acc: 0.86 - ETA: 18s - loss: 0.6847 - acc: 0.86 - ETA: 17s - loss: 0.6841 - acc: 0.86 - ETA: 17s - loss: 0.6864 - acc: 0.85 - ETA: 16s - loss: 0.6864 - acc: 0.85 - ETA: 16s - loss: 0.6877 - acc: 0.85 - ETA: 15s - loss: 0.6872 - acc: 0.85 - ETA: 14s - loss: 0.6844 - acc: 0.85 - ETA: 14s - loss: 0.6845 - acc: 0.85 - ETA: 13s - loss: 0.6819 - acc: 0.85 - ETA: 12s - loss: 0.6817 - acc: 0.86 - ETA: 12s - loss: 0.6811 - acc: 0.85 - ETA: 11s - loss: 0.6818 - acc: 0.85 - ETA: 11s - loss: 0.6800 - acc: 0.86 - ETA: 10s - loss: 0.6792 - acc: 0.86 - ETA: 9s - loss: 0.6792 - acc: 0.8607 - ETA: 9s - loss: 0.6810 - acc: 0.860 - ETA: 8s - loss: 0.6807 - acc: 0.859 - ETA: 8s - loss: 0.6802 - acc: 0.858 - ETA: 7s - loss: 0.6786 - acc: 0.859 - ETA: 6s - loss: 0.6783 - acc: 0.860 - ETA: 6s - loss: 0.6787 - acc: 0.860 - ETA: 5s - loss: 0.6790 - acc: 0.860 - ETA: 4s - loss: 0.6767 - acc: 0.862 - ETA: 4s - loss: 0.6746 - acc: 0.862 - ETA: 3s - loss: 0.6748 - acc: 0.862 - ETA: 3s - loss: 0.6744 - acc: 0.862 - ETA: 2s - loss: 0.6764 - acc: 0.861 - ETA: 1s - loss: 0.6747 - acc: 0.862 - ETA: 1s - loss: 0.6749 - acc: 0.861 - ETA: 0s - loss: 0.6740 - acc: 0.862 - 41s 644ms/step - loss: 0.6754 - acc: 0.8621 - val_loss: 0.9669 - val_acc: 0.7852\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80078\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 25s - loss: 0.6639 - acc: 0.84 - ETA: 23s - loss: 0.6897 - acc: 0.83 - ETA: 24s - loss: 0.6534 - acc: 0.85 - ETA: 23s - loss: 0.6278 - acc: 0.87 - ETA: 23s - loss: 0.6391 - acc: 0.86 - ETA: 23s - loss: 0.6665 - acc: 0.85 - ETA: 26s - loss: 0.6837 - acc: 0.84 - ETA: 27s - loss: 0.6792 - acc: 0.84 - ETA: 26s - loss: 0.6869 - acc: 0.84 - ETA: 27s - loss: 0.6914 - acc: 0.85 - ETA: 27s - loss: 0.6956 - acc: 0.84 - ETA: 27s - loss: 0.6904 - acc: 0.84 - ETA: 27s - loss: 0.7030 - acc: 0.84 - ETA: 27s - loss: 0.7024 - acc: 0.84 - ETA: 26s - loss: 0.7013 - acc: 0.84 - ETA: 25s - loss: 0.7023 - acc: 0.84 - ETA: 25s - loss: 0.6996 - acc: 0.85 - ETA: 25s - loss: 0.7011 - acc: 0.85 - ETA: 24s - loss: 0.6973 - acc: 0.85 - ETA: 24s - loss: 0.6901 - acc: 0.85 - ETA: 24s - loss: 0.6976 - acc: 0.85 - ETA: 23s - loss: 0.6987 - acc: 0.85 - ETA: 23s - loss: 0.7016 - acc: 0.85 - ETA: 22s - loss: 0.6990 - acc: 0.85 - ETA: 22s - loss: 0.6960 - acc: 0.85 - ETA: 21s - loss: 0.6942 - acc: 0.85 - ETA: 21s - loss: 0.6932 - acc: 0.85 - ETA: 20s - loss: 0.6988 - acc: 0.85 - ETA: 20s - loss: 0.6962 - acc: 0.85 - ETA: 19s - loss: 0.6986 - acc: 0.85 - ETA: 18s - loss: 0.6992 - acc: 0.85 - ETA: 18s - loss: 0.6981 - acc: 0.85 - ETA: 17s - loss: 0.7006 - acc: 0.85 - ETA: 17s - loss: 0.7044 - acc: 0.85 - ETA: 16s - loss: 0.6997 - acc: 0.85 - ETA: 16s - loss: 0.7015 - acc: 0.85 - ETA: 15s - loss: 0.7000 - acc: 0.85 - ETA: 15s - loss: 0.6983 - acc: 0.85 - ETA: 14s - loss: 0.6964 - acc: 0.85 - ETA: 13s - loss: 0.6961 - acc: 0.85 - ETA: 13s - loss: 0.6963 - acc: 0.85 - ETA: 12s - loss: 0.6977 - acc: 0.85 - ETA: 12s - loss: 0.6969 - acc: 0.85 - ETA: 11s - loss: 0.6935 - acc: 0.85 - ETA: 11s - loss: 0.6940 - acc: 0.85 - ETA: 10s - loss: 0.6962 - acc: 0.85 - ETA: 9s - loss: 0.6956 - acc: 0.8531 - ETA: 9s - loss: 0.6929 - acc: 0.854 - ETA: 8s - loss: 0.6915 - acc: 0.854 - ETA: 8s - loss: 0.6915 - acc: 0.854 - ETA: 7s - loss: 0.6912 - acc: 0.855 - ETA: 7s - loss: 0.6896 - acc: 0.855 - ETA: 6s - loss: 0.6900 - acc: 0.855 - ETA: 5s - loss: 0.6912 - acc: 0.854 - ETA: 5s - loss: 0.6896 - acc: 0.855 - ETA: 4s - loss: 0.6908 - acc: 0.853 - ETA: 4s - loss: 0.6893 - acc: 0.854 - ETA: 3s - loss: 0.6898 - acc: 0.854 - ETA: 2s - loss: 0.6896 - acc: 0.854 - ETA: 2s - loss: 0.6891 - acc: 0.854 - ETA: 1s - loss: 0.6881 - acc: 0.854 - ETA: 1s - loss: 0.6872 - acc: 0.855 - ETA: 0s - loss: 0.6893 - acc: 0.854 - 39s 614ms/step - loss: 0.6893 - acc: 0.8547 - val_loss: 1.0243 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80078\n",
      "Epoch 11/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.6744 - acc: 0.90 - ETA: 24s - loss: 0.6821 - acc: 0.89 - ETA: 24s - loss: 0.6630 - acc: 0.88 - ETA: 23s - loss: 0.6648 - acc: 0.87 - ETA: 23s - loss: 0.6709 - acc: 0.87 - ETA: 24s - loss: 0.6616 - acc: 0.86 - ETA: 25s - loss: 0.6560 - acc: 0.87 - ETA: 26s - loss: 0.6759 - acc: 0.86 - ETA: 26s - loss: 0.6594 - acc: 0.87 - ETA: 26s - loss: 0.6763 - acc: 0.86 - ETA: 26s - loss: 0.6686 - acc: 0.86 - ETA: 26s - loss: 0.6627 - acc: 0.86 - ETA: 26s - loss: 0.6601 - acc: 0.87 - ETA: 26s - loss: 0.6637 - acc: 0.86 - ETA: 26s - loss: 0.6645 - acc: 0.86 - ETA: 25s - loss: 0.6754 - acc: 0.86 - ETA: 25s - loss: 0.6733 - acc: 0.86 - ETA: 25s - loss: 0.6696 - acc: 0.86 - ETA: 24s - loss: 0.6672 - acc: 0.86 - ETA: 24s - loss: 0.6646 - acc: 0.86 - ETA: 23s - loss: 0.6628 - acc: 0.87 - ETA: 23s - loss: 0.6604 - acc: 0.87 - ETA: 22s - loss: 0.6602 - acc: 0.87 - ETA: 22s - loss: 0.6698 - acc: 0.86 - ETA: 21s - loss: 0.6749 - acc: 0.86 - ETA: 21s - loss: 0.6758 - acc: 0.86 - ETA: 20s - loss: 0.6749 - acc: 0.86 - ETA: 20s - loss: 0.6742 - acc: 0.86 - ETA: 19s - loss: 0.6709 - acc: 0.86 - ETA: 18s - loss: 0.6751 - acc: 0.86 - ETA: 18s - loss: 0.6715 - acc: 0.86 - ETA: 17s - loss: 0.6690 - acc: 0.86 - ETA: 17s - loss: 0.6748 - acc: 0.86 - ETA: 16s - loss: 0.6730 - acc: 0.86 - ETA: 16s - loss: 0.6741 - acc: 0.86 - ETA: 15s - loss: 0.6729 - acc: 0.86 - ETA: 15s - loss: 0.6708 - acc: 0.86 - ETA: 14s - loss: 0.6683 - acc: 0.86 - ETA: 14s - loss: 0.6661 - acc: 0.86 - ETA: 13s - loss: 0.6655 - acc: 0.86 - ETA: 13s - loss: 0.6623 - acc: 0.86 - ETA: 12s - loss: 0.6629 - acc: 0.86 - ETA: 11s - loss: 0.6620 - acc: 0.86 - ETA: 11s - loss: 0.6634 - acc: 0.86 - ETA: 10s - loss: 0.6644 - acc: 0.86 - ETA: 10s - loss: 0.6708 - acc: 0.86 - ETA: 9s - loss: 0.6711 - acc: 0.8654 - ETA: 9s - loss: 0.6746 - acc: 0.863 - ETA: 8s - loss: 0.6729 - acc: 0.864 - ETA: 7s - loss: 0.6724 - acc: 0.864 - ETA: 7s - loss: 0.6714 - acc: 0.865 - ETA: 6s - loss: 0.6722 - acc: 0.864 - ETA: 6s - loss: 0.6773 - acc: 0.862 - ETA: 5s - loss: 0.6747 - acc: 0.864 - ETA: 5s - loss: 0.6733 - acc: 0.864 - ETA: 4s - loss: 0.6747 - acc: 0.863 - ETA: 4s - loss: 0.6748 - acc: 0.864 - ETA: 3s - loss: 0.6738 - acc: 0.865 - ETA: 2s - loss: 0.6753 - acc: 0.864 - ETA: 2s - loss: 0.6752 - acc: 0.864 - ETA: 1s - loss: 0.6746 - acc: 0.865 - ETA: 1s - loss: 0.6724 - acc: 0.866 - ETA: 0s - loss: 0.6715 - acc: 0.866 - 38s 600ms/step - loss: 0.6706 - acc: 0.8677 - val_loss: 0.9274 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80078\n",
      "Epoch 12/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.6469 - acc: 0.87 - ETA: 24s - loss: 0.6776 - acc: 0.86 - ETA: 24s - loss: 0.7066 - acc: 0.85 - ETA: 23s - loss: 0.6869 - acc: 0.85 - ETA: 23s - loss: 0.6991 - acc: 0.85 - ETA: 23s - loss: 0.6956 - acc: 0.85 - ETA: 24s - loss: 0.7004 - acc: 0.85 - ETA: 24s - loss: 0.7120 - acc: 0.85 - ETA: 25s - loss: 0.7091 - acc: 0.85 - ETA: 25s - loss: 0.7099 - acc: 0.85 - ETA: 25s - loss: 0.7127 - acc: 0.85 - ETA: 25s - loss: 0.7052 - acc: 0.85 - ETA: 25s - loss: 0.7034 - acc: 0.86 - ETA: 25s - loss: 0.7030 - acc: 0.85 - ETA: 24s - loss: 0.7013 - acc: 0.86 - ETA: 24s - loss: 0.6947 - acc: 0.86 - ETA: 24s - loss: 0.6931 - acc: 0.86 - ETA: 23s - loss: 0.6860 - acc: 0.86 - ETA: 23s - loss: 0.6881 - acc: 0.86 - ETA: 22s - loss: 0.6844 - acc: 0.86 - ETA: 22s - loss: 0.6830 - acc: 0.86 - ETA: 21s - loss: 0.6843 - acc: 0.86 - ETA: 21s - loss: 0.6815 - acc: 0.86 - ETA: 20s - loss: 0.6805 - acc: 0.86 - ETA: 20s - loss: 0.6802 - acc: 0.86 - ETA: 19s - loss: 0.6791 - acc: 0.86 - ETA: 19s - loss: 0.6751 - acc: 0.86 - ETA: 18s - loss: 0.6747 - acc: 0.86 - ETA: 18s - loss: 0.6765 - acc: 0.86 - ETA: 17s - loss: 0.6803 - acc: 0.85 - ETA: 17s - loss: 0.6831 - acc: 0.85 - ETA: 16s - loss: 0.6826 - acc: 0.86 - ETA: 16s - loss: 0.6916 - acc: 0.85 - ETA: 15s - loss: 0.6960 - acc: 0.85 - ETA: 15s - loss: 0.6939 - acc: 0.85 - ETA: 14s - loss: 0.6917 - acc: 0.85 - ETA: 14s - loss: 0.6919 - acc: 0.85 - ETA: 13s - loss: 0.6942 - acc: 0.85 - ETA: 13s - loss: 0.6951 - acc: 0.85 - ETA: 12s - loss: 0.6948 - acc: 0.85 - ETA: 12s - loss: 0.6958 - acc: 0.85 - ETA: 11s - loss: 0.6984 - acc: 0.85 - ETA: 11s - loss: 0.6986 - acc: 0.85 - ETA: 10s - loss: 0.6994 - acc: 0.85 - ETA: 10s - loss: 0.6977 - acc: 0.85 - ETA: 9s - loss: 0.6978 - acc: 0.8529 - ETA: 8s - loss: 0.6994 - acc: 0.852 - ETA: 8s - loss: 0.6993 - acc: 0.851 - ETA: 7s - loss: 0.6993 - acc: 0.851 - ETA: 7s - loss: 0.6994 - acc: 0.850 - ETA: 6s - loss: 0.6991 - acc: 0.851 - ETA: 6s - loss: 0.6998 - acc: 0.851 - ETA: 5s - loss: 0.6991 - acc: 0.851 - ETA: 5s - loss: 0.6994 - acc: 0.851 - ETA: 4s - loss: 0.6991 - acc: 0.850 - ETA: 4s - loss: 0.6981 - acc: 0.851 - ETA: 3s - loss: 0.6976 - acc: 0.852 - ETA: 3s - loss: 0.6997 - acc: 0.851 - ETA: 2s - loss: 0.7020 - acc: 0.850 - ETA: 2s - loss: 0.7010 - acc: 0.851 - ETA: 1s - loss: 0.7011 - acc: 0.851 - ETA: 1s - loss: 0.6992 - acc: 0.852 - ETA: 0s - loss: 0.6973 - acc: 0.853 - 36s 559ms/step - loss: 0.6964 - acc: 0.8540 - val_loss: 1.0125 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80078\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 24s - loss: 0.5849 - acc: 0.90 - ETA: 24s - loss: 0.5799 - acc: 0.92 - ETA: 24s - loss: 0.6058 - acc: 0.89 - ETA: 24s - loss: 0.6117 - acc: 0.90 - ETA: 23s - loss: 0.6643 - acc: 0.87 - ETA: 23s - loss: 0.6717 - acc: 0.86 - ETA: 23s - loss: 0.6758 - acc: 0.87 - ETA: 24s - loss: 0.6852 - acc: 0.86 - ETA: 25s - loss: 0.6646 - acc: 0.87 - ETA: 24s - loss: 0.6720 - acc: 0.87 - ETA: 24s - loss: 0.6583 - acc: 0.87 - ETA: 24s - loss: 0.6574 - acc: 0.87 - ETA: 24s - loss: 0.6596 - acc: 0.87 - ETA: 24s - loss: 0.6567 - acc: 0.87 - ETA: 23s - loss: 0.6592 - acc: 0.87 - ETA: 23s - loss: 0.6676 - acc: 0.86 - ETA: 23s - loss: 0.6679 - acc: 0.86 - ETA: 22s - loss: 0.6599 - acc: 0.86 - ETA: 22s - loss: 0.6580 - acc: 0.86 - ETA: 21s - loss: 0.6569 - acc: 0.86 - ETA: 21s - loss: 0.6682 - acc: 0.86 - ETA: 20s - loss: 0.6626 - acc: 0.86 - ETA: 20s - loss: 0.6630 - acc: 0.86 - ETA: 20s - loss: 0.6616 - acc: 0.86 - ETA: 19s - loss: 0.6620 - acc: 0.86 - ETA: 19s - loss: 0.6665 - acc: 0.86 - ETA: 18s - loss: 0.6673 - acc: 0.86 - ETA: 18s - loss: 0.6718 - acc: 0.86 - ETA: 17s - loss: 0.6721 - acc: 0.86 - ETA: 17s - loss: 0.6763 - acc: 0.86 - ETA: 16s - loss: 0.6709 - acc: 0.86 - ETA: 16s - loss: 0.6715 - acc: 0.86 - ETA: 15s - loss: 0.6702 - acc: 0.86 - ETA: 15s - loss: 0.6700 - acc: 0.86 - ETA: 14s - loss: 0.6716 - acc: 0.86 - ETA: 14s - loss: 0.6709 - acc: 0.86 - ETA: 13s - loss: 0.6679 - acc: 0.86 - ETA: 13s - loss: 0.6669 - acc: 0.86 - ETA: 12s - loss: 0.6646 - acc: 0.86 - ETA: 12s - loss: 0.6641 - acc: 0.86 - ETA: 11s - loss: 0.6621 - acc: 0.86 - ETA: 11s - loss: 0.6663 - acc: 0.86 - ETA: 10s - loss: 0.6661 - acc: 0.86 - ETA: 10s - loss: 0.6657 - acc: 0.86 - ETA: 9s - loss: 0.6663 - acc: 0.8653 - ETA: 9s - loss: 0.6657 - acc: 0.865 - ETA: 8s - loss: 0.6647 - acc: 0.866 - ETA: 8s - loss: 0.6669 - acc: 0.865 - ETA: 7s - loss: 0.6671 - acc: 0.864 - ETA: 7s - loss: 0.6672 - acc: 0.865 - ETA: 6s - loss: 0.6648 - acc: 0.866 - ETA: 6s - loss: 0.6653 - acc: 0.865 - ETA: 5s - loss: 0.6688 - acc: 0.863 - ETA: 5s - loss: 0.6685 - acc: 0.864 - ETA: 4s - loss: 0.6666 - acc: 0.864 - ETA: 4s - loss: 0.6685 - acc: 0.863 - ETA: 3s - loss: 0.6685 - acc: 0.864 - ETA: 3s - loss: 0.6693 - acc: 0.865 - ETA: 2s - loss: 0.6710 - acc: 0.863 - ETA: 2s - loss: 0.6704 - acc: 0.864 - ETA: 1s - loss: 0.6707 - acc: 0.863 - ETA: 1s - loss: 0.6726 - acc: 0.863 - ETA: 0s - loss: 0.6742 - acc: 0.862 - 35s 540ms/step - loss: 0.6725 - acc: 0.8628 - val_loss: 0.9914 - val_acc: 0.7852\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80078\n",
      "Epoch 14/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.8049 - acc: 0.84 - ETA: 25s - loss: 0.7639 - acc: 0.84 - ETA: 24s - loss: 0.7471 - acc: 0.85 - ETA: 24s - loss: 0.7215 - acc: 0.87 - ETA: 23s - loss: 0.6967 - acc: 0.87 - ETA: 23s - loss: 0.6808 - acc: 0.87 - ETA: 23s - loss: 0.6902 - acc: 0.86 - ETA: 23s - loss: 0.6788 - acc: 0.86 - ETA: 23s - loss: 0.6870 - acc: 0.86 - ETA: 24s - loss: 0.6913 - acc: 0.86 - ETA: 24s - loss: 0.6865 - acc: 0.86 - ETA: 24s - loss: 0.6804 - acc: 0.87 - ETA: 23s - loss: 0.6759 - acc: 0.87 - ETA: 23s - loss: 0.6644 - acc: 0.87 - ETA: 23s - loss: 0.6644 - acc: 0.87 - ETA: 23s - loss: 0.6669 - acc: 0.87 - ETA: 22s - loss: 0.6670 - acc: 0.87 - ETA: 22s - loss: 0.6731 - acc: 0.87 - ETA: 21s - loss: 0.6672 - acc: 0.87 - ETA: 21s - loss: 0.6662 - acc: 0.87 - ETA: 21s - loss: 0.6717 - acc: 0.87 - ETA: 20s - loss: 0.6731 - acc: 0.87 - ETA: 20s - loss: 0.6782 - acc: 0.87 - ETA: 20s - loss: 0.6752 - acc: 0.87 - ETA: 19s - loss: 0.6818 - acc: 0.86 - ETA: 19s - loss: 0.6760 - acc: 0.87 - ETA: 18s - loss: 0.6744 - acc: 0.87 - ETA: 18s - loss: 0.6763 - acc: 0.87 - ETA: 17s - loss: 0.6786 - acc: 0.87 - ETA: 17s - loss: 0.6786 - acc: 0.87 - ETA: 16s - loss: 0.6783 - acc: 0.87 - ETA: 16s - loss: 0.6755 - acc: 0.87 - ETA: 15s - loss: 0.6795 - acc: 0.87 - ETA: 15s - loss: 0.6849 - acc: 0.86 - ETA: 14s - loss: 0.6815 - acc: 0.87 - ETA: 14s - loss: 0.6800 - acc: 0.86 - ETA: 13s - loss: 0.6798 - acc: 0.86 - ETA: 13s - loss: 0.6786 - acc: 0.86 - ETA: 12s - loss: 0.6784 - acc: 0.86 - ETA: 12s - loss: 0.6779 - acc: 0.86 - ETA: 11s - loss: 0.6736 - acc: 0.87 - ETA: 11s - loss: 0.6746 - acc: 0.86 - ETA: 10s - loss: 0.6759 - acc: 0.86 - ETA: 10s - loss: 0.6768 - acc: 0.86 - ETA: 9s - loss: 0.6750 - acc: 0.8694 - ETA: 9s - loss: 0.6754 - acc: 0.868 - ETA: 8s - loss: 0.6726 - acc: 0.869 - ETA: 8s - loss: 0.6732 - acc: 0.869 - ETA: 7s - loss: 0.6733 - acc: 0.868 - ETA: 7s - loss: 0.6729 - acc: 0.869 - ETA: 6s - loss: 0.6759 - acc: 0.868 - ETA: 6s - loss: 0.6767 - acc: 0.868 - ETA: 5s - loss: 0.6786 - acc: 0.867 - ETA: 5s - loss: 0.6779 - acc: 0.867 - ETA: 4s - loss: 0.6756 - acc: 0.868 - ETA: 4s - loss: 0.6755 - acc: 0.869 - ETA: 3s - loss: 0.6738 - acc: 0.869 - ETA: 3s - loss: 0.6749 - acc: 0.869 - ETA: 2s - loss: 0.6738 - acc: 0.869 - ETA: 2s - loss: 0.6753 - acc: 0.869 - ETA: 1s - loss: 0.6774 - acc: 0.868 - ETA: 1s - loss: 0.6758 - acc: 0.868 - ETA: 0s - loss: 0.6796 - acc: 0.866 - 34s 535ms/step - loss: 0.6777 - acc: 0.8677 - val_loss: 1.0595 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80078\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 15/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.7118 - acc: 0.79 - ETA: 24s - loss: 0.6875 - acc: 0.82 - ETA: 24s - loss: 0.6596 - acc: 0.84 - ETA: 23s - loss: 0.6795 - acc: 0.85 - ETA: 23s - loss: 0.6975 - acc: 0.84 - ETA: 23s - loss: 0.6830 - acc: 0.85 - ETA: 22s - loss: 0.6919 - acc: 0.85 - ETA: 22s - loss: 0.6951 - acc: 0.85 - ETA: 21s - loss: 0.6855 - acc: 0.85 - ETA: 22s - loss: 0.6866 - acc: 0.85 - ETA: 22s - loss: 0.6895 - acc: 0.85 - ETA: 22s - loss: 0.6987 - acc: 0.85 - ETA: 21s - loss: 0.7080 - acc: 0.85 - ETA: 21s - loss: 0.7004 - acc: 0.85 - ETA: 21s - loss: 0.6932 - acc: 0.85 - ETA: 20s - loss: 0.6911 - acc: 0.85 - ETA: 20s - loss: 0.6872 - acc: 0.86 - ETA: 20s - loss: 0.6807 - acc: 0.86 - ETA: 20s - loss: 0.6782 - acc: 0.86 - ETA: 19s - loss: 0.6868 - acc: 0.85 - ETA: 19s - loss: 0.6832 - acc: 0.85 - ETA: 19s - loss: 0.6818 - acc: 0.86 - ETA: 18s - loss: 0.6847 - acc: 0.86 - ETA: 18s - loss: 0.6847 - acc: 0.85 - ETA: 17s - loss: 0.6838 - acc: 0.86 - ETA: 17s - loss: 0.6787 - acc: 0.86 - ETA: 17s - loss: 0.6782 - acc: 0.86 - ETA: 16s - loss: 0.6806 - acc: 0.86 - ETA: 16s - loss: 0.6861 - acc: 0.86 - ETA: 15s - loss: 0.6891 - acc: 0.86 - ETA: 15s - loss: 0.6911 - acc: 0.86 - ETA: 14s - loss: 0.6905 - acc: 0.86 - ETA: 14s - loss: 0.6932 - acc: 0.86 - ETA: 14s - loss: 0.6969 - acc: 0.86 - ETA: 13s - loss: 0.6977 - acc: 0.86 - ETA: 13s - loss: 0.6934 - acc: 0.86 - ETA: 12s - loss: 0.6905 - acc: 0.86 - ETA: 12s - loss: 0.6887 - acc: 0.86 - ETA: 11s - loss: 0.6885 - acc: 0.86 - ETA: 11s - loss: 0.6911 - acc: 0.86 - ETA: 10s - loss: 0.6914 - acc: 0.86 - ETA: 10s - loss: 0.6925 - acc: 0.86 - ETA: 9s - loss: 0.6944 - acc: 0.8619 - ETA: 9s - loss: 0.6936 - acc: 0.862 - ETA: 9s - loss: 0.6928 - acc: 0.862 - ETA: 8s - loss: 0.6908 - acc: 0.863 - ETA: 8s - loss: 0.6900 - acc: 0.863 - ETA: 7s - loss: 0.6908 - acc: 0.862 - ETA: 7s - loss: 0.6933 - acc: 0.861 - ETA: 6s - loss: 0.6929 - acc: 0.862 - ETA: 6s - loss: 0.6935 - acc: 0.863 - ETA: 5s - loss: 0.6925 - acc: 0.862 - ETA: 5s - loss: 0.6934 - acc: 0.862 - ETA: 4s - loss: 0.6915 - acc: 0.863 - ETA: 4s - loss: 0.6914 - acc: 0.863 - ETA: 3s - loss: 0.6896 - acc: 0.863 - ETA: 3s - loss: 0.6885 - acc: 0.864 - ETA: 2s - loss: 0.6883 - acc: 0.864 - ETA: 2s - loss: 0.6874 - acc: 0.865 - ETA: 1s - loss: 0.6873 - acc: 0.864 - ETA: 1s - loss: 0.6867 - acc: 0.865 - ETA: 0s - loss: 0.6869 - acc: 0.865 - ETA: 0s - loss: 0.6874 - acc: 0.865 - 32s 506ms/step - loss: 0.6891 - acc: 0.8647 - val_loss: 0.9887 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80078\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 25s - loss: 0.6898 - acc: 0.87 - ETA: 24s - loss: 0.7179 - acc: 0.84 - ETA: 24s - loss: 0.6725 - acc: 0.86 - ETA: 23s - loss: 0.6670 - acc: 0.86 - ETA: 23s - loss: 0.6408 - acc: 0.87 - ETA: 22s - loss: 0.6476 - acc: 0.87 - ETA: 22s - loss: 0.6358 - acc: 0.88 - ETA: 22s - loss: 0.6430 - acc: 0.87 - ETA: 21s - loss: 0.6320 - acc: 0.87 - ETA: 21s - loss: 0.6309 - acc: 0.87 - ETA: 21s - loss: 0.6261 - acc: 0.88 - ETA: 21s - loss: 0.6216 - acc: 0.88 - ETA: 21s - loss: 0.6206 - acc: 0.88 - ETA: 20s - loss: 0.6135 - acc: 0.88 - ETA: 20s - loss: 0.6160 - acc: 0.88 - ETA: 20s - loss: 0.6171 - acc: 0.87 - ETA: 20s - loss: 0.6199 - acc: 0.87 - ETA: 20s - loss: 0.6256 - acc: 0.87 - ETA: 19s - loss: 0.6212 - acc: 0.87 - ETA: 19s - loss: 0.6190 - acc: 0.87 - ETA: 19s - loss: 0.6119 - acc: 0.87 - ETA: 18s - loss: 0.6098 - acc: 0.88 - ETA: 18s - loss: 0.6149 - acc: 0.88 - ETA: 18s - loss: 0.6193 - acc: 0.87 - ETA: 17s - loss: 0.6188 - acc: 0.88 - ETA: 17s - loss: 0.6159 - acc: 0.88 - ETA: 16s - loss: 0.6142 - acc: 0.88 - ETA: 16s - loss: 0.6176 - acc: 0.88 - ETA: 15s - loss: 0.6176 - acc: 0.88 - ETA: 15s - loss: 0.6190 - acc: 0.87 - ETA: 15s - loss: 0.6216 - acc: 0.87 - ETA: 14s - loss: 0.6213 - acc: 0.87 - ETA: 14s - loss: 0.6233 - acc: 0.87 - ETA: 13s - loss: 0.6266 - acc: 0.87 - ETA: 13s - loss: 0.6269 - acc: 0.87 - ETA: 12s - loss: 0.6271 - acc: 0.87 - ETA: 12s - loss: 0.6270 - acc: 0.87 - ETA: 12s - loss: 0.6326 - acc: 0.87 - ETA: 11s - loss: 0.6309 - acc: 0.87 - ETA: 11s - loss: 0.6350 - acc: 0.87 - ETA: 10s - loss: 0.6380 - acc: 0.87 - ETA: 10s - loss: 0.6389 - acc: 0.87 - ETA: 9s - loss: 0.6434 - acc: 0.8743 - ETA: 9s - loss: 0.6441 - acc: 0.873 - ETA: 8s - loss: 0.6429 - acc: 0.873 - ETA: 8s - loss: 0.6425 - acc: 0.874 - ETA: 7s - loss: 0.6429 - acc: 0.875 - ETA: 7s - loss: 0.6441 - acc: 0.874 - ETA: 6s - loss: 0.6438 - acc: 0.875 - ETA: 6s - loss: 0.6425 - acc: 0.875 - ETA: 6s - loss: 0.6426 - acc: 0.875 - ETA: 5s - loss: 0.6485 - acc: 0.872 - ETA: 5s - loss: 0.6476 - acc: 0.872 - ETA: 4s - loss: 0.6470 - acc: 0.873 - ETA: 4s - loss: 0.6474 - acc: 0.873 - ETA: 3s - loss: 0.6482 - acc: 0.872 - ETA: 3s - loss: 0.6471 - acc: 0.873 - ETA: 2s - loss: 0.6472 - acc: 0.873 - ETA: 2s - loss: 0.6478 - acc: 0.873 - ETA: 1s - loss: 0.6527 - acc: 0.872 - ETA: 1s - loss: 0.6516 - acc: 0.873 - ETA: 0s - loss: 0.6517 - acc: 0.873 - ETA: 0s - loss: 0.6521 - acc: 0.873 - 31s 490ms/step - loss: 0.6520 - acc: 0.8743 - val_loss: 1.0453 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80078\n",
      "Epoch 17/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.6908 - acc: 0.82 - ETA: 24s - loss: 0.6879 - acc: 0.82 - ETA: 24s - loss: 0.6758 - acc: 0.85 - ETA: 23s - loss: 0.6731 - acc: 0.85 - ETA: 23s - loss: 0.6635 - acc: 0.86 - ETA: 23s - loss: 0.6942 - acc: 0.85 - ETA: 22s - loss: 0.6971 - acc: 0.85 - ETA: 22s - loss: 0.6915 - acc: 0.85 - ETA: 21s - loss: 0.6887 - acc: 0.85 - ETA: 21s - loss: 0.6768 - acc: 0.86 - ETA: 20s - loss: 0.6733 - acc: 0.86 - ETA: 20s - loss: 0.6895 - acc: 0.86 - ETA: 20s - loss: 0.6840 - acc: 0.86 - ETA: 20s - loss: 0.6745 - acc: 0.87 - ETA: 20s - loss: 0.6786 - acc: 0.86 - ETA: 19s - loss: 0.6732 - acc: 0.86 - ETA: 19s - loss: 0.6670 - acc: 0.87 - ETA: 19s - loss: 0.6701 - acc: 0.86 - ETA: 19s - loss: 0.6706 - acc: 0.86 - ETA: 18s - loss: 0.6733 - acc: 0.86 - ETA: 18s - loss: 0.6695 - acc: 0.86 - ETA: 18s - loss: 0.6650 - acc: 0.87 - ETA: 17s - loss: 0.6673 - acc: 0.87 - ETA: 17s - loss: 0.6612 - acc: 0.87 - ETA: 17s - loss: 0.6611 - acc: 0.87 - ETA: 16s - loss: 0.6637 - acc: 0.87 - ETA: 16s - loss: 0.6635 - acc: 0.87 - ETA: 16s - loss: 0.6692 - acc: 0.86 - ETA: 15s - loss: 0.6674 - acc: 0.86 - ETA: 15s - loss: 0.6637 - acc: 0.87 - ETA: 14s - loss: 0.6599 - acc: 0.87 - ETA: 14s - loss: 0.6644 - acc: 0.87 - ETA: 13s - loss: 0.6615 - acc: 0.87 - ETA: 13s - loss: 0.6638 - acc: 0.87 - ETA: 13s - loss: 0.6632 - acc: 0.87 - ETA: 12s - loss: 0.6655 - acc: 0.87 - ETA: 12s - loss: 0.6677 - acc: 0.86 - ETA: 11s - loss: 0.6648 - acc: 0.86 - ETA: 11s - loss: 0.6640 - acc: 0.86 - ETA: 10s - loss: 0.6724 - acc: 0.86 - ETA: 10s - loss: 0.6746 - acc: 0.86 - ETA: 9s - loss: 0.6714 - acc: 0.8679 - ETA: 9s - loss: 0.6766 - acc: 0.865 - ETA: 9s - loss: 0.6734 - acc: 0.867 - ETA: 8s - loss: 0.6715 - acc: 0.868 - ETA: 8s - loss: 0.6688 - acc: 0.869 - ETA: 7s - loss: 0.6709 - acc: 0.868 - ETA: 7s - loss: 0.6736 - acc: 0.866 - ETA: 6s - loss: 0.6719 - acc: 0.867 - ETA: 6s - loss: 0.6672 - acc: 0.869 - ETA: 5s - loss: 0.6683 - acc: 0.867 - ETA: 5s - loss: 0.6733 - acc: 0.866 - ETA: 4s - loss: 0.6766 - acc: 0.864 - ETA: 4s - loss: 0.6742 - acc: 0.866 - ETA: 4s - loss: 0.6754 - acc: 0.865 - ETA: 3s - loss: 0.6749 - acc: 0.865 - ETA: 3s - loss: 0.6746 - acc: 0.865 - ETA: 2s - loss: 0.6744 - acc: 0.866 - ETA: 2s - loss: 0.6738 - acc: 0.866 - ETA: 1s - loss: 0.6732 - acc: 0.865 - ETA: 1s - loss: 0.6750 - acc: 0.864 - ETA: 0s - loss: 0.6747 - acc: 0.864 - ETA: 0s - loss: 0.6772 - acc: 0.864 - 31s 482ms/step - loss: 0.6766 - acc: 0.8647 - val_loss: 1.0068 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80078\n",
      "Epoch 18/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.6487 - acc: 0.89 - ETA: 24s - loss: 0.7270 - acc: 0.85 - ETA: 24s - loss: 0.6745 - acc: 0.86 - ETA: 23s - loss: 0.6428 - acc: 0.88 - ETA: 23s - loss: 0.6402 - acc: 0.88 - ETA: 22s - loss: 0.6530 - acc: 0.88 - ETA: 22s - loss: 0.6802 - acc: 0.87 - ETA: 22s - loss: 0.6699 - acc: 0.87 - ETA: 21s - loss: 0.6820 - acc: 0.87 - ETA: 21s - loss: 0.6722 - acc: 0.87 - ETA: 20s - loss: 0.6668 - acc: 0.87 - ETA: 20s - loss: 0.6707 - acc: 0.86 - ETA: 20s - loss: 0.6792 - acc: 0.86 - ETA: 20s - loss: 0.6762 - acc: 0.86 - ETA: 20s - loss: 0.6737 - acc: 0.86 - ETA: 19s - loss: 0.6827 - acc: 0.86 - ETA: 19s - loss: 0.6803 - acc: 0.86 - ETA: 19s - loss: 0.6769 - acc: 0.86 - ETA: 19s - loss: 0.6692 - acc: 0.87 - ETA: 18s - loss: 0.6656 - acc: 0.87 - ETA: 18s - loss: 0.6630 - acc: 0.87 - ETA: 17s - loss: 0.6657 - acc: 0.87 - ETA: 17s - loss: 0.6719 - acc: 0.87 - ETA: 17s - loss: 0.6771 - acc: 0.87 - ETA: 16s - loss: 0.6726 - acc: 0.87 - ETA: 16s - loss: 0.6745 - acc: 0.87 - ETA: 15s - loss: 0.6750 - acc: 0.86 - ETA: 15s - loss: 0.6722 - acc: 0.87 - ETA: 15s - loss: 0.6729 - acc: 0.87 - ETA: 14s - loss: 0.6745 - acc: 0.87 - ETA: 14s - loss: 0.6736 - acc: 0.87 - ETA: 13s - loss: 0.6727 - acc: 0.87 - ETA: 13s - loss: 0.6718 - acc: 0.87 - ETA: 13s - loss: 0.6706 - acc: 0.86 - ETA: 12s - loss: 0.6682 - acc: 0.86 - ETA: 12s - loss: 0.6693 - acc: 0.86 - ETA: 12s - loss: 0.6695 - acc: 0.86 - ETA: 11s - loss: 0.6675 - acc: 0.86 - ETA: 11s - loss: 0.6685 - acc: 0.86 - ETA: 10s - loss: 0.6729 - acc: 0.86 - ETA: 10s - loss: 0.6763 - acc: 0.86 - ETA: 9s - loss: 0.6781 - acc: 0.8646 - ETA: 9s - loss: 0.6800 - acc: 0.864 - ETA: 9s - loss: 0.6770 - acc: 0.865 - ETA: 8s - loss: 0.6778 - acc: 0.864 - ETA: 8s - loss: 0.6785 - acc: 0.864 - ETA: 7s - loss: 0.6789 - acc: 0.863 - ETA: 7s - loss: 0.6790 - acc: 0.863 - ETA: 6s - loss: 0.6769 - acc: 0.864 - ETA: 6s - loss: 0.6765 - acc: 0.864 - ETA: 5s - loss: 0.6765 - acc: 0.865 - ETA: 5s - loss: 0.6770 - acc: 0.864 - ETA: 5s - loss: 0.6778 - acc: 0.864 - ETA: 4s - loss: 0.6775 - acc: 0.864 - ETA: 4s - loss: 0.6792 - acc: 0.863 - ETA: 3s - loss: 0.6787 - acc: 0.864 - ETA: 3s - loss: 0.6761 - acc: 0.865 - ETA: 2s - loss: 0.6760 - acc: 0.865 - ETA: 2s - loss: 0.6740 - acc: 0.866 - ETA: 1s - loss: 0.6750 - acc: 0.865 - ETA: 1s - loss: 0.6776 - acc: 0.864 - ETA: 0s - loss: 0.6772 - acc: 0.864 - ETA: 0s - loss: 0.6776 - acc: 0.863 - 31s 481ms/step - loss: 0.6797 - acc: 0.8635 - val_loss: 1.0024 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80078\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 24s - loss: 0.7261 - acc: 0.81 - ETA: 24s - loss: 0.6672 - acc: 0.88 - ETA: 24s - loss: 0.7835 - acc: 0.83 - ETA: 23s - loss: 0.7498 - acc: 0.86 - ETA: 23s - loss: 0.7510 - acc: 0.87 - ETA: 22s - loss: 0.7287 - acc: 0.87 - ETA: 22s - loss: 0.7243 - acc: 0.87 - ETA: 22s - loss: 0.7116 - acc: 0.87 - ETA: 21s - loss: 0.7109 - acc: 0.87 - ETA: 21s - loss: 0.6972 - acc: 0.88 - ETA: 20s - loss: 0.7070 - acc: 0.87 - ETA: 20s - loss: 0.6994 - acc: 0.87 - ETA: 19s - loss: 0.7070 - acc: 0.87 - ETA: 19s - loss: 0.6960 - acc: 0.87 - ETA: 19s - loss: 0.6898 - acc: 0.88 - ETA: 19s - loss: 0.6846 - acc: 0.88 - ETA: 18s - loss: 0.6773 - acc: 0.88 - ETA: 18s - loss: 0.6758 - acc: 0.88 - ETA: 18s - loss: 0.6738 - acc: 0.88 - ETA: 18s - loss: 0.6752 - acc: 0.88 - ETA: 17s - loss: 0.6738 - acc: 0.88 - ETA: 17s - loss: 0.6799 - acc: 0.87 - ETA: 17s - loss: 0.6764 - acc: 0.87 - ETA: 17s - loss: 0.6700 - acc: 0.88 - ETA: 16s - loss: 0.6686 - acc: 0.88 - ETA: 16s - loss: 0.6688 - acc: 0.88 - ETA: 15s - loss: 0.6677 - acc: 0.88 - ETA: 15s - loss: 0.6601 - acc: 0.88 - ETA: 15s - loss: 0.6607 - acc: 0.88 - ETA: 14s - loss: 0.6603 - acc: 0.88 - ETA: 14s - loss: 0.6598 - acc: 0.88 - ETA: 14s - loss: 0.6579 - acc: 0.88 - ETA: 13s - loss: 0.6591 - acc: 0.88 - ETA: 13s - loss: 0.6609 - acc: 0.88 - ETA: 12s - loss: 0.6610 - acc: 0.88 - ETA: 12s - loss: 0.6588 - acc: 0.88 - ETA: 12s - loss: 0.6582 - acc: 0.88 - ETA: 11s - loss: 0.6596 - acc: 0.88 - ETA: 11s - loss: 0.6609 - acc: 0.87 - ETA: 10s - loss: 0.6634 - acc: 0.87 - ETA: 10s - loss: 0.6643 - acc: 0.87 - ETA: 9s - loss: 0.6653 - acc: 0.8780 - ETA: 9s - loss: 0.6623 - acc: 0.879 - ETA: 8s - loss: 0.6634 - acc: 0.877 - ETA: 8s - loss: 0.6623 - acc: 0.878 - ETA: 8s - loss: 0.6606 - acc: 0.879 - ETA: 7s - loss: 0.6621 - acc: 0.878 - ETA: 7s - loss: 0.6625 - acc: 0.878 - ETA: 6s - loss: 0.6612 - acc: 0.878 - ETA: 6s - loss: 0.6599 - acc: 0.879 - ETA: 5s - loss: 0.6655 - acc: 0.877 - ETA: 5s - loss: 0.6654 - acc: 0.877 - ETA: 4s - loss: 0.6664 - acc: 0.876 - ETA: 4s - loss: 0.6686 - acc: 0.875 - ETA: 4s - loss: 0.6667 - acc: 0.877 - ETA: 3s - loss: 0.6677 - acc: 0.876 - ETA: 3s - loss: 0.6662 - acc: 0.876 - ETA: 2s - loss: 0.6665 - acc: 0.875 - ETA: 2s - loss: 0.6636 - acc: 0.876 - ETA: 1s - loss: 0.6640 - acc: 0.876 - ETA: 1s - loss: 0.6654 - acc: 0.876 - ETA: 0s - loss: 0.6633 - acc: 0.877 - ETA: 0s - loss: 0.6612 - acc: 0.878 - 31s 477ms/step - loss: 0.6603 - acc: 0.8787 - val_loss: 1.0156 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80078\n",
      "Epoch 20/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.6823 - acc: 0.89 - ETA: 24s - loss: 0.6640 - acc: 0.89 - ETA: 24s - loss: 0.6329 - acc: 0.89 - ETA: 23s - loss: 0.6383 - acc: 0.88 - ETA: 23s - loss: 0.6376 - acc: 0.89 - ETA: 23s - loss: 0.6520 - acc: 0.89 - ETA: 22s - loss: 0.6603 - acc: 0.89 - ETA: 22s - loss: 0.6597 - acc: 0.88 - ETA: 21s - loss: 0.6790 - acc: 0.87 - ETA: 21s - loss: 0.6796 - acc: 0.87 - ETA: 20s - loss: 0.6663 - acc: 0.87 - ETA: 20s - loss: 0.6729 - acc: 0.87 - ETA: 20s - loss: 0.6652 - acc: 0.88 - ETA: 19s - loss: 0.6695 - acc: 0.87 - ETA: 19s - loss: 0.6619 - acc: 0.88 - ETA: 18s - loss: 0.6665 - acc: 0.87 - ETA: 18s - loss: 0.6583 - acc: 0.87 - ETA: 18s - loss: 0.6577 - acc: 0.87 - ETA: 17s - loss: 0.6617 - acc: 0.87 - ETA: 17s - loss: 0.6657 - acc: 0.87 - ETA: 17s - loss: 0.6607 - acc: 0.87 - ETA: 16s - loss: 0.6643 - acc: 0.87 - ETA: 16s - loss: 0.6619 - acc: 0.87 - ETA: 16s - loss: 0.6619 - acc: 0.87 - ETA: 15s - loss: 0.6586 - acc: 0.87 - ETA: 15s - loss: 0.6564 - acc: 0.87 - ETA: 15s - loss: 0.6576 - acc: 0.87 - ETA: 14s - loss: 0.6623 - acc: 0.87 - ETA: 14s - loss: 0.6635 - acc: 0.87 - ETA: 14s - loss: 0.6657 - acc: 0.87 - ETA: 13s - loss: 0.6667 - acc: 0.87 - ETA: 13s - loss: 0.6635 - acc: 0.87 - ETA: 12s - loss: 0.6671 - acc: 0.86 - ETA: 12s - loss: 0.6658 - acc: 0.86 - ETA: 12s - loss: 0.6682 - acc: 0.86 - ETA: 11s - loss: 0.6648 - acc: 0.86 - ETA: 11s - loss: 0.6639 - acc: 0.86 - ETA: 10s - loss: 0.6644 - acc: 0.86 - ETA: 10s - loss: 0.6647 - acc: 0.86 - ETA: 9s - loss: 0.6631 - acc: 0.8680 - ETA: 9s - loss: 0.6624 - acc: 0.868 - ETA: 9s - loss: 0.6640 - acc: 0.867 - ETA: 8s - loss: 0.6645 - acc: 0.867 - ETA: 8s - loss: 0.6621 - acc: 0.869 - ETA: 7s - loss: 0.6642 - acc: 0.867 - ETA: 7s - loss: 0.6654 - acc: 0.866 - ETA: 7s - loss: 0.6642 - acc: 0.866 - ETA: 6s - loss: 0.6644 - acc: 0.866 - ETA: 6s - loss: 0.6672 - acc: 0.865 - ETA: 5s - loss: 0.6635 - acc: 0.867 - ETA: 5s - loss: 0.6646 - acc: 0.866 - ETA: 5s - loss: 0.6653 - acc: 0.866 - ETA: 4s - loss: 0.6709 - acc: 0.865 - ETA: 4s - loss: 0.6684 - acc: 0.866 - ETA: 3s - loss: 0.6669 - acc: 0.867 - ETA: 3s - loss: 0.6659 - acc: 0.867 - ETA: 2s - loss: 0.6649 - acc: 0.868 - ETA: 2s - loss: 0.6650 - acc: 0.868 - ETA: 2s - loss: 0.6647 - acc: 0.868 - ETA: 1s - loss: 0.6657 - acc: 0.867 - ETA: 1s - loss: 0.6696 - acc: 0.867 - ETA: 0s - loss: 0.6685 - acc: 0.867 - ETA: 0s - loss: 0.6698 - acc: 0.866 - 29s 447ms/step - loss: 0.6694 - acc: 0.8669 - val_loss: 0.9679 - val_acc: 0.7891\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80078\n",
      "Epoch 21/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.6665 - acc: 0.89 - ETA: 24s - loss: 0.7336 - acc: 0.88 - ETA: 24s - loss: 0.7341 - acc: 0.86 - ETA: 23s - loss: 0.7059 - acc: 0.87 - ETA: 23s - loss: 0.7225 - acc: 0.86 - ETA: 23s - loss: 0.6860 - acc: 0.88 - ETA: 22s - loss: 0.6625 - acc: 0.88 - ETA: 22s - loss: 0.6647 - acc: 0.88 - ETA: 21s - loss: 0.6699 - acc: 0.88 - ETA: 21s - loss: 0.6678 - acc: 0.88 - ETA: 20s - loss: 0.6739 - acc: 0.87 - ETA: 20s - loss: 0.6648 - acc: 0.87 - ETA: 19s - loss: 0.6633 - acc: 0.87 - ETA: 19s - loss: 0.6634 - acc: 0.87 - ETA: 19s - loss: 0.6673 - acc: 0.87 - ETA: 18s - loss: 0.6702 - acc: 0.87 - ETA: 18s - loss: 0.6750 - acc: 0.87 - ETA: 18s - loss: 0.6656 - acc: 0.87 - ETA: 18s - loss: 0.6610 - acc: 0.88 - ETA: 18s - loss: 0.6680 - acc: 0.87 - ETA: 17s - loss: 0.6627 - acc: 0.88 - ETA: 17s - loss: 0.6584 - acc: 0.88 - ETA: 16s - loss: 0.6599 - acc: 0.87 - ETA: 16s - loss: 0.6598 - acc: 0.87 - ETA: 16s - loss: 0.6625 - acc: 0.87 - ETA: 15s - loss: 0.6613 - acc: 0.87 - ETA: 15s - loss: 0.6577 - acc: 0.87 - ETA: 15s - loss: 0.6563 - acc: 0.87 - ETA: 14s - loss: 0.6531 - acc: 0.88 - ETA: 14s - loss: 0.6541 - acc: 0.87 - ETA: 13s - loss: 0.6563 - acc: 0.87 - ETA: 13s - loss: 0.6552 - acc: 0.87 - ETA: 12s - loss: 0.6531 - acc: 0.88 - ETA: 12s - loss: 0.6479 - acc: 0.88 - ETA: 12s - loss: 0.6492 - acc: 0.88 - ETA: 11s - loss: 0.6520 - acc: 0.88 - ETA: 11s - loss: 0.6503 - acc: 0.88 - ETA: 10s - loss: 0.6496 - acc: 0.88 - ETA: 10s - loss: 0.6509 - acc: 0.88 - ETA: 10s - loss: 0.6502 - acc: 0.88 - ETA: 9s - loss: 0.6487 - acc: 0.8841 - ETA: 9s - loss: 0.6453 - acc: 0.885 - ETA: 8s - loss: 0.6451 - acc: 0.885 - ETA: 8s - loss: 0.6459 - acc: 0.884 - ETA: 8s - loss: 0.6457 - acc: 0.884 - ETA: 7s - loss: 0.6445 - acc: 0.885 - ETA: 7s - loss: 0.6441 - acc: 0.886 - ETA: 6s - loss: 0.6424 - acc: 0.885 - ETA: 6s - loss: 0.6431 - acc: 0.885 - ETA: 5s - loss: 0.6429 - acc: 0.885 - ETA: 5s - loss: 0.6469 - acc: 0.883 - ETA: 5s - loss: 0.6484 - acc: 0.882 - ETA: 4s - loss: 0.6491 - acc: 0.882 - ETA: 4s - loss: 0.6543 - acc: 0.880 - ETA: 3s - loss: 0.6524 - acc: 0.880 - ETA: 3s - loss: 0.6532 - acc: 0.880 - ETA: 2s - loss: 0.6573 - acc: 0.880 - ETA: 2s - loss: 0.6557 - acc: 0.881 - ETA: 2s - loss: 0.6542 - acc: 0.881 - ETA: 1s - loss: 0.6541 - acc: 0.881 - ETA: 1s - loss: 0.6509 - acc: 0.881 - ETA: 0s - loss: 0.6509 - acc: 0.881 - ETA: 0s - loss: 0.6503 - acc: 0.882 - 29s 453ms/step - loss: 0.6497 - acc: 0.8826 - val_loss: 0.9809 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80078\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 25s - loss: 0.7550 - acc: 0.82 - ETA: 24s - loss: 0.6841 - acc: 0.86 - ETA: 24s - loss: 0.6797 - acc: 0.86 - ETA: 24s - loss: 0.7035 - acc: 0.84 - ETA: 23s - loss: 0.6737 - acc: 0.85 - ETA: 23s - loss: 0.6760 - acc: 0.85 - ETA: 22s - loss: 0.6594 - acc: 0.86 - ETA: 22s - loss: 0.6647 - acc: 0.86 - ETA: 21s - loss: 0.6711 - acc: 0.86 - ETA: 21s - loss: 0.6672 - acc: 0.86 - ETA: 21s - loss: 0.6723 - acc: 0.86 - ETA: 20s - loss: 0.6688 - acc: 0.86 - ETA: 20s - loss: 0.6624 - acc: 0.86 - ETA: 19s - loss: 0.6726 - acc: 0.86 - ETA: 19s - loss: 0.6778 - acc: 0.86 - ETA: 18s - loss: 0.6789 - acc: 0.86 - ETA: 18s - loss: 0.6790 - acc: 0.86 - ETA: 18s - loss: 0.6758 - acc: 0.86 - ETA: 17s - loss: 0.6751 - acc: 0.86 - ETA: 17s - loss: 0.6692 - acc: 0.86 - ETA: 17s - loss: 0.6752 - acc: 0.86 - ETA: 17s - loss: 0.6754 - acc: 0.86 - ETA: 16s - loss: 0.6701 - acc: 0.86 - ETA: 16s - loss: 0.6707 - acc: 0.86 - ETA: 15s - loss: 0.6716 - acc: 0.86 - ETA: 15s - loss: 0.6702 - acc: 0.86 - ETA: 15s - loss: 0.6763 - acc: 0.86 - ETA: 14s - loss: 0.6757 - acc: 0.86 - ETA: 14s - loss: 0.6759 - acc: 0.86 - ETA: 14s - loss: 0.6759 - acc: 0.86 - ETA: 13s - loss: 0.6754 - acc: 0.86 - ETA: 13s - loss: 0.6754 - acc: 0.86 - ETA: 12s - loss: 0.6780 - acc: 0.86 - ETA: 12s - loss: 0.6767 - acc: 0.86 - ETA: 12s - loss: 0.6755 - acc: 0.86 - ETA: 11s - loss: 0.6722 - acc: 0.87 - ETA: 11s - loss: 0.6717 - acc: 0.87 - ETA: 10s - loss: 0.6682 - acc: 0.87 - ETA: 10s - loss: 0.6648 - acc: 0.87 - ETA: 10s - loss: 0.6634 - acc: 0.87 - ETA: 9s - loss: 0.6613 - acc: 0.8742 - ETA: 9s - loss: 0.6608 - acc: 0.873 - ETA: 8s - loss: 0.6603 - acc: 0.873 - ETA: 8s - loss: 0.6582 - acc: 0.873 - ETA: 7s - loss: 0.6585 - acc: 0.874 - ETA: 7s - loss: 0.6595 - acc: 0.874 - ETA: 7s - loss: 0.6591 - acc: 0.875 - ETA: 6s - loss: 0.6584 - acc: 0.875 - ETA: 6s - loss: 0.6591 - acc: 0.874 - ETA: 5s - loss: 0.6581 - acc: 0.875 - ETA: 5s - loss: 0.6589 - acc: 0.874 - ETA: 5s - loss: 0.6601 - acc: 0.874 - ETA: 4s - loss: 0.6601 - acc: 0.874 - ETA: 4s - loss: 0.6609 - acc: 0.874 - ETA: 3s - loss: 0.6601 - acc: 0.875 - ETA: 3s - loss: 0.6628 - acc: 0.874 - ETA: 2s - loss: 0.6611 - acc: 0.875 - ETA: 2s - loss: 0.6606 - acc: 0.875 - ETA: 2s - loss: 0.6631 - acc: 0.875 - ETA: 1s - loss: 0.6618 - acc: 0.875 - ETA: 1s - loss: 0.6611 - acc: 0.875 - ETA: 0s - loss: 0.6617 - acc: 0.875 - ETA: 0s - loss: 0.6602 - acc: 0.875 - 29s 449ms/step - loss: 0.6634 - acc: 0.8740 - val_loss: 1.1967 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80078\n",
      "Epoch 23/25\n",
      "64/64 [==============================] - ETA: 25s - loss: 0.8066 - acc: 0.85 - ETA: 24s - loss: 0.7229 - acc: 0.87 - ETA: 24s - loss: 0.7087 - acc: 0.87 - ETA: 23s - loss: 0.7137 - acc: 0.86 - ETA: 23s - loss: 0.6844 - acc: 0.87 - ETA: 22s - loss: 0.6671 - acc: 0.87 - ETA: 22s - loss: 0.6760 - acc: 0.87 - ETA: 22s - loss: 0.6707 - acc: 0.87 - ETA: 21s - loss: 0.6739 - acc: 0.87 - ETA: 21s - loss: 0.6717 - acc: 0.86 - ETA: 20s - loss: 0.6737 - acc: 0.86 - ETA: 20s - loss: 0.6718 - acc: 0.86 - ETA: 19s - loss: 0.6689 - acc: 0.86 - ETA: 19s - loss: 0.6733 - acc: 0.86 - ETA: 19s - loss: 0.6757 - acc: 0.86 - ETA: 18s - loss: 0.6689 - acc: 0.86 - ETA: 18s - loss: 0.6688 - acc: 0.86 - ETA: 17s - loss: 0.6672 - acc: 0.87 - ETA: 17s - loss: 0.6610 - acc: 0.87 - ETA: 17s - loss: 0.6603 - acc: 0.87 - ETA: 16s - loss: 0.6608 - acc: 0.87 - ETA: 16s - loss: 0.6605 - acc: 0.87 - ETA: 16s - loss: 0.6581 - acc: 0.87 - ETA: 15s - loss: 0.6645 - acc: 0.87 - ETA: 15s - loss: 0.6591 - acc: 0.87 - ETA: 15s - loss: 0.6625 - acc: 0.87 - ETA: 14s - loss: 0.6655 - acc: 0.87 - ETA: 14s - loss: 0.6699 - acc: 0.87 - ETA: 14s - loss: 0.6653 - acc: 0.87 - ETA: 13s - loss: 0.6649 - acc: 0.87 - ETA: 13s - loss: 0.6606 - acc: 0.87 - ETA: 13s - loss: 0.6630 - acc: 0.87 - ETA: 12s - loss: 0.6633 - acc: 0.87 - ETA: 12s - loss: 0.6624 - acc: 0.87 - ETA: 11s - loss: 0.6610 - acc: 0.87 - ETA: 11s - loss: 0.6553 - acc: 0.87 - ETA: 11s - loss: 0.6517 - acc: 0.87 - ETA: 10s - loss: 0.6581 - acc: 0.87 - ETA: 10s - loss: 0.6534 - acc: 0.87 - ETA: 9s - loss: 0.6565 - acc: 0.8766 - ETA: 9s - loss: 0.6533 - acc: 0.876 - ETA: 9s - loss: 0.6543 - acc: 0.876 - ETA: 8s - loss: 0.6552 - acc: 0.876 - ETA: 8s - loss: 0.6543 - acc: 0.875 - ETA: 7s - loss: 0.6538 - acc: 0.875 - ETA: 7s - loss: 0.6532 - acc: 0.875 - ETA: 7s - loss: 0.6517 - acc: 0.876 - ETA: 6s - loss: 0.6489 - acc: 0.877 - ETA: 6s - loss: 0.6525 - acc: 0.876 - ETA: 5s - loss: 0.6511 - acc: 0.877 - ETA: 5s - loss: 0.6508 - acc: 0.877 - ETA: 5s - loss: 0.6470 - acc: 0.879 - ETA: 4s - loss: 0.6469 - acc: 0.879 - ETA: 4s - loss: 0.6470 - acc: 0.879 - ETA: 3s - loss: 0.6462 - acc: 0.879 - ETA: 3s - loss: 0.6451 - acc: 0.878 - ETA: 2s - loss: 0.6450 - acc: 0.879 - ETA: 2s - loss: 0.6470 - acc: 0.879 - ETA: 2s - loss: 0.6459 - acc: 0.879 - ETA: 1s - loss: 0.6460 - acc: 0.879 - ETA: 1s - loss: 0.6447 - acc: 0.880 - ETA: 0s - loss: 0.6442 - acc: 0.881 - ETA: 0s - loss: 0.6446 - acc: 0.881 - 28s 444ms/step - loss: 0.6418 - acc: 0.8823 - val_loss: 1.1208 - val_acc: 0.7637\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80078\n",
      "Epoch 24/25\n",
      "64/64 [==============================] - ETA: 24s - loss: 0.5810 - acc: 0.87 - ETA: 24s - loss: 0.5731 - acc: 0.89 - ETA: 24s - loss: 0.6073 - acc: 0.88 - ETA: 23s - loss: 0.6073 - acc: 0.88 - ETA: 23s - loss: 0.6365 - acc: 0.88 - ETA: 23s - loss: 0.6275 - acc: 0.89 - ETA: 22s - loss: 0.6384 - acc: 0.89 - ETA: 22s - loss: 0.6427 - acc: 0.89 - ETA: 21s - loss: 0.6431 - acc: 0.88 - ETA: 21s - loss: 0.6477 - acc: 0.88 - ETA: 20s - loss: 0.6557 - acc: 0.87 - ETA: 20s - loss: 0.6624 - acc: 0.87 - ETA: 20s - loss: 0.6652 - acc: 0.87 - ETA: 19s - loss: 0.6651 - acc: 0.87 - ETA: 19s - loss: 0.6598 - acc: 0.87 - ETA: 18s - loss: 0.6542 - acc: 0.87 - ETA: 18s - loss: 0.6645 - acc: 0.86 - ETA: 18s - loss: 0.6561 - acc: 0.87 - ETA: 17s - loss: 0.6460 - acc: 0.87 - ETA: 17s - loss: 0.6469 - acc: 0.87 - ETA: 16s - loss: 0.6455 - acc: 0.87 - ETA: 16s - loss: 0.6503 - acc: 0.87 - ETA: 16s - loss: 0.6468 - acc: 0.87 - ETA: 15s - loss: 0.6491 - acc: 0.87 - ETA: 15s - loss: 0.6491 - acc: 0.87 - ETA: 14s - loss: 0.6496 - acc: 0.87 - ETA: 14s - loss: 0.6503 - acc: 0.87 - ETA: 14s - loss: 0.6499 - acc: 0.87 - ETA: 13s - loss: 0.6536 - acc: 0.87 - ETA: 13s - loss: 0.6550 - acc: 0.87 - ETA: 13s - loss: 0.6621 - acc: 0.87 - ETA: 12s - loss: 0.6599 - acc: 0.87 - ETA: 12s - loss: 0.6550 - acc: 0.87 - ETA: 12s - loss: 0.6543 - acc: 0.87 - ETA: 11s - loss: 0.6493 - acc: 0.87 - ETA: 11s - loss: 0.6559 - acc: 0.87 - ETA: 10s - loss: 0.6576 - acc: 0.87 - ETA: 10s - loss: 0.6561 - acc: 0.87 - ETA: 10s - loss: 0.6554 - acc: 0.87 - ETA: 9s - loss: 0.6545 - acc: 0.8750 - ETA: 9s - loss: 0.6569 - acc: 0.875 - ETA: 8s - loss: 0.6549 - acc: 0.876 - ETA: 8s - loss: 0.6593 - acc: 0.874 - ETA: 8s - loss: 0.6581 - acc: 0.875 - ETA: 7s - loss: 0.6624 - acc: 0.873 - ETA: 7s - loss: 0.6633 - acc: 0.874 - ETA: 6s - loss: 0.6621 - acc: 0.874 - ETA: 6s - loss: 0.6620 - acc: 0.874 - ETA: 6s - loss: 0.6593 - acc: 0.875 - ETA: 5s - loss: 0.6582 - acc: 0.876 - ETA: 5s - loss: 0.6567 - acc: 0.877 - ETA: 4s - loss: 0.6573 - acc: 0.875 - ETA: 4s - loss: 0.6600 - acc: 0.875 - ETA: 4s - loss: 0.6637 - acc: 0.874 - ETA: 3s - loss: 0.6634 - acc: 0.874 - ETA: 3s - loss: 0.6650 - acc: 0.873 - ETA: 2s - loss: 0.6638 - acc: 0.873 - ETA: 2s - loss: 0.6630 - acc: 0.873 - ETA: 2s - loss: 0.6634 - acc: 0.873 - ETA: 1s - loss: 0.6623 - acc: 0.873 - ETA: 1s - loss: 0.6635 - acc: 0.873 - ETA: 0s - loss: 0.6624 - acc: 0.873 - ETA: 0s - loss: 0.6663 - acc: 0.872 - 28s 439ms/step - loss: 0.6671 - acc: 0.8718 - val_loss: 1.0484 - val_acc: 0.7402\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80078\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 24s - loss: 0.5533 - acc: 0.90 - ETA: 24s - loss: 0.6613 - acc: 0.85 - ETA: 24s - loss: 0.6370 - acc: 0.85 - ETA: 23s - loss: 0.6316 - acc: 0.87 - ETA: 23s - loss: 0.6440 - acc: 0.86 - ETA: 23s - loss: 0.6417 - acc: 0.87 - ETA: 22s - loss: 0.6271 - acc: 0.88 - ETA: 22s - loss: 0.6366 - acc: 0.87 - ETA: 21s - loss: 0.6213 - acc: 0.88 - ETA: 21s - loss: 0.6155 - acc: 0.88 - ETA: 20s - loss: 0.6139 - acc: 0.89 - ETA: 20s - loss: 0.6155 - acc: 0.88 - ETA: 20s - loss: 0.6122 - acc: 0.88 - ETA: 19s - loss: 0.6086 - acc: 0.88 - ETA: 19s - loss: 0.6098 - acc: 0.88 - ETA: 18s - loss: 0.6102 - acc: 0.88 - ETA: 18s - loss: 0.6108 - acc: 0.88 - ETA: 17s - loss: 0.6090 - acc: 0.88 - ETA: 17s - loss: 0.6108 - acc: 0.88 - ETA: 17s - loss: 0.6122 - acc: 0.88 - ETA: 16s - loss: 0.6151 - acc: 0.88 - ETA: 16s - loss: 0.6232 - acc: 0.88 - ETA: 16s - loss: 0.6366 - acc: 0.87 - ETA: 15s - loss: 0.6395 - acc: 0.87 - ETA: 15s - loss: 0.6473 - acc: 0.87 - ETA: 14s - loss: 0.6445 - acc: 0.87 - ETA: 14s - loss: 0.6455 - acc: 0.87 - ETA: 14s - loss: 0.6458 - acc: 0.87 - ETA: 13s - loss: 0.6453 - acc: 0.87 - ETA: 13s - loss: 0.6432 - acc: 0.87 - ETA: 13s - loss: 0.6405 - acc: 0.87 - ETA: 12s - loss: 0.6440 - acc: 0.87 - ETA: 12s - loss: 0.6418 - acc: 0.87 - ETA: 12s - loss: 0.6435 - acc: 0.87 - ETA: 11s - loss: 0.6430 - acc: 0.87 - ETA: 11s - loss: 0.6448 - acc: 0.87 - ETA: 10s - loss: 0.6463 - acc: 0.87 - ETA: 10s - loss: 0.6438 - acc: 0.87 - ETA: 10s - loss: 0.6440 - acc: 0.87 - ETA: 9s - loss: 0.6434 - acc: 0.8750 - ETA: 9s - loss: 0.6455 - acc: 0.874 - ETA: 8s - loss: 0.6469 - acc: 0.874 - ETA: 8s - loss: 0.6452 - acc: 0.875 - ETA: 8s - loss: 0.6465 - acc: 0.876 - ETA: 7s - loss: 0.6489 - acc: 0.875 - ETA: 7s - loss: 0.6516 - acc: 0.874 - ETA: 6s - loss: 0.6527 - acc: 0.874 - ETA: 6s - loss: 0.6533 - acc: 0.873 - ETA: 6s - loss: 0.6556 - acc: 0.873 - ETA: 5s - loss: 0.6528 - acc: 0.874 - ETA: 5s - loss: 0.6531 - acc: 0.874 - ETA: 4s - loss: 0.6522 - acc: 0.874 - ETA: 4s - loss: 0.6529 - acc: 0.873 - ETA: 4s - loss: 0.6533 - acc: 0.874 - ETA: 3s - loss: 0.6531 - acc: 0.875 - ETA: 3s - loss: 0.6502 - acc: 0.876 - ETA: 2s - loss: 0.6524 - acc: 0.875 - ETA: 2s - loss: 0.6520 - acc: 0.875 - ETA: 2s - loss: 0.6511 - acc: 0.876 - ETA: 1s - loss: 0.6485 - acc: 0.877 - ETA: 1s - loss: 0.6493 - acc: 0.877 - ETA: 0s - loss: 0.6489 - acc: 0.877 - ETA: 0s - loss: 0.6473 - acc: 0.877 - 28s 434ms/step - loss: 0.6466 - acc: 0.8777 - val_loss: 1.2320 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80078\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 25\n",
    "batch_size=64\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist1 = model.fit_generator(data_gen(train[\"Video\"].tolist()[0:],batch_size),\n",
    "                           validation_data=data_gen(validation[\"Video\"].tolist()[0:1500],batch_size),\n",
    "                           steps_per_epoch=64,\n",
    "                           validation_steps=8,\n",
    "                           epochs = nb_epoch,\n",
    "                           callbacks=[checkpoint,lr_reducer]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.159174650907516, 8.306070894002914, 7.739842616021633, 7.284769669175148, 6.85097000002861, 6.434616029262543, 6.07478092610836, 5.754337944090366, 5.432695411145687, 5.146792985498905, 4.89737918227911, 4.627633407711983, 4.408005028963089, 4.173054661601782, 3.9833878576755524, 3.7621783949434757, 3.6150610893964767, 3.4649037942290306, 3.2831980772316456, 3.184559315443039, 2.993940208107233, 2.8784841671586037, 2.754051096737385, 2.638166233897209, 2.5338493771851063, 2.4327814131975174, 2.3546321019530296, 2.2276926767081022, 2.1866721380501986, 2.1142055969685316, 1.9912969209253788, 2.017504060640931, 1.9047045391052961, 1.8632878568023443, 1.8377693258225918, 1.7462337035685778, 1.6978614125400782, 1.653299866244197, 1.6017180066555738, 1.558741295710206, 1.5335441567003727, 1.5042224302887917, 1.4495833441615105, 1.4466045051813126, 1.4101767968386412, 1.3792289644479752, 1.3259321860969067, 1.32746472209692, 1.3220573868602514, 1.3094399366527796, 1.2346582626923919, 1.2114819642156363, 1.2209966974332929, 1.2065796181559563, 1.1838647173717618, 1.195016206242144, 1.1190113564953208, 1.1356302853673697, 1.1717200465500355, 1.1160187795758247, 1.09472909104079, 1.0864122342318296, 1.0922120613977313, 1.106229211203754, 1.0603370852768421, 1.0581199396401644, 1.048354177735746, 1.0379802454262972, 1.0280553186312318, 1.0460070855915546, 1.0184034099802375, 1.051059358753264, 1.0149177964776754, 1.0255726696923375, 1.0552332010120153, 1.0120438300073147, 0.9763939324766397, 1.001460268162191, 1.012777958996594, 0.9876488046720624, 0.9763959012925625, 0.9576813811436296, 0.9841288030147552, 1.0036444021388888, 0.9977497300133109, 0.9634668910875916, 0.9665399584919214, 0.8988357530906796, 0.8778338385745883, 0.8597198966890574, 0.84183978009969, 0.8553785560652614, 0.8296868577599525, 0.8426294038072228, 0.8365391250699759, 0.8251376915723085, 0.8074707956984639, 0.8371638478711247, 0.7934301840141416, 0.8028377341106534, [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073]\n"
     ]
    }
   ],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.159174650907516, 8.306070894002914, 7.739842616021633, 7.284769669175148, 6.85097000002861, 6.434616029262543, 6.07478092610836, 5.754337944090366, 5.432695411145687, 5.146792985498905, 4.89737918227911, 4.627633407711983, 4.408005028963089, 4.173054661601782, 3.9833878576755524, 3.7621783949434757, 3.6150610893964767, 3.4649037942290306, 3.2831980772316456, 3.184559315443039, 2.993940208107233, 2.8784841671586037, 2.754051096737385, 2.638166233897209, 2.5338493771851063, 2.4327814131975174, 2.3546321019530296, 2.2276926767081022, 2.1866721380501986, 2.1142055969685316, 1.9912969209253788, 2.017504060640931, 1.9047045391052961, 1.8632878568023443, 1.8377693258225918, 1.7462337035685778, 1.6978614125400782, 1.653299866244197, 1.6017180066555738, 1.558741295710206, 1.5335441567003727, 1.5042224302887917, 1.4495833441615105, 1.4466045051813126, 1.4101767968386412, 1.3792289644479752, 1.3259321860969067, 1.32746472209692, 1.3220573868602514, 1.3094399366527796, 1.2346582626923919, 1.2114819642156363, 1.2209966974332929, 1.2065796181559563, 1.1838647173717618, 1.195016206242144, 1.1190113564953208, 1.1356302853673697, 1.1717200465500355, 1.1160187795758247, 1.09472909104079, 1.0864122342318296, 1.0922120613977313, 1.106229211203754, 1.0603370852768421, 1.0581199396401644, 1.048354177735746, 1.0379802454262972, 1.0280553186312318, 1.0460070855915546, 1.0184034099802375, 1.051059358753264, 1.0149177964776754, 1.0255726696923375, 1.0552332010120153, 1.0120438300073147, 0.9763939324766397, 1.001460268162191, 1.012777958996594, 0.9876488046720624, 0.9763959012925625, 0.9576813811436296, 0.9841288030147552, 1.0036444021388888, 0.9977497300133109, 0.9634668910875916, 0.9665399584919214, 0.8988357530906796, 0.8778338385745883, 0.8597198966890574, 0.84183978009969, 0.8553785560652614, 0.8296868577599525, 0.8426294038072228, 0.8365391250699759, 0.8251376915723085, 0.8074707956984639, 0.8371638478711247, 0.7934301840141416, 0.8028377341106534, [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], [0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073], 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073, 0.7813731441274285, 0.811829587444663, 0.7740358589217067, 0.7762301713228226, 0.7780659655109048, 0.7742243064567447, 0.7510848948732018, 0.7567032305523753, 0.7505011884495616, 0.7714072735980153, 0.758393807336688, 0.7286364771425724, 0.7307634111493826, 0.7459195852279663, 0.7616943260654807, 0.7360555920749903, 0.7319521177560091, 0.7245918423868716, 0.7367974705994129, 0.7289915597066283, 0.7341660158708692, 0.721584627404809, 0.690944978967309, 0.7049909895285964, 0.7178594963625073]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"for entry in hist1.history['loss']:\n",
    "    training_loss.append(entry)\n",
    "for entry in hist1.history['val_loss']:\n",
    "    val_loss.append(entry)\n",
    "for entry in hist1.history['acc']:\n",
    "    training_acc.append(entry)\n",
    "for entry in hist1.history['val_acc']:\n",
    "    val_acc.append(entry)\"\"\"\n",
    "print(len(training_loss))\n",
    "print(len(val_loss))\n",
    "print(len(training_acc))\n",
    "print(len(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1619\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a5572d9a51bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"training_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning Curve\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2811\u001b[0m     return gca().plot(\n\u001b[0;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2813\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1618\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     '''\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \"\"\"\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model1_name = \"working\"\n",
    "model1_path = os.path.join(save_dir, model1_name)\n",
    "model1 = load_model(model1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:07<00:00, 191.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 176, 2)\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "\n",
    "X_tr=[]           # variable to store entire dataset\n",
    "label=[]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "ls_path = os.path.join(\"E:/Jupyter/Project/generated_images512_timeSampled\")\n",
    "\n",
    "for vid_ID in tqdm(validation[\"Video\"].tolist()[0:1500]):\n",
    "    frames = []\n",
    "    frame_count=0\n",
    "    pos_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    neg_dir = os.path.join(os.path.join(ls_path,\"pos\"),str(vid_ID))\n",
    "    for img_ID in sorted(os.listdir(pos_dir)):\n",
    "        if frame_count < nb_frames:\n",
    "            pos = os.path.join(pos_dir,img_ID)\n",
    "            neg = os.path.join(neg_dir,img_ID)\n",
    "            p_img = cv2.imread(pos,0)\n",
    "            p_img = cv2.resize(p_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            n_img = cv2.imread(neg,0)\n",
    "            n_img = cv2.resize(n_img,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.merge((p_img,n_img))\n",
    "            frames.append(frame)\n",
    "            frame_count+=1\n",
    "        else:\n",
    "            break\n",
    "    while frame_count < nb_frames:\n",
    "        frames.append(np.zeros((img_cols,img_rows,channels), np.uint8))\n",
    "        frame_count+=1\n",
    "    input_img = np.array(frames)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    X_tr.append(ipt)\n",
    "    label.append(labels_dict[vid_ID])\n",
    "\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr) \n",
    "print (num_samples)\n",
    "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "train_data = [X_tr_array,label]\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "train_set = np.zeros((num_samples, nb_frames, img_cols,img_rows,2))\n",
    "for h in range(num_samples):\n",
    "    train_set[h][:][:][:][:]=X_train[h,:,:,:]\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 3 0 5 0 3 3 5 3 0 0 4 2 0 4 4 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "test_pred =model1.predict(train_set[50:70])\n",
    "result = np.argmax(test_pred, axis =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244   1   0  18   3   2]\n",
      " [  8  29  75  73  25  22]\n",
      " [  7  14 108  80  15  37]\n",
      " [ 29   0   0 189  24  14]\n",
      " [  9   0   0  52 167  17]\n",
      " [  3   0   2  55  26 152]]\n"
     ]
    }
   ],
   "source": [
    "img_array = train_set[50]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "met = confusion_matrix(np.argmax(Y_train,axis =1), np.argmax(model1.predict(train_set),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, range(27), rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_plot(met, classes=labels[labels[\"Class\"].isin([\"No gesture\",\"Swiping Left\",\"Swiping Right\",\"Stop Sign\",\"Rolling Hand Forward\",\"Rolling Hand Backward\"])].sort_values(by=['Label'])['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - ETA: 13 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9234457728068033, 0.5926666661898295]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(train_set,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
